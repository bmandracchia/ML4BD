
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Image Classification &#8212; Introduction to Machine Learning for Biomedical Data</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b76e3c8a" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'chapters/25_Image_Classification';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Convolutional Neural Networks" href="26_convolutions.html" />
    <link rel="prev" title="Training a Digit Classifier" href="24_Loss_Metrics_and_Optimizers.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="Introduction to Machine Learning for Biomedical Data - Home"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="Introduction to Machine Learning for Biomedical Data - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Computational Tools</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="01_python_primer.html">Python: a Primer</a></li>
<li class="toctree-l1"><a class="reference internal" href="02_data_science_with_pandas.html">Data Science with Python and Pandas</a></li>
<li class="toctree-l1"><a class="reference internal" href="03_jupyter_markdown.html">Jupyter &amp; Markdown</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Feature Engineering</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="11_machine_learning_fundamentals.html">The Machine Learning Fundamentals</a></li>
<li class="toctree-l1"><a class="reference internal" href="12_basic_feature_engineering.html">Basic Feature Engineering</a></li>
<li class="toctree-l1"><a class="reference internal" href="13_categorical_variables.html">Categorical Variables</a></li>
<li class="toctree-l1"><a class="reference internal" href="14_classifiers.html">Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="15_decision_trees.html">Decision Trees</a></li>
<li class="toctree-l1"><a class="reference internal" href="16_dimensionality_reduction.html">Dimensionality Reduction: PCA</a></li>
<li class="toctree-l1"><a class="reference internal" href="17_kmeans.html">Nonlinear Manifold Feature Extraction</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Deep Learning</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="21_neural%20networks.html">Deep Learning in Biomedical Engineering</a></li>
<li class="toctree-l1"><a class="reference internal" href="23_NN_as_UA.html">Neural Networks as Universal Approximators</a></li>
<li class="toctree-l1"><a class="reference internal" href="24_Loss_Metrics_and_Optimizers.html">Training a Digit Classifier</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Image Classification</a></li>

<li class="toctree-l1"><a class="reference internal" href="26_convolutions.html">Convolutional Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="27_resnet2.html">ResNets for Biomedical Image Analysis</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/bmandracchia/ML4BD" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/bmandracchia/ML4BD/issues/new?title=Issue%20on%20page%20%2Fchapters/25_Image_Classification.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/chapters/25_Image_Classification.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Image Classification</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Image Classification</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pet-breeds-data">Pet Breeds Data</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#understanding-data-layout">Understanding Data Layout</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#inspecting-image-files">Inspecting Image Files</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#extracting-labels-using-regular-expressions">Extracting Labels Using Regular Expressions</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#building-the-datablock">Building the DataBlock</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#explanation-of-the-datablock-parameters">Explanation of the <code class="docutils literal notranslate"><span class="pre">DataBlock</span></code> Parameters</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-augmentation-and-presizing">Data Augmentation and Presizing</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#presizing">Presizing</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#validating-the-data-pipeline">Validating the Data Pipeline</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training-the-model">Training the Model</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#understanding-cross-entropy-loss">Understanding Cross-Entropy Loss</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#interpreting-the-model">Interpreting the Model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#improving-the-model">Improving the Model</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-learning-rate">The Learning Rate</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#learning-rate-finder">Learning Rate Finder</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#fine-tuning-and-transfer-learning">Fine-Tuning and Transfer Learning</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#concept-of-transfer-learning">Concept of Transfer Learning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#discriminative-learning-rates">Discriminative Learning Rates</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#using-deeper-architectures">Using Deeper Architectures</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#further-optimization-selecting-epochs-and-avoiding-overfitting">Further Optimization: Selecting Epochs and Avoiding Overfitting</a></li>
</ul>
</li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="image-classification">
<h1>Image Classification<a class="headerlink" href="#image-classification" title="Link to this heading">#</a></h1>
<p>In this lesson, we will build an image classifier to identify pet breeds. We’ll explore the key steps and techniques in the deep learning pipeline, from handling image data to transforming it, training models, and optimizing performance. We’ll use the fastai library, which simplifies working with large datasets and neural networks.</p>
<p>In image classification, our goal is to assign a label <span class="math notranslate nohighlight">\( y \)</span> to each image <span class="math notranslate nohighlight">\( X \)</span> from a set of possible classes <span class="math notranslate nohighlight">\( C \)</span>, where <span class="math notranslate nohighlight">\( C \)</span> could be categories like pet breeds, disease states, or cell types. Mathematically, we can represent this as a function <span class="math notranslate nohighlight">\( f: X \rightarrow y \)</span>, which maps each image to a class label. This is achieved by training a model to minimize a loss function that quantifies the difference between predicted and true labels.</p>
<p>For binary classification (e.g., identifying the presence or absence of a disease), the output is a single probability score <span class="math notranslate nohighlight">\( p \)</span>, with <span class="math notranslate nohighlight">\( y = 1 \)</span> if <span class="math notranslate nohighlight">\( p \geq 0.5 \)</span> and <span class="math notranslate nohighlight">\( y = 0 \)</span> otherwise. For multi-class classification (e.g., identifying different types of tumors), the model outputs a vector of probabilities <span class="math notranslate nohighlight">\( \mathbf{p} = [p_1, p_2, \dots, p_k] \)</span> for each class <span class="math notranslate nohighlight">\( k \)</span>, where <span class="math notranslate nohighlight">\( \sum_{i=1}^k p_i = 1 \)</span>.</p>
<section id="pet-breeds-data">
<h2>Pet Breeds Data<a class="headerlink" href="#pet-breeds-data" title="Link to this heading">#</a></h2>
<p>We begin by importing fastai and downloading the Oxford-IIIT Pet dataset. This dataset consists of images of various pet breeds, making it suitable for building a model that classifies each image based on breed.</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">fastai.vision.all</span> <span class="kn">import</span> <span class="o">*</span>
<span class="n">path</span> <span class="o">=</span> <span class="n">untar_data</span><span class="p">(</span><span class="n">URLs</span><span class="o">.</span><span class="n">PETS</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
</div>
<section id="understanding-data-layout">
<h3>Understanding Data Layout<a class="headerlink" href="#understanding-data-layout" title="Link to this heading">#</a></h3>
<p>To train a deep learning model effectively, we need to know how the data is structured. Generally, biomedical image data follows specific patterns, such as:</p>
<ul class="simple">
<li><p><strong>Folder-based organization:</strong> Images are stored in directories by class label (e.g., “Normal” and “Tumor”).</p></li>
<li><p><strong>Tabular annotation files:</strong> Metadata in CSV files may specify the condition or label of each image.</p></li>
</ul>
<p>Most datasets follow these patterns, though exceptions exist. For instance, genomic data may use binary database formats. Let’s explore the layout of our dataset:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">path</span><span class="o">.</span><span class="n">ls</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(#2) [Path(&#39;C:/Users/biagi/.fastai/data/oxford-iiit-pet/annotations&#39;),Path(&#39;C:/Users/biagi/.fastai/data/oxford-iiit-pet/images&#39;)]
</pre></div>
</div>
</div>
</div>
<p>In our case, pet images are stored in a directory, and the label (breed) is embedded in the filename.</p>
<p>The dataset contains two main folders: <em>images</em> and <em>annotations</em>. According to the dataset’s <a class="reference external" href="https://www.robots.ox.ac.uk/~vgg/data/pets/">website</a>, the <em>annotations</em> folder provides localization information (i.e., where pets are located in each image). For this lesson, we focus on classification (identifying the breed) rather than localization, so we’ll only use the <em>images</em> folder.</p>
</section>
<section id="inspecting-image-files">
<h3>Inspecting Image Files<a class="headerlink" href="#inspecting-image-files" title="Link to this heading">#</a></h3>
<p>To understand the data better, let’s examine the files inside the <em>images</em> directory.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="n">path</span><span class="o">/</span><span class="s2">&quot;images&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">ls</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(#7393) [Path(&#39;C:/Users/biagi/.fastai/data/oxford-iiit-pet/images/Abyssinian_1.jpg&#39;),Path(&#39;C:/Users/biagi/.fastai/data/oxford-iiit-pet/images/Abyssinian_10.jpg&#39;),Path(&#39;C:/Users/biagi/.fastai/data/oxford-iiit-pet/images/Abyssinian_100.jpg&#39;),Path(&#39;C:/Users/biagi/.fastai/data/oxford-iiit-pet/images/Abyssinian_100.mat&#39;),Path(&#39;C:/Users/biagi/.fastai/data/oxford-iiit-pet/images/Abyssinian_101.jpg&#39;),Path(&#39;C:/Users/biagi/.fastai/data/oxford-iiit-pet/images/Abyssinian_101.mat&#39;),Path(&#39;C:/Users/biagi/.fastai/data/oxford-iiit-pet/images/Abyssinian_102.jpg&#39;),Path(&#39;C:/Users/biagi/.fastai/data/oxford-iiit-pet/images/Abyssinian_102.mat&#39;),Path(&#39;C:/Users/biagi/.fastai/data/oxford-iiit-pet/images/Abyssinian_103.jpg&#39;),Path(&#39;C:/Users/biagi/.fastai/data/oxford-iiit-pet/images/Abyssinian_104.jpg&#39;)...]
</pre></div>
</div>
</div>
</div>
<p>Each filename contains the pet breed, followed by an underscore (<code class="docutils literal notranslate"><span class="pre">_</span></code>), a number, and a file extension. By analyzing the structure, we can see that the breed name precedes the underscore, making it possible to extract the breed name directly from the filename.</p>
</section>
<section id="extracting-labels-using-regular-expressions">
<h3>Extracting Labels Using Regular Expressions<a class="headerlink" href="#extracting-labels-using-regular-expressions" title="Link to this heading">#</a></h3>
<p>To automate label extraction, we can use regular expressions (regex). Regular expressions provide a powerful way to find patterns in text. Here, we’ll use regex to isolate the breed name from each filename.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">re</span>

<span class="c1"># Select an example file</span>
<span class="n">fname</span> <span class="o">=</span> <span class="p">(</span><span class="n">path</span><span class="o">/</span><span class="s2">&quot;images&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">ls</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
<span class="c1"># Use regex to extract the breed name</span>
<span class="n">re</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;(.+)_\d+.jpg$&#39;</span><span class="p">,</span> <span class="n">fname</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;Abyssinian&#39;]
</pre></div>
</div>
</div>
</div>
<p>Explanation:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">r'(.+)_\d+.jpg$'</span></code>: This regex matches one or more characters before the last underscore, captures them in parentheses, and ignores the subsequent number and <code class="docutils literal notranslate"><span class="pre">.jpg</span></code> extension. This pattern helps us isolate the breed name in the filename.</p></li>
</ul>
</section>
<section id="building-the-datablock">
<h3>Building the DataBlock<a class="headerlink" href="#building-the-datablock" title="Link to this heading">#</a></h3>
<p>With our extraction pattern in place, we’ll use fastai’s <code class="docutils literal notranslate"><span class="pre">DataBlock</span></code> API to set up the data pipeline. <code class="docutils literal notranslate"><span class="pre">DataBlock</span></code> helps you organize and transform data for training, providing a flexible approach to defining inputs, outputs, and transformations.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pets</span> <span class="o">=</span> <span class="n">DataBlock</span><span class="p">(</span>
    <span class="n">blocks</span><span class="o">=</span><span class="p">(</span><span class="n">ImageBlock</span><span class="p">,</span> <span class="n">CategoryBlock</span><span class="p">),</span>
    <span class="n">get_items</span><span class="o">=</span><span class="n">get_image_files</span><span class="p">,</span>
    <span class="n">splitter</span><span class="o">=</span><span class="n">RandomSplitter</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">),</span>
    <span class="n">get_y</span><span class="o">=</span><span class="n">using_attr</span><span class="p">(</span><span class="n">RegexLabeller</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;(.+)_\d+.jpg$&#39;</span><span class="p">),</span> <span class="s1">&#39;name&#39;</span><span class="p">),</span>
    <span class="n">item_tfms</span><span class="o">=</span><span class="n">Resize</span><span class="p">(</span><span class="mi">460</span><span class="p">),</span>
    <span class="n">batch_tfms</span><span class="o">=</span><span class="n">aug_transforms</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">224</span><span class="p">,</span> <span class="n">min_scale</span><span class="o">=</span><span class="mf">0.75</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">dls</span> <span class="o">=</span> <span class="n">pets</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">(</span><span class="n">path</span><span class="o">/</span><span class="s2">&quot;images&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<section id="explanation-of-the-datablock-parameters">
<h4>Explanation of the <code class="docutils literal notranslate"><span class="pre">DataBlock</span></code> Parameters<a class="headerlink" href="#explanation-of-the-datablock-parameters" title="Link to this heading">#</a></h4>
<ul class="simple">
<li><p><strong><code class="docutils literal notranslate"><span class="pre">blocks=(ImageBlock,</span> <span class="pre">CategoryBlock)</span></code></strong>: Specifies that the input type is an image and the output is a category (label).</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">get_items=get_image_files</span></code></strong>: Retrieves all image files within the specified path.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">splitter=RandomSplitter(seed=42)</span></code></strong>: Randomly splits the dataset into training and validation sets. Setting a seed ensures consistency across runs.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">get_y=using_attr(RegexLabeller(r'(.+)_\d+.jpg$'),</span> <span class="pre">'name')</span></code></strong>: Uses the regex pattern to extract labels from filenames.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">item_tfms=Resize(460)</span></code></strong>: Resizes each image to 460 pixels. This larger size supports flexible transformations while preserving image quality.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">batch_tfms=aug_transforms(size=224,</span> <span class="pre">min_scale=0.75)</span></code></strong>: Performs batch-level transformations, such as resizing to 224 pixels and applying data augmentation.</p></li>
</ul>
</section>
</section>
</section>
<section id="data-augmentation-and-presizing">
<h2>Data Augmentation and Presizing<a class="headerlink" href="#data-augmentation-and-presizing" title="Link to this heading">#</a></h2>
<p>To improve model robustness, we’ll apply data augmentation using a technique called <em>presizing</em>. Presizing helps retain image quality during augmentation.</p>
<section id="presizing">
<h3>Presizing<a class="headerlink" href="#presizing" title="Link to this heading">#</a></h3>
<p>Presizing is an augmentation technique that prepares images at a larger size than the target training size. By resizing initially to 460 pixels, we avoid excessive data loss or distortion during transformations.</p>
<ul class="simple">
<li><p><strong><code class="docutils literal notranslate"><span class="pre">item_tfms=Resize(460)</span></code></strong>: This transformation prepares images for subsequent augmentations by resizing them to a large dimension.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">batch_tfms=aug_transforms(size=224,</span> <span class="pre">min_scale=0.75)</span></code></strong>: The batch transformation downsizes images to the target size (224 pixels) and applies augmentations like rotation, zooming, and warping, ensuring these happen in a single step on the GPU to maintain data quality.</p></li>
</ul>
<p>Presizing helps ensure that augmented images don’t lose essential details or develop artifacts, which can negatively impact model training.</p>
</section>
</section>
<section id="validating-the-data-pipeline">
<h2>Validating the Data Pipeline<a class="headerlink" href="#validating-the-data-pipeline" title="Link to this heading">#</a></h2>
<p>Before training, always verify the data pipeline. Errors or misaligned labels can lead to incorrect model training. We can check the data layout using <code class="docutils literal notranslate"><span class="pre">show_batch</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dls</span><span class="o">.</span><span class="n">show_batch</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/b1645b8201ae574999e1e5929a460d876cd63d2dac8d5af12e8d6e0113f2e9f9.png" src="../_images/b1645b8201ae574999e1e5929a460d876cd63d2dac8d5af12e8d6e0113f2e9f9.png" />
</div>
</div>
<p>This visualizes a batch of images and their labels, helping confirm that images match expected labels. If needed, use the <code class="docutils literal notranslate"><span class="pre">summary</span></code> method to display a detailed breakdown of data transformations and steps.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pets</span><span class="o">.</span><span class="n">summary</span><span class="p">(</span><span class="n">path</span><span class="o">/</span><span class="s2">&quot;images&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Setting-up type transforms pipelines
Collecting items from C:\Users\biagi\.fastai\data\oxford-iiit-pet\images
Found 7390 items
2 datasets of sizes 5912,1478
Setting up Pipeline: PILBase.create
Setting up Pipeline: partial -&gt; Categorize -- {&#39;vocab&#39;: None, &#39;sort&#39;: True, &#39;add_na&#39;: False}

Building one sample
  Pipeline: PILBase.create
    starting from
      C:\Users\biagi\.fastai\data\oxford-iiit-pet\images\saint_bernard_138.jpg
    applying PILBase.create gives
      PILImage mode=RGB size=500x375
  Pipeline: partial -&gt; Categorize -- {&#39;vocab&#39;: None, &#39;sort&#39;: True, &#39;add_na&#39;: False}
    starting from
      C:\Users\biagi\.fastai\data\oxford-iiit-pet\images\saint_bernard_138.jpg
    applying partial gives
      saint_bernard
    applying Categorize -- {&#39;vocab&#39;: None, &#39;sort&#39;: True, &#39;add_na&#39;: False} gives
      TensorCategory(30)

Final sample: (PILImage mode=RGB size=500x375, TensorCategory(30))


Collecting items from C:\Users\biagi\.fastai\data\oxford-iiit-pet\images
Found 7390 items
2 datasets of sizes 5912,1478
Setting up Pipeline: PILBase.create
Setting up Pipeline: partial -&gt; Categorize -- {&#39;vocab&#39;: None, &#39;sort&#39;: True, &#39;add_na&#39;: False}
Setting up after_item: Pipeline: Resize -- {&#39;size&#39;: (460, 460), &#39;method&#39;: &#39;crop&#39;, &#39;pad_mode&#39;: &#39;reflection&#39;, &#39;resamples&#39;: (&lt;Resampling.BILINEAR: 2&gt;, &lt;Resampling.NEAREST: 0&gt;), &#39;p&#39;: 1.0} -&gt; ToTensor
Setting up before_batch: Pipeline: 
Setting up after_batch: Pipeline: IntToFloatTensor -- {&#39;div&#39;: 255.0, &#39;div_mask&#39;: 1} -&gt; Flip -- {&#39;size&#39;: None, &#39;mode&#39;: &#39;bilinear&#39;, &#39;pad_mode&#39;: &#39;reflection&#39;, &#39;mode_mask&#39;: &#39;nearest&#39;, &#39;align_corners&#39;: True, &#39;p&#39;: 0.5} -&gt; RandomResizedCropGPU -- {&#39;size&#39;: (224, 224), &#39;min_scale&#39;: 0.75, &#39;ratio&#39;: (1, 1), &#39;mode&#39;: &#39;bilinear&#39;, &#39;valid_scale&#39;: 1.0, &#39;max_scale&#39;: 1.0, &#39;mode_mask&#39;: &#39;nearest&#39;, &#39;p&#39;: 1.0} -&gt; Brightness -- {&#39;max_lighting&#39;: 0.2, &#39;p&#39;: 1.0, &#39;draw&#39;: None, &#39;batch&#39;: False}
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Building one batch
Applying item_tfms to the first sample:
  Pipeline: Resize -- {&#39;size&#39;: (460, 460), &#39;method&#39;: &#39;crop&#39;, &#39;pad_mode&#39;: &#39;reflection&#39;, &#39;resamples&#39;: (&lt;Resampling.BILINEAR: 2&gt;, &lt;Resampling.NEAREST: 0&gt;), &#39;p&#39;: 1.0} -&gt; ToTensor
    starting from
      (PILImage mode=RGB size=500x375, TensorCategory(30))
    applying Resize -- {&#39;size&#39;: (460, 460), &#39;method&#39;: &#39;crop&#39;, &#39;pad_mode&#39;: &#39;reflection&#39;, &#39;resamples&#39;: (&lt;Resampling.BILINEAR: 2&gt;, &lt;Resampling.NEAREST: 0&gt;), &#39;p&#39;: 1.0} gives
      (PILImage mode=RGB size=460x460, TensorCategory(30))
    applying ToTensor gives
      (TensorImage of size 3x460x460, TensorCategory(30))

Adding the next 3 samples

No before_batch transform to apply

Collating items in a batch

Applying batch_tfms to the batch built
  Pipeline: IntToFloatTensor -- {&#39;div&#39;: 255.0, &#39;div_mask&#39;: 1} -&gt; Flip -- {&#39;size&#39;: None, &#39;mode&#39;: &#39;bilinear&#39;, &#39;pad_mode&#39;: &#39;reflection&#39;, &#39;mode_mask&#39;: &#39;nearest&#39;, &#39;align_corners&#39;: True, &#39;p&#39;: 0.5} -&gt; RandomResizedCropGPU -- {&#39;size&#39;: (224, 224), &#39;min_scale&#39;: 0.75, &#39;ratio&#39;: (1, 1), &#39;mode&#39;: &#39;bilinear&#39;, &#39;valid_scale&#39;: 1.0, &#39;max_scale&#39;: 1.0, &#39;mode_mask&#39;: &#39;nearest&#39;, &#39;p&#39;: 1.0} -&gt; Brightness -- {&#39;max_lighting&#39;: 0.2, &#39;p&#39;: 1.0, &#39;draw&#39;: None, &#39;batch&#39;: False}
    starting from
      (TensorImage of size 4x3x460x460, TensorCategory([30,  8, 31, 23]))
    applying IntToFloatTensor -- {&#39;div&#39;: 255.0, &#39;div_mask&#39;: 1} gives
      (TensorImage of size 4x3x460x460, TensorCategory([30,  8, 31, 23]))
    applying Flip -- {&#39;size&#39;: None, &#39;mode&#39;: &#39;bilinear&#39;, &#39;pad_mode&#39;: &#39;reflection&#39;, &#39;mode_mask&#39;: &#39;nearest&#39;, &#39;align_corners&#39;: True, &#39;p&#39;: 0.5} gives
      (TensorImage of size 4x3x460x460, TensorCategory([30,  8, 31, 23]))
    applying RandomResizedCropGPU -- {&#39;size&#39;: (224, 224), &#39;min_scale&#39;: 0.75, &#39;ratio&#39;: (1, 1), &#39;mode&#39;: &#39;bilinear&#39;, &#39;valid_scale&#39;: 1.0, &#39;max_scale&#39;: 1.0, &#39;mode_mask&#39;: &#39;nearest&#39;, &#39;p&#39;: 1.0} gives
      (TensorImage of size 4x3x224x224, TensorCategory([30,  8, 31, 23]))
    applying Brightness -- {&#39;max_lighting&#39;: 0.2, &#39;p&#39;: 1.0, &#39;draw&#39;: None, &#39;batch&#39;: False} gives
      (TensorImage of size 4x3x224x224, TensorCategory([30,  8, 31, 23]))
</pre></div>
</div>
</div>
</div>
</section>
<section id="training-the-model">
<h2>Training the Model<a class="headerlink" href="#training-the-model" title="Link to this heading">#</a></h2>
<p>Now that our data is ready, we can proceed to training. We’ll use a pretrained ResNet34 model from fastai’s vision library. This model will be fine-tuned for our specific task of classifying pet breeds.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">learn</span> <span class="o">=</span> <span class="n">vision_learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">resnet18</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">error_rate</span><span class="p">)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fine_tune</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div><div class="output text_html">
    <div>
      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>
      0.00% [0/1 00:00&lt;?]
    </div>
    
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>error_rate</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
  </tbody>
</table><p>

    <div>
      <progress value='7' class='' max='92' style='width:300px; height:20px; vertical-align: middle;'></progress>
      7.61% [7/92 00:28&lt;05:45 5.1933]
    </div>
    </div></div>
</div>
<section id="understanding-cross-entropy-loss">
<h3>Understanding Cross-Entropy Loss<a class="headerlink" href="#understanding-cross-entropy-loss" title="Link to this heading">#</a></h3>
<p>In multi-class classification, the cross-entropy loss function, also known as log loss, is commonly used. For each image <span class="math notranslate nohighlight">\( X \)</span> with a true label <span class="math notranslate nohighlight">\( y \)</span>, the loss is given by:</p>
<div class="math notranslate nohighlight">
\[
\text{Loss} = - \sum_{i=1}^C y_i \log(p_i)
\]</div>
<p>where <span class="math notranslate nohighlight">\( C \)</span> is the number of classes, <span class="math notranslate nohighlight">\( y_i \)</span> is the true probability (0 or 1) for class <span class="math notranslate nohighlight">\( i \)</span>, and <span class="math notranslate nohighlight">\( p_i \)</span> is the predicted probability for class <span class="math notranslate nohighlight">\( i \)</span>. Cross-entropy encourages the model to output high probabilities for the correct class, penalizing incorrect predictions.</p>
</section>
</section>
<section id="interpreting-the-model">
<h2>Interpreting the Model<a class="headerlink" href="#interpreting-the-model" title="Link to this heading">#</a></h2>
<p>After training, it’s helpful to interpret the model’s performance to understand areas of improvement. A confusion matrix is useful for identifying patterns in misclassifications.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">interp</span> <span class="o">=</span> <span class="n">ClassificationInterpretation</span><span class="o">.</span><span class="n">from_learner</span><span class="p">(</span><span class="n">learn</span><span class="p">)</span>
<span class="n">interp</span><span class="o">.</span><span class="n">plot_confusion_matrix</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">12</span><span class="p">),</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">60</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div><div class="output text_html">
    <div>
      <progress value='0' class='' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>
      0.00% [0/24 00:00&lt;?]
    </div>
    </div><div class="output text_html">
<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div><div class="output text_html"></div><img alt="../_images/b414246b94a4d85f4764f5a1c649462fcc745b8ad3c9ada9230d2f44ba24cf22.png" src="../_images/b414246b94a4d85f4764f5a1c649462fcc745b8ad3c9ada9230d2f44ba24cf22.png" />
</div>
</div>
<p>When dealing with a large number of classes, as in this case with 37 breeds, the confusion matrix can become complex. The <code class="docutils literal notranslate"><span class="pre">most_confused</span></code> method highlights the most common errors:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">interp</span><span class="o">.</span><span class="n">most_confused</span><span class="p">(</span><span class="n">min_val</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div><div class="output text_html"></div><div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[(&#39;Egyptian_Mau&#39;, &#39;Bengal&#39;, 10),
 (&#39;Russian_Blue&#39;, &#39;British_Shorthair&#39;, 5),
 (&#39;Siamese&#39;, &#39;Birman&#39;, 5)]
</pre></div>
</div>
</div>
</div>
<p>This output shows which breeds the model often confuses, providing insights into areas needing improvement.</p>
</section>
<section id="improving-the-model">
<h2>Improving the Model<a class="headerlink" href="#improving-the-model" title="Link to this heading">#</a></h2>
<section id="the-learning-rate">
<h3>The Learning Rate<a class="headerlink" href="#the-learning-rate" title="Link to this heading">#</a></h3>
<p>The learning rate <span class="math notranslate nohighlight">\( \eta \)</span> controls the step size in the gradient descent optimization process. At each training step, the model updates its weights <span class="math notranslate nohighlight">\( w \)</span> in the opposite direction of the gradient <span class="math notranslate nohighlight">\( \nabla L(w) \)</span> of the loss function <span class="math notranslate nohighlight">\( L \)</span> with respect to the weights. This update rule is:</p>
<div class="math notranslate nohighlight">
\[
w_{i+1} = w_i - \eta \nabla L(w_i)
\]</div>
<p>If <span class="math notranslate nohighlight">\( \eta \)</span> is too large, the model may overshoot the optimal weights, causing unstable training. If <span class="math notranslate nohighlight">\( \eta \)</span> is too small, training may take too long to converge. The optimal learning rate is usually found by experimenting or using a learning rate finder.</p>
</section>
<section id="learning-rate-finder">
<h3>Learning Rate Finder<a class="headerlink" href="#learning-rate-finder" title="Link to this heading">#</a></h3>
<p>The learning rate finder in fastai allows us to identify a suitable learning rate by gradually increasing it and observing the effect on the loss. Here’s how to apply it:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">lr_min</span><span class="p">,</span> <span class="n">lr_steep</span> <span class="o">=</span> <span class="n">learn</span><span class="o">.</span><span class="n">lr_find</span><span class="p">(</span><span class="n">suggest_funcs</span><span class="o">=</span><span class="p">(</span><span class="n">minimum</span><span class="p">,</span> <span class="n">steep</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Minimum/10: </span><span class="si">{</span><span class="n">lr_min</span><span class="si">:</span><span class="s2">.2e</span><span class="si">}</span><span class="s2">, steepest point: </span><span class="si">{</span><span class="n">lr_steep</span><span class="si">:</span><span class="s2">.2e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div><div class="output text_html"></div><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>c:\Users\biagi\anaconda3\envs\book\Lib\site-packages\fastai\learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don&#39;t have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state = torch.load(file, map_location=device, **torch_load_kwargs)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Minimum/10: 1.32e-05, steepest point: 6.31e-07
</pre></div>
</div>
<img alt="../_images/08b7249742937b1dd4ae310b7e49d29b1c2e43ca091409c99ad4078911076019.png" src="../_images/08b7249742937b1dd4ae310b7e49d29b1c2e43ca091409c99ad4078911076019.png" />
</div>
</div>
<blockquote>
<div><p>Note: Logarithmic Scale: The learning rate finder plot has a logarithmic scale, which is why the middle point between 1e-3 and 1e-2 is between 3e-3 and 4e-3. This is because we care mostly about the order of magnitude of the learning rate.</p>
</div></blockquote>
<p>The learning rate plot helps identify a rate that minimizes loss without diverging. Choose a rate slightly lower than the minimum or steepest point, around 3e-3 in this case.</p>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="fine-tuning-and-transfer-learning">
<h1>Fine-Tuning and Transfer Learning<a class="headerlink" href="#fine-tuning-and-transfer-learning" title="Link to this heading">#</a></h1>
<section id="concept-of-transfer-learning">
<h2>Concept of Transfer Learning<a class="headerlink" href="#concept-of-transfer-learning" title="Link to this heading">#</a></h2>
<p>Transfer learning leverages a pretrained model on a related dataset to improve performance on a new task. For instance, in medical image analysis, a model pretrained on ImageNet might provide useful feature representations for a new dataset of MRI images. When fine-tuning, we typically:</p>
<p>Freeze earlier layers to retain generic features like edge and shape detectors.
Unfreeze later layers, allowing the model to adapt to specific features relevant to the new dataset.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">unfreeze</span><span class="p">()</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">lr_max</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div><div class="output text_html"><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>error_rate</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.284875</td>
      <td>0.234757</td>
      <td>0.075101</td>
      <td>07:09</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.268512</td>
      <td>0.227902</td>
      <td>0.070365</td>
      <td>07:12</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0.269002</td>
      <td>0.227186</td>
      <td>0.071042</td>
      <td>07:15</td>
    </tr>
    <tr>
      <td>3</td>
      <td>0.249046</td>
      <td>0.223080</td>
      <td>0.070365</td>
      <td>07:20</td>
    </tr>
  </tbody>
</table></div></div>
</div>
<p>Transfer learning is particularly useful in biomedical contexts where data can be scarce, such as in diagnosing rare diseases. Pretrained models on large datasets capture general image characteristics, while fine-tuning helps adapt the model to detect subtle differences relevant to the specific disease.</p>
</section>
<section id="discriminative-learning-rates">
<h2>Discriminative Learning Rates<a class="headerlink" href="#discriminative-learning-rates" title="Link to this heading">#</a></h2>
<p>Different layers in a neural network can benefit from varied learning rates. Earlier layers, which capture more general features, should have lower rates, while later layers can use higher rates to adapt to the new task.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">lr_max</span><span class="o">=</span><span class="nb">slice</span><span class="p">(</span><span class="mf">1e-6</span><span class="p">,</span> <span class="mf">1e-4</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div><div class="output text_html"><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>error_rate</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.246748</td>
      <td>0.224052</td>
      <td>0.071719</td>
      <td>07:29</td>
    </tr>
  </tbody>
</table></div></div>
</div>
</section>
<section id="using-deeper-architectures">
<h2>Using Deeper Architectures<a class="headerlink" href="#using-deeper-architectures" title="Link to this heading">#</a></h2>
<p>Increasing model depth can help capture complex patterns. The ResNet architecture, used here in its 50-layer variant, is commonly used for image tasks. We’ll also use <em>mixed-precision training</em> for faster and more efficient processing.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">fastai.callback.fp16</span> <span class="kn">import</span> <span class="o">*</span>
<span class="n">learn</span> <span class="o">=</span> <span class="n">vision_learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">resnet34</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">error_rate</span><span class="p">)</span><span class="o">.</span><span class="n">to_fp16</span><span class="p">()</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fine_tune</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="n">freeze_epochs</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>c:\Users\biagi\anaconda3\envs\book\Lib\site-packages\fastai\callback\fp16.py:47: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast(&#39;cuda&#39;, args...)` instead.
  self.autocast,self.learn.scaler,self.scales = autocast(dtype=dtype),GradScaler(**self.kwargs),L()
c:\Users\biagi\anaconda3\envs\book\Lib\site-packages\torch\amp\autocast_mode.py:265: UserWarning: User provided device_type of &#39;cuda&#39;, but CUDA is not available. Disabling
  warnings.warn(
c:\Users\biagi\anaconda3\envs\book\Lib\site-packages\fastai\callback\fp16.py:47: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler(&#39;cuda&#39;, args...)` instead.
  self.autocast,self.learn.scaler,self.scales = autocast(dtype=dtype),GradScaler(**self.kwargs),L()
c:\Users\biagi\anaconda3\envs\book\Lib\site-packages\torch\amp\grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.
  warnings.warn(
</pre></div>
</div>
<div class="output text_html">
<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div><div class="output text_html"><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>error_rate</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>2.544297</td>
      <td>0.550967</td>
      <td>0.165765</td>
      <td>08:47</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.908935</td>
      <td>0.275755</td>
      <td>0.095399</td>
      <td>08:47</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0.529911</td>
      <td>0.263721</td>
      <td>0.085927</td>
      <td>08:48</td>
    </tr>
  </tbody>
</table></div><div class="output text_html">
<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div><div class="output text_html"><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>error_rate</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.356789</td>
      <td>0.251893</td>
      <td>0.079161</td>
      <td>11:44</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.329284</td>
      <td>0.285859</td>
      <td>0.092693</td>
      <td>12:05</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0.286786</td>
      <td>0.246736</td>
      <td>0.075101</td>
      <td>12:15</td>
    </tr>
    <tr>
      <td>3</td>
      <td>0.203805</td>
      <td>0.232188</td>
      <td>0.071042</td>
      <td>12:47</td>
    </tr>
    <tr>
      <td>4</td>
      <td>0.134884</td>
      <td>0.206825</td>
      <td>0.063599</td>
      <td>13:26</td>
    </tr>
    <tr>
      <td>5</td>
      <td>0.088163</td>
      <td>0.196916</td>
      <td>0.060217</td>
      <td>14:49</td>
    </tr>
  </tbody>
</table></div></div>
</div>
<p>In this example, mixed-precision training enables tensor cores on compatible GPUs, leading to faster training with less memory use.</p>
</section>
<section id="further-optimization-selecting-epochs-and-avoiding-overfitting">
<h2>Further Optimization: Selecting Epochs and Avoiding Overfitting<a class="headerlink" href="#further-optimization-selecting-epochs-and-avoiding-overfitting" title="Link to this heading">#</a></h2>
<p>Choosing the number of epochs is a balancing act. Too few epochs can result in underfitting, while too many can lead to overfitting. Here are some general guidelines:</p>
<ul class="simple">
<li><p>Start with a few epochs to see baseline performance.</p></li>
<li><p>Monitor validation loss and accuracy over epochs to determine when the model starts overfitting.</p></li>
<li><p>Use early stopping or cross-validation if needed.</p></li>
</ul>
<p>If training resources allow, try experimenting with larger models or deeper architectures. However, always validate if additional complexity improves your specific task.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./chapters"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="24_Loss_Metrics_and_Optimizers.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Training a Digit Classifier</p>
      </div>
    </a>
    <a class="right-next"
       href="26_convolutions.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Convolutional Neural Networks</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Image Classification</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pet-breeds-data">Pet Breeds Data</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#understanding-data-layout">Understanding Data Layout</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#inspecting-image-files">Inspecting Image Files</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#extracting-labels-using-regular-expressions">Extracting Labels Using Regular Expressions</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#building-the-datablock">Building the DataBlock</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#explanation-of-the-datablock-parameters">Explanation of the <code class="docutils literal notranslate"><span class="pre">DataBlock</span></code> Parameters</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-augmentation-and-presizing">Data Augmentation and Presizing</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#presizing">Presizing</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#validating-the-data-pipeline">Validating the Data Pipeline</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training-the-model">Training the Model</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#understanding-cross-entropy-loss">Understanding Cross-Entropy Loss</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#interpreting-the-model">Interpreting the Model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#improving-the-model">Improving the Model</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-learning-rate">The Learning Rate</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#learning-rate-finder">Learning Rate Finder</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#fine-tuning-and-transfer-learning">Fine-Tuning and Transfer Learning</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#concept-of-transfer-learning">Concept of Transfer Learning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#discriminative-learning-rates">Discriminative Learning Rates</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#using-deeper-architectures">Using Deeper Architectures</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#further-optimization-selecting-epochs-and-avoiding-overfitting">Further Optimization: Selecting Epochs and Avoiding Overfitting</a></li>
</ul>
</li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Biagio Mandracchia
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>