
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Deep Learning in Biomedical Engineering &#8212; Introduction to Machine Learning for Biomedical Data</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b76e3c8a" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'chapters/21_neural networks';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Neural Networks as Universal Approximators" href="23_NN_as_UA.html" />
    <link rel="prev" title="Nonlinear Manifold Feature Extraction" href="17_kmeans.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="Introduction to Machine Learning for Biomedical Data - Home"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="Introduction to Machine Learning for Biomedical Data - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Computational Tools</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="01_python_primer.html">Python: a Primer</a></li>
<li class="toctree-l1"><a class="reference internal" href="02_data_science_with_pandas.html">Data Science with Python and Pandas</a></li>
<li class="toctree-l1"><a class="reference internal" href="03_jupyter_markdown.html">Jupyter &amp; Markdown</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Feature Engineering</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="11_machine_learning_fundamentals.html">The Machine Learning Fundamentals</a></li>
<li class="toctree-l1"><a class="reference internal" href="12_basic_feature_engineering.html">Basic Feature Engineering</a></li>
<li class="toctree-l1"><a class="reference internal" href="13_categorical_variables.html">Categorical Variables</a></li>
<li class="toctree-l1"><a class="reference internal" href="14_classifiers.html">Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="15_decision_trees.html">Decision Trees</a></li>
<li class="toctree-l1"><a class="reference internal" href="16_dimensionality_reduction.html">Dimensionality Reduction: PCA</a></li>
<li class="toctree-l1"><a class="reference internal" href="17_kmeans.html">Nonlinear Manifold Feature Extraction</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Deep Learning</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Deep Learning in Biomedical Engineering</a></li>
<li class="toctree-l1"><a class="reference internal" href="23_NN_as_UA.html">Neural Networks as Universal Approximators</a></li>
<li class="toctree-l1"><a class="reference internal" href="24_Loss_Metrics_and_Optimizers.html">Training a Digit Classifier</a></li>
<li class="toctree-l1"><a class="reference internal" href="25_Image_Classification.html">Image Classification</a></li>

<li class="toctree-l1"><a class="reference internal" href="26_convolutions.html">Convolutional Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="27_resnet2.html">ResNets for Biomedical Image Analysis</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/bmandracchia/ML4BD" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/bmandracchia/ML4BD/issues/new?title=Issue%20on%20page%20%2Fchapters/21_neural networks.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/chapters/21_neural networks.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Deep Learning in Biomedical Engineering</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#neural-networks-a-brief-history">Neural Networks: A Brief History</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-to-learn-deep-learning">How to Learn Deep Learning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-software">The Software</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-a-neural-network">What Is a Neural Network?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#limitations-inherent-to-machine-learning">Limitations Inherent to Machine Learning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-our-medical-image-recognizer-works">How Our Medical Image Recognizer Works</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-neural-networks-make-predictions">How Neural Networks Make Predictions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#improving-the-model">Improving the Model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluating-model-performance">Evaluating Model Performance</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#limitations-and-ethical-considerations">Limitations and Ethical Considerations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#handling-overfitting">Handling Overfitting</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#transfer-learning">Transfer Learning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#deploying-the-model-for-real-world-use">Deploying the Model for Real-World Use</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#validation-sets-and-test-sets">Validation Sets and Test Sets</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#hide</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
</div>
<section id="deep-learning-in-biomedical-engineering">
<h1>Deep Learning in Biomedical Engineering<a class="headerlink" href="#deep-learning-in-biomedical-engineering" title="Link to this heading">#</a></h1>
<p>Deep learning, a subset of machine learning, has revolutionized numerous fields, including biomedical engineering. By enabling models to automatically learn representations from large datasets, deep learning has become pivotal in applications such as medical image analysis, drug discovery, and patient monitoring. With its ability to handle complex patterns in data, deep learning is increasingly being used to solve critical healthcare challenges, from early disease detection to personalized medicine.</p>
<p>Deep learning is a computational method that extracts and transforms data through the use of multiple layers of neural networks. In biomedical engineering, it has been applied to areas such as recognizing patterns in medical imaging (e.g., MRI or CT scans) or analyzing gene expression data. Each neural network layer processes inputs from the previous one, progressively refining and improving the output. The layers are trained using algorithms that minimize error and improve accuracy, enabling the network to perform tasks such as diagnosing diseases or predicting patient outcomes. We will discuss training algorithms in detail in the next section.</p>
<p>Some of the tasks in different areas where deep learning is now leading the world, particularly in biomedical engineering and healthcare:</p>
<ul class="simple">
<li><p>Natural Language Processing (NLP): Extracting key information from medical records; summarizing clinical notes; automated speech recognition for medical dictation; question-answering systems for clinical decision support.</p></li>
<li><p>Medical Imaging: Detecting anomalies in radiology images, including CT, MRI, and X-ray scans; quantifying features in pathology slides; measuring anatomical structures in ultrasounds; diagnosing diabetic retinopathy and other conditions from retinal images.</p></li>
<li><p>Genomics and Proteomics: Predicting protein structures (e.g., AlphaFold); classifying proteins based on sequence; analyzing tumor-normal sequencing for cancer research; identifying clinically actionable genetic mutations; classifying cells in microscopy images.</p></li>
<li><p>Image Generation: Enhancing medical images by increasing resolution; removing noise from MRI or ultrasound images; generating synthetic medical data for training purposes.</p></li>
<li><p>Recommendation Systems: Recommending personalized treatment options; identifying clinical trials for patients based on their genetic and medical history.</p></li>
<li><p>Robotics: Assisting in robotic surgeries; automating medical laboratory tasks like handling biological samples; improving precision in drug delivery systems.</p></li>
<li><p>Other Applications: Predicting disease progression; forecasting hospital resource allocation; converting text to speech for assisting visually impaired patients, and many more.</p></li>
</ul>
<p>What is remarkable about deep learning is its versatility across so many applications, yet nearly all of these advancements are built on a single type of model: the neural network. In the biomedical field, neural networks are at the core of systems used for diagnosing diseases from medical images, predicting patient outcomes, and even designing personalized treatment plans. The power of this model lies in its ability to learn complex patterns from vast amounts of healthcare data, whether from imaging, genomics, or patient monitoring systems.</p>
<section id="neural-networks-a-brief-history">
<h2>Neural Networks: A Brief History<a class="headerlink" href="#neural-networks-a-brief-history" title="Link to this heading">#</a></h2>
<p>Neural networks, a foundational component of deep learning, have a long history that stretches back to the mid-20th century. Initially inspired by the architecture of the human brain, neural networks have evolved to become one of the most powerful tools in artificial intelligence. Thanks to their ability to learn complex, non-linear relationships,  in biomedical engineering neural networks are used to analyze complex medical datasets, such as those from MRI or CT scans, to detect patterns that can aid in diagnosing diseases. One prominent example is the use of neural networks for early detection of Alzheimer’s Disease, where MRI images are processed to identify early signs of brain degeneration.</p>
<p>In 1943, Warren McCulloch, a neurophysiologist, and Walter Pitts, a logician, collaborated to develop a mathematical model of an artificial neuron. Their foundational paper, A Logical Calculus of the Ideas Immanent in Nervous Activity, proposed that:</p>
<blockquote>
<div><p>Because of the “all-or-none” nature of nervous activity, neural events and their relations can be modeled using propositional logic. The behavior of every neural network can be described using these terms.</p>
</div></blockquote>
<p>This early work laid the foundation for modern neural networks, which now drive many biomedical innovations, such as interpreting brain activity, diagnosing neurological diseases, and aiding in cognitive rehabilitation.</p>
<p>McCulloch and Pitts recognized that a simplified model of a biological neuron could be represented using basic mathematical operations, such as addition and thresholding. This model mimicked the behavior of neurons in the brain, where inputs from various sources are combined, and an output is triggered only if a certain threshold is reached. Today, this concept forms the basis of artificial neural networks used in a variety of biomedical applications, from analyzing neural activity to developing brain-computer interfaces.</p>
<p><img alt="image.png" src="chapters/attachment:image.png" /></p>
<p>Rosenblatt advanced the concept of the artificial neuron by giving it the ability to learn. He also built the first device to implement these principles, the Mark I Perceptron. However, in their book <em>Perceptrons</em> (MIT Press), Minsky and Papert demonstrated that a single-layer perceptron was unable to learn certain fundamental mathematical functions (like XOR). They also noted that using multiple layers could overcome these limitations, although only the former insight gained wide attention. This led to a significant decline in research on neural networks for the next two decades. Despite this, modern deep learning, especially in biomedical fields like medical imaging and genomics, relies heavily on multi-layered neural networks to address complex healthcare problems.</p>
<p>Perhaps the most pivotal work in neural networks over the last 50 years was the multi-volume <em>Parallel Distributed Processing</em> (PDP) by David Rumelhart, James McClellan, and the PDP Research Group, released in 1986. Chapter 1 expresses hope similar to that of Rosenblatt:</p>
<blockquote>
<div><p>People are smarter than today’s computers because the brain employs a basic computational architecture that is more suited to deal with a central aspect of natural information processing tasks. We will introduce a computational framework for modeling cognitive processes that seems closer than other frameworks to the style of computation done by the brain.</p>
</div></blockquote>
<p>This premise suggests that traditional computing methods are fundamentally different from how brains operate, and this might explain why computers have struggled to perform tasks, such as recognizing objects in images, which the brain handles effortlessly. In the field of biomedical engineering, this idea has driven the development of neural networks that can analyze brain activity, diagnose neurological conditions, and improve understanding of cognitive processes.</p>
<p>In fact, the approach outlined in Parallel Distributed Processing (PDP) is strikingly similar to the neural networks we use today, especially in biomedical applications. PDP defined parallel distributed processing using several key components:</p>
<ul class="simple">
<li><p>A set of <strong>processing units</strong> (neurons, both biological and artificial).</p></li>
<li><p>A <strong>state of activation</strong> (whether the neuron is “firing” or active).</p></li>
<li><p>An <strong>output function</strong> for each unit (how much the neuron is activated).</p></li>
<li><p>A <strong>pattern of connectivity</strong> among units (similar to the brain’s synaptic connections).</p></li>
<li><p>A <strong>propagation rule</strong> for transmitting patterns of activity through the network (similar to the brain’s signal transmission).</p></li>
<li><p>An <strong>activation rule</strong> for combining inputs and determining the output (mimicking neuron signal processing).</p></li>
<li><p>A <strong>learning rule</strong> to adjust the connections based on experience (similar to synaptic plasticity in the brain).</p></li>
<li><p>An <strong>environment</strong> within which the system operates (such as data from medical images, genomics, or real-time patient monitoring).</p></li>
</ul>
<p>These concepts have greatly influenced modern deep learning approaches in healthcare, particularly for applications like medical image analysis, predicting disease progression, and understanding neural processes.</p>
<p>Although researchers demonstrated over 30 years ago that practical neural networks need more than two layers to achieve good performance, this insight has only recently been fully appreciated and applied. Today, neural networks are finally realizing their potential, especially in biomedical fields, due to the use of deeper networks, advances in computer hardware, increased availability of medical data, and algorithmic improvements that make it easier to train neural networks quickly and efficiently. These developments have enabled breakthroughs in areas such as automated medical diagnosis, drug discovery, and patient-specific treatment planning.</p>
</section>
<section id="how-to-learn-deep-learning">
<h2>How to Learn Deep Learning<a class="headerlink" href="#how-to-learn-deep-learning" title="Link to this heading">#</a></h2>
<p>Learning deep learning is an essential skill for solving complex biomedical problems. From analyzing vast datasets of patient records to developing predictive models for disease progression, deep learning is becoming a vital tool for biomedical engineers. This section will guide you through the essential concepts, tools, and resources to help you become proficient in applying deep learning techniques to real-world healthcare challenges.</p>
<p>The most challenging part of deep learning is practical: How do you ensure you have enough medical data? Is it in the correct format? Is your model training correctly? If not, how do you fix it? This is why learning by doing is essential. In biomedical engineering, hands-on experience with real datasets—such as patient records, imaging data, or genomic sequences—will improve your skills faster than purely focusing on theory. Solving real healthcare problems through coding will provide the necessary context and motivation to dive deeper into the theoretical aspects later.</p>
</section>
<section id="the-software">
<h2>The Software<a class="headerlink" href="#the-software" title="Link to this heading">#</a></h2>
<p>To effectively implement deep learning models in biomedical engineering, it’s essential to use the right tools. PyTorch, fastai, and Jupyter Notebooks are powerful, open-source software platforms that simplify the development of deep learning models.</p>
<p>PyTorch has become the go-to framework for research and prototyping. Its dynamic computation graph (define-by-run) allows for easier debugging and a more intuitive workflow, which has made it particularly popular in academia and among researchers, including in biomedical fields. PyTorch is favored for quick experimentation and flexibility, making it a dominant player in state-of-the-art model development and research papers. For example, it is extensively used in cutting-edge tasks like medical image analysis and cancer research.</p>
<p>Since its release in 2017, PyTorch has become the fastest-growing deep learning library and is widely used in top research papers, including many in biomedical engineering. This trend often indicates future industry adoption, as these innovations are eventually integrated into healthcare products and services. PyTorch excels as a low-level foundation for deep learning, providing essential operations that power applications like medical image analysis and predictive modeling. The fastai library enhances PyTorch by adding high-level functionality, making it easier for researchers and engineers to develop complex models, such as those used in diagnosing diseases or analyzing biomedical signals.</p>
<p><img alt="image.png" src="chapters/attachment:image.png" /></p>
<p>Fastai builds on PyTorch, providing an easy-to-use framework for rapidly developing models, while Jupyter Notebooks allow you to combine code, data visualization, and documentation seamlessly in one place, making them ideal for biomedical research projects.</p>
<p>While the choice of software (e.g., PyTorch, TensorFlow) isn’t crucial, as switching between libraries is relatively easy, mastering the foundations and techniques of deep learning is what truly matters—especially in biomedical engineering. Whether you are developing models to predict disease progression, analyze medical images, or discover new drugs, understanding the core principles is key. In this course, we will focus on writing code that clearly illustrates the deep learning concepts you need to learn for practical applications in healthcare.</p>
</section>
<section id="what-is-a-neural-network">
<h2>What Is a Neural Network?<a class="headerlink" href="#what-is-a-neural-network" title="Link to this heading">#</a></h2>
<p>If we regard a neural network as a mathematical function, it is incredibly flexible depending on its weights. According to the <em>universal approximation theorem</em>, a neural network can theoretically solve any problem to any level of accuracy. This flexibility makes neural networks particularly suited for solving complex biomedical problems, such as detecting skin lesions or analyzing genomic sequences. The key challenge lies in training the network effectively, which involves finding the right weight assignments for the model.</p>
<p>Thankfully, we don’t need a new mechanism for adjusting the weights for every task. Instead, <em>stochastic gradient descent</em> (SGD) allows us to automatically update the weights and improve the model for any given task, such as classifying medical images or predicting patient outcomes.</p>
</section>
<section id="limitations-inherent-to-machine-learning">
<h2>Limitations Inherent to Machine Learning<a class="headerlink" href="#limitations-inherent-to-machine-learning" title="Link to this heading">#</a></h2>
<p>Based on this understanding, we can highlight some fundamental aspects of training a deep learning model, particularly in biomedical applications:</p>
<ul class="simple">
<li><p>A model cannot be created without data.</p></li>
<li><p>A model can only learn to recognize the patterns seen in the input data used during training.</p></li>
<li><p>This learning approach generates <strong>predictions</strong>, not recommended <strong>actions</strong> (e.g., diagnosing a skin lesion, but not determining treatment).</p></li>
<li><p>It’s not enough to have just examples of input data; we also need <strong>labels</strong> for that data. For example, having images of skin lesions isn’t enough to train a model—each image needs to be labeled with information such as whether it indicates a benign or malignant condition.</p></li>
</ul>
<p>In healthcare, many organizations claim they don’t have enough data, but in reality, they often lack enough <strong>labeled</strong> data. For instance, dermatology clinics may have archives of skin lesion images, but these images might not have structured labels, as clinicians often provide free-text reports.</p>
<p><img alt="image.png" src="chapters/attachment:image.png" /></p>
<p>Another critical insight comes from considering how a model interacts with its environment, particularly in healthcare settings. This interaction can create a <strong>positive feedback loop</strong>, where the more the model is used, the more biased the data becomes, potentially leading to even more biased predictions. For example, if a model trained on limited or biased patient demographics is used in a clinic, its predictions may reinforce existing biases in diagnosis, which can negatively affect patient care.</p>
</section>
<section id="how-our-medical-image-recognizer-works">
<h2>How Our Medical Image Recognizer Works<a class="headerlink" href="#how-our-medical-image-recognizer-works" title="Link to this heading">#</a></h2>
<p>In this section, we will build and fine-tune a medical image recognizer that can classify colon pathologies from histology slides using the MedMNIST Dataset.</p>
<p>The following code will provide:</p>
<ol class="arabic simple">
<li><p>A <strong>dataset</strong>, which contains thousands of images of cancer histology slides labeled for colon pathology detection, will be downloaded to your local machine and extracted.</p></li>
<li><p>A <strong>pretrained model</strong> that has already been trained on large-scale medical imaging datasets will be downloaded from the internet.</p></li>
<li><p>The pretrained model will be <strong>fine-tuned</strong> using transfer learning, creating a model specially customized for recognizing specific diseases, such as pneumonia or lung abnormalities, from chest X-rays.</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">fastai.vision.all</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">import</span> <span class="nn">medmnist</span>

<span class="c1"># Choose a specific MedMNIST dataset (e.g., &#39;pathmnist&#39;)</span>
<span class="n">data_flag</span> <span class="o">=</span> <span class="s1">&#39;pathmnist&#39;</span>
<span class="n">download</span> <span class="o">=</span> <span class="kc">True</span>

<span class="c1"># Ensure the target folder exists</span>
<span class="n">path</span> <span class="o">=</span> <span class="s1">&#39;./datasets/ch8&#39;</span>
<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Load the chosen MedMNIST dataset</span>
<span class="n">info</span> <span class="o">=</span> <span class="n">medmnist</span><span class="o">.</span><span class="n">INFO</span><span class="p">[</span><span class="n">data_flag</span><span class="p">]</span>
<span class="n">dataset_class</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">medmnist</span><span class="p">,</span> <span class="n">info</span><span class="p">[</span><span class="s1">&#39;python_class&#39;</span><span class="p">])</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">dataset_class</span><span class="p">(</span><span class="n">split</span><span class="o">=</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="n">download</span><span class="p">,</span> <span class="n">root</span><span class="o">=</span><span class="n">path</span><span class="p">)</span>
<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">dataset_class</span><span class="p">(</span><span class="n">split</span><span class="o">=</span><span class="s1">&#39;test&#39;</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="n">download</span><span class="p">,</span> <span class="n">root</span><span class="o">=</span><span class="n">path</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Using downloaded and verified file: ./datasets/ch8\pathmnist.npz
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Using downloaded and verified file: ./datasets/ch8\pathmnist.npz
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">fastai.vision.all</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">import</span> <span class="nn">medmnist</span>
<span class="kn">from</span> <span class="nn">medmnist</span> <span class="kn">import</span> <span class="n">INFO</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">transforms</span>

<span class="c1"># Choose a specific MedMNIST dataset (e.g., &#39;pathmnist&#39;)</span>
<span class="n">data_flag</span> <span class="o">=</span> <span class="s1">&#39;pathmnist&#39;</span>
<span class="n">download</span> <span class="o">=</span> <span class="kc">True</span>

<span class="c1"># Ensure the target folder exists</span>
<span class="n">path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s1">&#39;./datasets/ch8&#39;</span><span class="p">)</span>
<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Load the chosen MedMNIST dataset</span>
<span class="n">info</span> <span class="o">=</span> <span class="n">INFO</span><span class="p">[</span><span class="n">data_flag</span><span class="p">]</span>
<span class="n">dataset_class</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">medmnist</span><span class="p">,</span> <span class="n">info</span><span class="p">[</span><span class="s1">&#39;python_class&#39;</span><span class="p">])</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">dataset_class</span><span class="p">(</span><span class="n">split</span><span class="o">=</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="n">download</span><span class="p">,</span> <span class="n">root</span><span class="o">=</span><span class="n">path</span><span class="p">)</span>
<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">dataset_class</span><span class="p">(</span><span class="n">split</span><span class="o">=</span><span class="s1">&#39;test&#39;</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="n">download</span><span class="p">,</span> <span class="n">root</span><span class="o">=</span><span class="n">path</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Using downloaded and verified file: datasets\ch8\pathmnist.npz
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Using downloaded and verified file: datasets\ch8\pathmnist.npz
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create a function to convert MedMNIST dataset to Fastai&#39;s DataLoader</span>
<span class="k">def</span> <span class="nf">medmnist_to_fastai</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">test_dataset</span><span class="p">):</span>
    <span class="n">train_images</span><span class="p">,</span> <span class="n">train_labels</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">imgs</span><span class="p">,</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">labels</span>
    <span class="n">test_images</span><span class="p">,</span> <span class="n">test_labels</span> <span class="o">=</span> <span class="n">test_dataset</span><span class="o">.</span><span class="n">imgs</span><span class="p">,</span> <span class="n">test_dataset</span><span class="o">.</span><span class="n">labels</span>
    
    <span class="c1"># Convert images and labels into a DataFrame to work with Fastai&#39;s DataBlock</span>
    <span class="n">df_train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;image&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">Image</span><span class="o">.</span><span class="n">fromarray</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="s1">&#39;RGB&#39;</span><span class="p">)</span> <span class="k">for</span> <span class="n">img</span> <span class="ow">in</span> <span class="n">train_images</span><span class="p">],</span> 
                             <span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="n">train_labels</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()})</span>
    <span class="n">df_test</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;image&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">Image</span><span class="o">.</span><span class="n">fromarray</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="s1">&#39;RGB&#39;</span><span class="p">)</span> <span class="k">for</span> <span class="n">img</span> <span class="ow">in</span> <span class="n">test_images</span><span class="p">],</span> 
                            <span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="n">test_labels</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()})</span>
    
    <span class="k">return</span> <span class="n">df_train</span><span class="p">,</span> <span class="n">df_test</span>

<span class="c1"># Convert MedMNIST to DataFrame suitable for Fastai</span>
<span class="n">df_train</span><span class="p">,</span> <span class="n">df_test</span> <span class="o">=</span> <span class="n">medmnist_to_fastai</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">test_dataset</span><span class="p">)</span>

<span class="n">valid_pct</span> <span class="o">=</span> <span class="mf">0.02</span> <span class="c1"># the validation percentage is low to speed up calculations</span>

<span class="c1"># Define DataBlock for Fastai</span>
<span class="n">dblock</span> <span class="o">=</span> <span class="n">DataBlock</span><span class="p">(</span>
    <span class="n">blocks</span><span class="o">=</span><span class="p">(</span><span class="n">ImageBlock</span><span class="p">(</span><span class="n">PILImage</span><span class="p">),</span> <span class="n">CategoryBlock</span><span class="p">),</span>
    <span class="n">get_x</span><span class="o">=</span><span class="n">ColReader</span><span class="p">(</span><span class="s1">&#39;image&#39;</span><span class="p">),</span>
    <span class="n">get_y</span><span class="o">=</span><span class="n">ColReader</span><span class="p">(</span><span class="s1">&#39;label&#39;</span><span class="p">),</span>
    <span class="n">splitter</span><span class="o">=</span><span class="n">RandomSplitter</span><span class="p">(</span><span class="n">valid_pct</span><span class="o">=</span><span class="n">valid_pct</span><span class="p">),</span> 
    <span class="c1">#item_tfms=Resize(28),</span>
    <span class="n">batch_tfms</span><span class="o">=</span><span class="n">aug_transforms</span><span class="p">()</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">DataLoaders</span></code> is a thin class that just stores whatever <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code> objects you pass to it, and makes them available as <code class="docutils literal notranslate"><span class="pre">train</span></code> and <code class="docutils literal notranslate"><span class="pre">valid</span></code>. Although it’s a very simple class, it’s very important in fastai: it provides the data for your model. The key functionality in <code class="docutils literal notranslate"><span class="pre">DataLoaders</span></code> is provided with just these four lines of code (it has some other minor functionality we’ll skip over for now):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">DataLoaders</span><span class="p">(</span><span class="n">GetAttr</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">loaders</span><span class="p">):</span> <span class="bp">self</span><span class="o">.</span><span class="n">loaders</span> <span class="o">=</span> <span class="n">loaders</span>
    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">):</span> <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">loaders</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="n">train</span><span class="p">,</span><span class="n">valid</span> <span class="o">=</span> <span class="n">add_props</span><span class="p">(</span><span class="k">lambda</span> <span class="n">i</span><span class="p">,</span><span class="bp">self</span><span class="p">:</span> <span class="bp">self</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
</pre></div>
</div>
<blockquote>
<div><p>DataLoaders: A fastai class that stores multiple <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code> objects you pass to it, normally a <code class="docutils literal notranslate"><span class="pre">train</span></code> and a <code class="docutils literal notranslate"><span class="pre">valid</span></code>, although it’s possible to have as many as you like. The first two are made available as properties.</p>
</div></blockquote>
<p>To turn our downloaded data into a <code class="docutils literal notranslate"><span class="pre">DataLoaders</span></code> object we need to tell fastai at least four things:</p>
<ul class="simple">
<li><p>What kinds of data we are working with</p></li>
<li><p>How to get the list of items</p></li>
<li><p>How to label these items</p></li>
<li><p>How to create the validation set</p></li>
</ul>
<p>fastai has a number of <em>factory methods</em> for particular combinations of these things, which are convenient when you have an application and data structure that happen to fit into those predefined methods. For when you don’t, fastai has an extremely flexible system called the <em>data block API</em>. With this API you can fully customize every stage of the creation of your <code class="docutils literal notranslate"><span class="pre">DataLoaders</span></code>.</p>
<p>Let’s look at each of these arguments in turn. First we provide a tuple where we specify what types we want for the independent and dependent variables:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">blocks</span><span class="o">=</span><span class="p">(</span><span class="n">ImageBlock</span><span class="p">,</span> <span class="n">CategoryBlock</span><span class="p">)</span>
</pre></div>
</div>
<p>The <em>independent variable</em> is the thing we are using to make predictions from, and the <em>dependent variable</em> is our target. In this case, our independent variables are images, and our dependent variables are the categories (type of bear) for each image.</p>
<p>For this <code class="docutils literal notranslate"><span class="pre">DataLoaders</span></code> our underlying items will be in a dataframe. To tell fastai how to get them we use:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">get_x</span><span class="o">=</span><span class="n">ColReader</span><span class="p">(</span><span class="s1">&#39;image&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>The independent variable is often referred to as <code class="docutils literal notranslate"><span class="pre">x</span></code> and the dependent variable is often referred to as <code class="docutils literal notranslate"><span class="pre">y</span></code>. Here, we are telling fastai what function to call to create the labels in our dataset:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">get_y</span><span class="o">=</span><span class="n">ColReader</span><span class="p">(</span><span class="s1">&#39;labels&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>In the data block, we define the <code class="docutils literal notranslate"><span class="pre">Transform</span></code>s that we need. A <code class="docutils literal notranslate"><span class="pre">Transform</span></code> contains code that is applied automatically during training; fastai includes many predefined Transforms, and adding new ones is as simple as creating a Python function. There are two kinds: <code class="docutils literal notranslate"><span class="pre">item_tfms</span></code> are applied to each item, while <code class="docutils literal notranslate"><span class="pre">batch_tfms</span></code> are applied to a <em>batch</em> of items at a time using the GPU, so they’re particularly fast.</p>
<p>Now that we have a <code class="docutils literal notranslate"><span class="pre">DataBlock</span></code> object, we use it like a <em>template</em> for creating a <code class="docutils literal notranslate"><span class="pre">DataLoaders</span></code>. We still need to tell fastai the actual source of our data—in this case, the dataframe:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create DataLoaders</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">500</span>
<span class="n">dls</span> <span class="o">=</span> <span class="n">dblock</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">(</span><span class="n">df_train</span><span class="p">,</span> <span class="n">bs</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">)</span> <span class="c1"># to speed up training we use only 500 images from the training dataset, you can either change the number or remove it to use the whole dataset.</span>
</pre></div>
</div>
</div>
</div>
<p>A <code class="docutils literal notranslate"><span class="pre">DataLoaders</span></code> includes validation and training <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code>s. <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code> is a class that provides batches of a few items at a time to the GPU. When you loop through a <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code> fastai will give you 64 (by default) items at a time, all stacked up into a single tensor. We can take a look at a few of those items by calling the <code class="docutils literal notranslate"><span class="pre">show_batch</span></code> method on a <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dls</span><span class="o">.</span><span class="n">show_batch</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/6e8b3ec6d9bd170ba75f1d2ccab261099aea2fa767fb6bb105c076bc73a36fd0.png" src="../_images/6e8b3ec6d9bd170ba75f1d2ccab261099aea2fa767fb6bb105c076bc73a36fd0.png" />
</div>
</div>
<p>The next line of the code training our image recognizer tells fastai to create a <em>convolutional neural network</em> (CNN) and specifies what <em>architecture</em> to use (i.e. what kind of model to create), what data we want to train it on, and what <em>metric</em> to use:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">learn</span> <span class="o">=</span> <span class="n">vision_learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">resnet18</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">error_rate</span><span class="p">)</span>
</pre></div>
</div>
<p>CNN it’s the current state-of-the-art approach to creating computer vision models. Their structure is inspired by how the human vision system works.</p>
<p>Most of the time, however, picking an architecture isn’t a very important part of the deep learning process. It’s something that academics love to talk about, but in practice it is unlikely to be something you need to spend much time on. There are some standard architectures that work most of the time, and in this case we’re using one called <em>ResNet</em>; it is both fast and accurate for many datasets and problems. The <code class="docutils literal notranslate"><span class="pre">18</span></code> in <code class="docutils literal notranslate"><span class="pre">resnet18</span></code> refers to the number of layers in this variant of the architecture (other options are <code class="docutils literal notranslate"><span class="pre">34</span></code>, <code class="docutils literal notranslate"><span class="pre">50</span></code>, <code class="docutils literal notranslate"><span class="pre">101</span></code>, and <code class="docutils literal notranslate"><span class="pre">152</span></code>). Models using architectures with more layers take longer to train, and are more prone to overfitting (i.e. you can’t train them for as many epochs before the accuracy on the validation set starts getting worse). On the other hand, when using more data, they can be quite a bit more accurate.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Train the model using a ResNet architecture</span>
<span class="n">learn</span> <span class="o">=</span> <span class="n">vision_learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> 
                       <span class="n">resnet18</span><span class="p">,</span> 
                       <span class="n">metrics</span><span class="o">=</span><span class="n">error_rate</span><span class="p">,</span> 
                       <span class="c1"># cbs=ShortEpochCallback(.01, short_valid=False),</span>
                       <span class="p">)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fine_tune</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>

<span class="c1"># Show some results</span>
<span class="n">learn</span><span class="o">.</span><span class="n">show_results</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div><div class="output text_html"><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>error_rate</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>3.334232</td>
      <td>2.127958</td>
      <td>0.748193</td>
      <td>00:02</td>
    </tr>
  </tbody>
</table></div><div class="output text_html">
<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div><div class="output text_html"><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>error_rate</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>2.637707</td>
      <td>1.799325</td>
      <td>0.642579</td>
      <td>00:05</td>
    </tr>
    <tr>
      <td>1</td>
      <td>2.385804</td>
      <td>1.529558</td>
      <td>0.516398</td>
      <td>00:05</td>
    </tr>
    <tr>
      <td>2</td>
      <td>2.143686</td>
      <td>1.454205</td>
      <td>0.491384</td>
      <td>00:05</td>
    </tr>
  </tbody>
</table></div><div class="output text_html">
<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div><div class="output text_html"></div><img alt="../_images/63ed3bde60c3b543fa977a8958e75df368046a9d7c07a562e4446c73acbea8b5.png" src="../_images/63ed3bde60c3b543fa977a8958e75df368046a9d7c07a562e4446c73acbea8b5.png" />
</div>
</div>
<p>A <em>metric</em> is a function that measures the quality of the model’s predictions using the validation set, and will be printed at the end of each <em>epoch</em>. In this case, we’re using <code class="docutils literal notranslate"><span class="pre">error_rate</span></code>, which is a function provided by fastai that does just what it says: tells you what percentage of images in the validation set are being classified incorrectly. Another common metric for classification is <code class="docutils literal notranslate"><span class="pre">accuracy</span></code> (which is just <code class="docutils literal notranslate"><span class="pre">1.0</span> <span class="pre">-</span> <span class="pre">error_rate</span></code>).</p>
<p>The concept of a metric may remind you of <em>loss</em>, but there is an important distinction. The entire purpose of loss is to define a “measure of performance” that the training system can use to update weights automatically. In other words, a good choice for loss is a choice that is easy for stochastic gradient descent to use. But a metric is defined for human consumption, so a good metric is one that is easy for you to understand, and that is as close as possible to what you want the model to do. At times, you might decide that the loss function is a suitable metric, but that is not necessarily the case.</p>
<p><code class="docutils literal notranslate"><span class="pre">vision_learner</span></code> also has a parameter <code class="docutils literal notranslate"><span class="pre">pretrained</span></code>, which defaults to <code class="docutils literal notranslate"><span class="pre">True</span></code> (so it’s used in this case, even though we haven’t specified it), which sets the weights in your model to values that have already been trained by experts to recognize a thousand different categories across 1.3 million photos (using the famous <a class="reference external" href="http://www.image-net.org/"><em>ImageNet</em> dataset</a>). A model that has weights that have already been trained on some other dataset is called a <em>pretrained model</em>. A pretrained model can be very useful, because it means that your model, before you’ve even shown it any of your data, is already very capable. And, as you’ll see, in a deep learning model many of these capabilities are things you’ll need, almost regardless of the details of your project. For instance, parts of pretrained models will handle edge, gradient, and color detection, which are needed for many tasks.</p>
<p>When using a pretrained model, <code class="docutils literal notranslate"><span class="pre">vision_learner</span></code> will remove the last layer, since that is always specifically customized to the original training task (i.e. ImageNet dataset classification), and replace it with one or more new layers with randomized weights, of an appropriate size for the dataset you are working with. This last part of the model is known as the <em>head</em>.</p>
<p>Using pretrained models is the <em>most</em> important method we have to allow us to train more accurate models, more quickly, with less data, and less time and money.</p>
<blockquote>
<div><p>Transfer learning: Using a pretrained model for a task different to what it was originally trained for.</p>
</div></blockquote>
<p>fastai will <em>always</em> show the model’s accuracy using <em>only</em> the validation set, <em>never</em> the training set. This is absolutely critical, because if you train a large enough model for a long enough time, it will eventually memorize the label of every item in your dataset! The result will not actually be a useful model, because what we care about is how well our model works on <em>previously unseen images</em>. That is always our goal when creating a model: for it to be useful on data that the model only sees in the future, after it has been trained.</p>
<p>Even when your model has not fully memorized all your data, earlier on in training it may have memorized certain parts of it. As a result, the longer you train for, the better your accuracy will get on the training set; the validation set accuracy will also improve for a while, but eventually it will start getting worse as the model starts to memorize the training set, rather than finding generalizable underlying patterns in the data. When this happens, we say that the model is <em>overfitting</em>.</p>
<p>The model we just fine-tuned uses a <strong>pretrained ResNet</strong> model, which has already learned to recognize general images. We then adapted it to the PathMNIST dataset. After fine-tuning, the model is specialized in classifying colon pathologies.</p>
<p>So, how do we know if this model is any good? In the last column of the table, you can see the <strong>error rate</strong>, which represents the proportion of images that were incorrectly classified (e.g., misdiagnosing a pathology). The error rate is our key metric, providing an intuitive measure of the model’s quality.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Evaluate the model</span>
<span class="n">interp</span> <span class="o">=</span> <span class="n">ClassificationInterpretation</span><span class="o">.</span><span class="n">from_learner</span><span class="p">(</span><span class="n">learn</span><span class="p">)</span>
<span class="n">interp</span><span class="o">.</span><span class="n">plot_confusion_matrix</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div><div class="output text_html"></div><div class="output text_html">
<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div><div class="output text_html"></div><img alt="../_images/fe1d66f8c2ec3efaf4648a394a0872a7fb51a3ca4ad6e680bd7de891aa8b8ac4.png" src="../_images/fe1d66f8c2ec3efaf4648a394a0872a7fb51a3ca4ad6e680bd7de891aa8b8ac4.png" />
</div>
</div>
<p>The confusion matrix shows the number of correct and incorrect predictions the model made. This visualization helps us understand where the model struggles, such as distinguishing between similar skin lesions.</p>
<p>Now you can pass a histology slide image to the model for classification. Ensure that it is a valid image. The notebook will analyze the image and provide its prediction along with a confidence score.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">im</span> <span class="o">=</span> <span class="n">PILImage</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="n">test_dataset</span><span class="o">.</span><span class="n">imgs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">pred</span><span class="p">,</span> <span class="n">pred_idx</span><span class="p">,</span> <span class="n">probs</span> <span class="o">=</span> <span class="n">learn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">im</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Prediction: </span><span class="si">{</span><span class="n">pred</span><span class="si">}</span><span class="s2">; Probability: </span><span class="si">{</span><span class="n">probs</span><span class="p">[</span><span class="n">pred_idx</span><span class="p">]</span><span class="si">:</span><span class="s2">.04f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">im</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div><div class="output text_html"></div><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Prediction: 6; Probability: 0.3315
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;Axes: &gt;
</pre></div>
</div>
<img alt="../_images/c4d4f2fe44976065a21bbd92ea7a70466065923d58ac2770c600030ed23ddba8.png" src="../_images/c4d4f2fe44976065a21bbd92ea7a70466065923d58ac2770c600030ed23ddba8.png" />
</div>
</div>
</section>
<section id="how-neural-networks-make-predictions">
<h2>How Neural Networks Make Predictions<a class="headerlink" href="#how-neural-networks-make-predictions" title="Link to this heading">#</a></h2>
<p>When you pass an image through the neural network, the model processes it through several layers. Each layer performs mathematical operations on the input data (e.g., pixels of the image) and progressively refines its understanding of the image’s features. For instance, the first layers might detect simple patterns like edges, while deeper layers might recognize complex structures, such as shapes that are characteristic of certain skin lesions. Finally, the model makes a prediction by assigning a probability to each possible class (e.g., benign or malignant).</p>
</section>
<section id="improving-the-model">
<h2>Improving the Model<a class="headerlink" href="#improving-the-model" title="Link to this heading">#</a></h2>
<p>If the model’s performance isn’t satisfactory, there are several ways we can improve it:</p>
<ol class="arabic simple">
<li><p><strong>Data Augmentation</strong>: Applying transformations like flipping, rotating, and zooming in on the images to artificially increase the diversity of the training set.</p></li>
<li><p><strong>Fine-tuning</strong>: Training the model for more epochs or adjusting the learning rate to improve performance.</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Example of data augmentation</span>
<span class="n">dblock</span> <span class="o">=</span> <span class="n">DataBlock</span><span class="p">(</span>
    <span class="n">blocks</span><span class="o">=</span><span class="p">(</span><span class="n">ImageBlock</span><span class="p">(</span><span class="n">PILImage</span><span class="p">),</span> <span class="n">CategoryBlock</span><span class="p">),</span>
    <span class="n">get_x</span><span class="o">=</span><span class="n">ColReader</span><span class="p">(</span><span class="s1">&#39;image&#39;</span><span class="p">),</span>
    <span class="n">get_y</span><span class="o">=</span><span class="n">ColReader</span><span class="p">(</span><span class="s1">&#39;label&#39;</span><span class="p">),</span>
    <span class="n">splitter</span><span class="o">=</span><span class="n">RandomSplitter</span><span class="p">(</span><span class="n">valid_pct</span><span class="o">=</span><span class="n">valid_pct</span><span class="p">),</span>
    <span class="c1">#item_tfms=Resize(28),</span>
    <span class="n">batch_tfms</span><span class="o">=</span><span class="n">aug_transforms</span><span class="p">(</span><span class="n">do_flip</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">flip_vert</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_rotate</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
<span class="p">)</span>

<span class="c1"># Create DataLoaders</span>
<span class="n">dls</span> <span class="o">=</span> <span class="n">dblock</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">(</span><span class="n">df_train</span><span class="p">,</span> <span class="n">bs</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>
<span class="n">learn</span> <span class="o">=</span> <span class="n">vision_learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> 
                       <span class="n">resnet18</span><span class="p">,</span> 
                       <span class="n">metrics</span><span class="o">=</span><span class="n">error_rate</span><span class="p">,</span>
                    <span class="c1">#    cbs=ShortEpochCallback(.1, short_valid=False),</span>
                       <span class="p">)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fine_tune</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div><div class="output text_html"><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>error_rate</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>3.270024</td>
      <td>2.082289</td>
      <td>0.815453</td>
      <td>00:02</td>
    </tr>
  </tbody>
</table></div><div class="output text_html">
<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div><div class="output text_html">
    <div>
      <progress value='3' class='' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>
      30.00% [3/10 00:17&lt;00:41]
    </div>
    
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>error_rate</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>2.541684</td>
      <td>2.016075</td>
      <td>0.748193</td>
      <td>00:05</td>
    </tr>
    <tr>
      <td>1</td>
      <td>2.341283</td>
      <td>1.708858</td>
      <td>0.585881</td>
      <td>00:05</td>
    </tr>
    <tr>
      <td>2</td>
      <td>2.215443</td>
      <td>1.607642</td>
      <td>0.538077</td>
      <td>00:05</td>
    </tr>
  </tbody>
</table><p>

    <div>
      <progress value='25' class='' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>
      86.21% [25/29 00:01&lt;00:00 2.0608]
    </div>
    </div><div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">KeyboardInterrupt</span><span class="g g-Whitespace">                         </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">10</span><span class="p">],</span> <span class="n">line</span> <span class="mi">18</span>
<span class="g g-Whitespace">     </span><span class="mi">12</span> <span class="n">dls</span> <span class="o">=</span> <span class="n">dblock</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">(</span><span class="n">df_train</span><span class="p">,</span> <span class="n">bs</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">13</span> <span class="n">learn</span> <span class="o">=</span> <span class="n">vision_learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> 
<span class="g g-Whitespace">     </span><span class="mi">14</span>                        <span class="n">resnet18</span><span class="p">,</span> 
<span class="g g-Whitespace">     </span><span class="mi">15</span>                        <span class="n">metrics</span><span class="o">=</span><span class="n">error_rate</span><span class="p">,</span>
<span class="g g-Whitespace">     </span><span class="mi">16</span>                     <span class="c1">#    cbs=ShortEpochCallback(.1, short_valid=False),</span>
<span class="g g-Whitespace">     </span><span class="mi">17</span>                        <span class="p">)</span>
<span class="ne">---&gt; </span><span class="mi">18</span> <span class="n">learn</span><span class="o">.</span><span class="n">fine_tune</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>

<span class="nn">File ~\anaconda3\envs\book\Lib\site-packages\fastai\callback\schedule.py:170,</span> in <span class="ni">fine_tune</span><span class="nt">(self, epochs, base_lr, freeze_epochs, lr_mult, pct_start, div, **kwargs)</span>
<span class="g g-Whitespace">    </span><span class="mi">168</span> <span class="n">base_lr</span> <span class="o">/=</span> <span class="mi">2</span>
<span class="g g-Whitespace">    </span><span class="mi">169</span> <span class="bp">self</span><span class="o">.</span><span class="n">unfreeze</span><span class="p">()</span>
<span class="ne">--&gt; </span><span class="mi">170</span> <span class="bp">self</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="nb">slice</span><span class="p">(</span><span class="n">base_lr</span><span class="o">/</span><span class="n">lr_mult</span><span class="p">,</span> <span class="n">base_lr</span><span class="p">),</span> <span class="n">pct_start</span><span class="o">=</span><span class="n">pct_start</span><span class="p">,</span> <span class="n">div</span><span class="o">=</span><span class="n">div</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="nn">File ~\anaconda3\envs\book\Lib\site-packages\fastai\callback\schedule.py:121,</span> in <span class="ni">fit_one_cycle</span><span class="nt">(self, n_epoch, lr_max, div, div_final, pct_start, wd, moms, cbs, reset_opt, start_epoch)</span>
<span class="g g-Whitespace">    </span><span class="mi">118</span> <span class="n">lr_max</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">h</span><span class="p">[</span><span class="s1">&#39;lr&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">opt</span><span class="o">.</span><span class="n">hypers</span><span class="p">])</span>
<span class="g g-Whitespace">    </span><span class="mi">119</span> <span class="n">scheds</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;lr&#39;</span><span class="p">:</span> <span class="n">combined_cos</span><span class="p">(</span><span class="n">pct_start</span><span class="p">,</span> <span class="n">lr_max</span><span class="o">/</span><span class="n">div</span><span class="p">,</span> <span class="n">lr_max</span><span class="p">,</span> <span class="n">lr_max</span><span class="o">/</span><span class="n">div_final</span><span class="p">),</span>
<span class="g g-Whitespace">    </span><span class="mi">120</span>           <span class="s1">&#39;mom&#39;</span><span class="p">:</span> <span class="n">combined_cos</span><span class="p">(</span><span class="n">pct_start</span><span class="p">,</span> <span class="o">*</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">moms</span> <span class="k">if</span> <span class="n">moms</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">moms</span><span class="p">))}</span>
<span class="ne">--&gt; </span><span class="mi">121</span> <span class="bp">self</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">n_epoch</span><span class="p">,</span> <span class="n">cbs</span><span class="o">=</span><span class="n">ParamScheduler</span><span class="p">(</span><span class="n">scheds</span><span class="p">)</span><span class="o">+</span><span class="n">L</span><span class="p">(</span><span class="n">cbs</span><span class="p">),</span> <span class="n">reset_opt</span><span class="o">=</span><span class="n">reset_opt</span><span class="p">,</span> <span class="n">wd</span><span class="o">=</span><span class="n">wd</span><span class="p">,</span> <span class="n">start_epoch</span><span class="o">=</span><span class="n">start_epoch</span><span class="p">)</span>

<span class="nn">File ~\anaconda3\envs\book\Lib\site-packages\fastai\learner.py:266,</span> in <span class="ni">Learner.fit</span><span class="nt">(self, n_epoch, lr, wd, cbs, reset_opt, start_epoch)</span>
<span class="g g-Whitespace">    </span><span class="mi">264</span> <span class="bp">self</span><span class="o">.</span><span class="n">opt</span><span class="o">.</span><span class="n">set_hypers</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">lr</span> <span class="k">if</span> <span class="n">lr</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">lr</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">265</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_epoch</span> <span class="o">=</span> <span class="n">n_epoch</span>
<span class="ne">--&gt; </span><span class="mi">266</span> <span class="bp">self</span><span class="o">.</span><span class="n">_with_events</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_do_fit</span><span class="p">,</span> <span class="s1">&#39;fit&#39;</span><span class="p">,</span> <span class="n">CancelFitException</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_end_cleanup</span><span class="p">)</span>

<span class="nn">File ~\anaconda3\envs\book\Lib\site-packages\fastai\learner.py:201,</span> in <span class="ni">Learner._with_events</span><span class="nt">(self, f, event_type, ex, final)</span>
<span class="g g-Whitespace">    </span><span class="mi">200</span> <span class="k">def</span> <span class="nf">_with_events</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">event_type</span><span class="p">,</span> <span class="n">ex</span><span class="p">,</span> <span class="n">final</span><span class="o">=</span><span class="n">noop</span><span class="p">):</span>
<span class="ne">--&gt; </span><span class="mi">201</span>     <span class="k">try</span><span class="p">:</span> <span class="bp">self</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;before_</span><span class="si">{</span><span class="n">event_type</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">);</span>  <span class="n">f</span><span class="p">()</span>
<span class="g g-Whitespace">    </span><span class="mi">202</span>     <span class="k">except</span> <span class="n">ex</span><span class="p">:</span> <span class="bp">self</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;after_cancel_</span><span class="si">{</span><span class="n">event_type</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">203</span>     <span class="bp">self</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;after_</span><span class="si">{</span><span class="n">event_type</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">);</span>  <span class="n">final</span><span class="p">()</span>

<span class="nn">File ~\anaconda3\envs\book\Lib\site-packages\fastai\learner.py:255,</span> in <span class="ni">Learner._do_fit</span><span class="nt">(self)</span>
<span class="g g-Whitespace">    </span><span class="mi">253</span> <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_epoch</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">254</span>     <span class="bp">self</span><span class="o">.</span><span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span>
<span class="ne">--&gt; </span><span class="mi">255</span>     <span class="bp">self</span><span class="o">.</span><span class="n">_with_events</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_do_epoch</span><span class="p">,</span> <span class="s1">&#39;epoch&#39;</span><span class="p">,</span> <span class="n">CancelEpochException</span><span class="p">)</span>

<span class="nn">File ~\anaconda3\envs\book\Lib\site-packages\fastai\learner.py:201,</span> in <span class="ni">Learner._with_events</span><span class="nt">(self, f, event_type, ex, final)</span>
<span class="g g-Whitespace">    </span><span class="mi">200</span> <span class="k">def</span> <span class="nf">_with_events</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">event_type</span><span class="p">,</span> <span class="n">ex</span><span class="p">,</span> <span class="n">final</span><span class="o">=</span><span class="n">noop</span><span class="p">):</span>
<span class="ne">--&gt; </span><span class="mi">201</span>     <span class="k">try</span><span class="p">:</span> <span class="bp">self</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;before_</span><span class="si">{</span><span class="n">event_type</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">);</span>  <span class="n">f</span><span class="p">()</span>
<span class="g g-Whitespace">    </span><span class="mi">202</span>     <span class="k">except</span> <span class="n">ex</span><span class="p">:</span> <span class="bp">self</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;after_cancel_</span><span class="si">{</span><span class="n">event_type</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">203</span>     <span class="bp">self</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;after_</span><span class="si">{</span><span class="n">event_type</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">);</span>  <span class="n">final</span><span class="p">()</span>

<span class="nn">File ~\anaconda3\envs\book\Lib\site-packages\fastai\learner.py:250,</span> in <span class="ni">Learner._do_epoch</span><span class="nt">(self)</span>
<span class="g g-Whitespace">    </span><span class="mi">248</span> <span class="k">def</span> <span class="nf">_do_epoch</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">249</span>     <span class="bp">self</span><span class="o">.</span><span class="n">_do_epoch_train</span><span class="p">()</span>
<span class="ne">--&gt; </span><span class="mi">250</span>     <span class="bp">self</span><span class="o">.</span><span class="n">_do_epoch_validate</span><span class="p">()</span>

<span class="nn">File ~\anaconda3\envs\book\Lib\site-packages\fastai\learner.py:246,</span> in <span class="ni">Learner._do_epoch_validate</span><span class="nt">(self, ds_idx, dl)</span>
<span class="g g-Whitespace">    </span><span class="mi">244</span> <span class="k">if</span> <span class="n">dl</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span> <span class="n">dl</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dls</span><span class="p">[</span><span class="n">ds_idx</span><span class="p">]</span>
<span class="g g-Whitespace">    </span><span class="mi">245</span> <span class="bp">self</span><span class="o">.</span><span class="n">dl</span> <span class="o">=</span> <span class="n">dl</span>
<span class="ne">--&gt; </span><span class="mi">246</span> <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span> <span class="bp">self</span><span class="o">.</span><span class="n">_with_events</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">all_batches</span><span class="p">,</span> <span class="s1">&#39;validate&#39;</span><span class="p">,</span> <span class="n">CancelValidException</span><span class="p">)</span>

<span class="nn">File ~\anaconda3\envs\book\Lib\site-packages\fastai\learner.py:201,</span> in <span class="ni">Learner._with_events</span><span class="nt">(self, f, event_type, ex, final)</span>
<span class="g g-Whitespace">    </span><span class="mi">200</span> <span class="k">def</span> <span class="nf">_with_events</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">event_type</span><span class="p">,</span> <span class="n">ex</span><span class="p">,</span> <span class="n">final</span><span class="o">=</span><span class="n">noop</span><span class="p">):</span>
<span class="ne">--&gt; </span><span class="mi">201</span>     <span class="k">try</span><span class="p">:</span> <span class="bp">self</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;before_</span><span class="si">{</span><span class="n">event_type</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">);</span>  <span class="n">f</span><span class="p">()</span>
<span class="g g-Whitespace">    </span><span class="mi">202</span>     <span class="k">except</span> <span class="n">ex</span><span class="p">:</span> <span class="bp">self</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;after_cancel_</span><span class="si">{</span><span class="n">event_type</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">203</span>     <span class="bp">self</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;after_</span><span class="si">{</span><span class="n">event_type</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">);</span>  <span class="n">final</span><span class="p">()</span>

<span class="nn">File ~\anaconda3\envs\book\Lib\site-packages\fastai\learner.py:207,</span> in <span class="ni">Learner.all_batches</span><span class="nt">(self)</span>
<span class="g g-Whitespace">    </span><span class="mi">205</span> <span class="k">def</span> <span class="nf">all_batches</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">206</span>     <span class="bp">self</span><span class="o">.</span><span class="n">n_iter</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dl</span><span class="p">)</span>
<span class="nn">--&gt; 207     for o</span> in <span class="ni">enumerate(self.dl): self.one_batch</span><span class="nt">(*o)</span>

<span class="nn">File ~\anaconda3\envs\book\Lib\site-packages\fastai\learner.py:237,</span> in <span class="ni">Learner.one_batch</span><span class="nt">(self, i, b)</span>
<span class="g g-Whitespace">    </span><span class="mi">235</span> <span class="n">b</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set_device</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">236</span> <span class="bp">self</span><span class="o">.</span><span class="n">_split</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">237</span> <span class="bp">self</span><span class="o">.</span><span class="n">_with_events</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_do_one_batch</span><span class="p">,</span> <span class="s1">&#39;batch&#39;</span><span class="p">,</span> <span class="n">CancelBatchException</span><span class="p">)</span>

<span class="nn">File ~\anaconda3\envs\book\Lib\site-packages\fastai\learner.py:201,</span> in <span class="ni">Learner._with_events</span><span class="nt">(self, f, event_type, ex, final)</span>
<span class="g g-Whitespace">    </span><span class="mi">200</span> <span class="k">def</span> <span class="nf">_with_events</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">event_type</span><span class="p">,</span> <span class="n">ex</span><span class="p">,</span> <span class="n">final</span><span class="o">=</span><span class="n">noop</span><span class="p">):</span>
<span class="ne">--&gt; </span><span class="mi">201</span>     <span class="k">try</span><span class="p">:</span> <span class="bp">self</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;before_</span><span class="si">{</span><span class="n">event_type</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">);</span>  <span class="n">f</span><span class="p">()</span>
<span class="g g-Whitespace">    </span><span class="mi">202</span>     <span class="k">except</span> <span class="n">ex</span><span class="p">:</span> <span class="bp">self</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;after_cancel_</span><span class="si">{</span><span class="n">event_type</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">203</span>     <span class="bp">self</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;after_</span><span class="si">{</span><span class="n">event_type</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">);</span>  <span class="n">final</span><span class="p">()</span>

<span class="nn">File ~\anaconda3\envs\book\Lib\site-packages\fastai\learner.py:218,</span> in <span class="ni">Learner._do_one_batch</span><span class="nt">(self)</span>
<span class="g g-Whitespace">    </span><span class="mi">217</span> <span class="k">def</span> <span class="nf">_do_one_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="ne">--&gt; </span><span class="mi">218</span>     <span class="bp">self</span><span class="o">.</span><span class="n">pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">xb</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">219</span>     <span class="bp">self</span><span class="p">(</span><span class="s1">&#39;after_pred&#39;</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">220</span>     <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">yb</span><span class="p">):</span>

<span class="nn">File ~\anaconda3\envs\book\Lib\site-packages\torch\nn\modules\module.py:1553,</span> in <span class="ni">Module._wrapped_call_impl</span><span class="nt">(self, *args, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1551</span>     <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compiled_call_impl</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>  <span class="c1"># type: ignore[misc]</span>
<span class="g g-Whitespace">   </span><span class="mi">1552</span> <span class="k">else</span><span class="p">:</span>
<span class="ne">-&gt; </span><span class="mi">1553</span>     <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call_impl</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="nn">File ~\anaconda3\envs\book\Lib\site-packages\torch\nn\modules\module.py:1562,</span> in <span class="ni">Module._call_impl</span><span class="nt">(self, *args, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1557</span> <span class="c1"># If we don&#39;t have any hooks, we want to skip the rest of the logic in</span>
<span class="g g-Whitespace">   </span><span class="mi">1558</span> <span class="c1"># this function, and just call forward.</span>
<span class="g g-Whitespace">   </span><span class="mi">1559</span> <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_backward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_backward_pre_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pre_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1560</span>         <span class="ow">or</span> <span class="n">_global_backward_pre_hooks</span> <span class="ow">or</span> <span class="n">_global_backward_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1561</span>         <span class="ow">or</span> <span class="n">_global_forward_hooks</span> <span class="ow">or</span> <span class="n">_global_forward_pre_hooks</span><span class="p">):</span>
<span class="ne">-&gt; </span><span class="mi">1562</span>     <span class="k">return</span> <span class="n">forward_call</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1564</span> <span class="k">try</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1565</span>     <span class="n">result</span> <span class="o">=</span> <span class="kc">None</span>

<span class="nn">File ~\anaconda3\envs\book\Lib\site-packages\torch\nn\modules\container.py:219,</span> in <span class="ni">Sequential.forward</span><span class="nt">(self, input)</span>
<span class="g g-Whitespace">    </span><span class="mi">217</span> <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">218</span>     <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">219</span>         <span class="nb">input</span> <span class="o">=</span> <span class="n">module</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">220</span>     <span class="k">return</span> <span class="nb">input</span>

<span class="nn">File ~\anaconda3\envs\book\Lib\site-packages\torch\nn\modules\module.py:1553,</span> in <span class="ni">Module._wrapped_call_impl</span><span class="nt">(self, *args, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1551</span>     <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compiled_call_impl</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>  <span class="c1"># type: ignore[misc]</span>
<span class="g g-Whitespace">   </span><span class="mi">1552</span> <span class="k">else</span><span class="p">:</span>
<span class="ne">-&gt; </span><span class="mi">1553</span>     <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call_impl</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="nn">File ~\anaconda3\envs\book\Lib\site-packages\torch\nn\modules\module.py:1562,</span> in <span class="ni">Module._call_impl</span><span class="nt">(self, *args, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1557</span> <span class="c1"># If we don&#39;t have any hooks, we want to skip the rest of the logic in</span>
<span class="g g-Whitespace">   </span><span class="mi">1558</span> <span class="c1"># this function, and just call forward.</span>
<span class="g g-Whitespace">   </span><span class="mi">1559</span> <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_backward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_backward_pre_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pre_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1560</span>         <span class="ow">or</span> <span class="n">_global_backward_pre_hooks</span> <span class="ow">or</span> <span class="n">_global_backward_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1561</span>         <span class="ow">or</span> <span class="n">_global_forward_hooks</span> <span class="ow">or</span> <span class="n">_global_forward_pre_hooks</span><span class="p">):</span>
<span class="ne">-&gt; </span><span class="mi">1562</span>     <span class="k">return</span> <span class="n">forward_call</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1564</span> <span class="k">try</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1565</span>     <span class="n">result</span> <span class="o">=</span> <span class="kc">None</span>

<span class="nn">File ~\anaconda3\envs\book\Lib\site-packages\torch\nn\modules\container.py:219,</span> in <span class="ni">Sequential.forward</span><span class="nt">(self, input)</span>
<span class="g g-Whitespace">    </span><span class="mi">217</span> <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">218</span>     <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">219</span>         <span class="nb">input</span> <span class="o">=</span> <span class="n">module</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">220</span>     <span class="k">return</span> <span class="nb">input</span>

<span class="nn">File ~\anaconda3\envs\book\Lib\site-packages\torch\nn\modules\module.py:1553,</span> in <span class="ni">Module._wrapped_call_impl</span><span class="nt">(self, *args, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1551</span>     <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compiled_call_impl</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>  <span class="c1"># type: ignore[misc]</span>
<span class="g g-Whitespace">   </span><span class="mi">1552</span> <span class="k">else</span><span class="p">:</span>
<span class="ne">-&gt; </span><span class="mi">1553</span>     <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call_impl</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="nn">File ~\anaconda3\envs\book\Lib\site-packages\torch\nn\modules\module.py:1562,</span> in <span class="ni">Module._call_impl</span><span class="nt">(self, *args, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1557</span> <span class="c1"># If we don&#39;t have any hooks, we want to skip the rest of the logic in</span>
<span class="g g-Whitespace">   </span><span class="mi">1558</span> <span class="c1"># this function, and just call forward.</span>
<span class="g g-Whitespace">   </span><span class="mi">1559</span> <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_backward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_backward_pre_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pre_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1560</span>         <span class="ow">or</span> <span class="n">_global_backward_pre_hooks</span> <span class="ow">or</span> <span class="n">_global_backward_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1561</span>         <span class="ow">or</span> <span class="n">_global_forward_hooks</span> <span class="ow">or</span> <span class="n">_global_forward_pre_hooks</span><span class="p">):</span>
<span class="ne">-&gt; </span><span class="mi">1562</span>     <span class="k">return</span> <span class="n">forward_call</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1564</span> <span class="k">try</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1565</span>     <span class="n">result</span> <span class="o">=</span> <span class="kc">None</span>

<span class="nn">File ~\anaconda3\envs\book\Lib\site-packages\torch\nn\modules\container.py:219,</span> in <span class="ni">Sequential.forward</span><span class="nt">(self, input)</span>
<span class="g g-Whitespace">    </span><span class="mi">217</span> <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">218</span>     <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">219</span>         <span class="nb">input</span> <span class="o">=</span> <span class="n">module</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">220</span>     <span class="k">return</span> <span class="nb">input</span>

<span class="nn">File ~\anaconda3\envs\book\Lib\site-packages\torch\nn\modules\module.py:1553,</span> in <span class="ni">Module._wrapped_call_impl</span><span class="nt">(self, *args, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1551</span>     <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compiled_call_impl</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>  <span class="c1"># type: ignore[misc]</span>
<span class="g g-Whitespace">   </span><span class="mi">1552</span> <span class="k">else</span><span class="p">:</span>
<span class="ne">-&gt; </span><span class="mi">1553</span>     <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call_impl</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="nn">File ~\anaconda3\envs\book\Lib\site-packages\torch\nn\modules\module.py:1562,</span> in <span class="ni">Module._call_impl</span><span class="nt">(self, *args, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1557</span> <span class="c1"># If we don&#39;t have any hooks, we want to skip the rest of the logic in</span>
<span class="g g-Whitespace">   </span><span class="mi">1558</span> <span class="c1"># this function, and just call forward.</span>
<span class="g g-Whitespace">   </span><span class="mi">1559</span> <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_backward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_backward_pre_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pre_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1560</span>         <span class="ow">or</span> <span class="n">_global_backward_pre_hooks</span> <span class="ow">or</span> <span class="n">_global_backward_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1561</span>         <span class="ow">or</span> <span class="n">_global_forward_hooks</span> <span class="ow">or</span> <span class="n">_global_forward_pre_hooks</span><span class="p">):</span>
<span class="ne">-&gt; </span><span class="mi">1562</span>     <span class="k">return</span> <span class="n">forward_call</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1564</span> <span class="k">try</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1565</span>     <span class="n">result</span> <span class="o">=</span> <span class="kc">None</span>

<span class="nn">File ~\anaconda3\envs\book\Lib\site-packages\torchvision\models\resnet.py:96,</span> in <span class="ni">BasicBlock.forward</span><span class="nt">(self, x)</span>
<span class="g g-Whitespace">     </span><span class="mi">93</span> <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn1</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">94</span> <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
<span class="ne">---&gt; </span><span class="mi">96</span> <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">97</span> <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">99</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">downsample</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>

<span class="nn">File ~\anaconda3\envs\book\Lib\site-packages\torch\nn\modules\module.py:1553,</span> in <span class="ni">Module._wrapped_call_impl</span><span class="nt">(self, *args, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1551</span>     <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compiled_call_impl</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>  <span class="c1"># type: ignore[misc]</span>
<span class="g g-Whitespace">   </span><span class="mi">1552</span> <span class="k">else</span><span class="p">:</span>
<span class="ne">-&gt; </span><span class="mi">1553</span>     <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call_impl</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="nn">File ~\anaconda3\envs\book\Lib\site-packages\torch\nn\modules\module.py:1562,</span> in <span class="ni">Module._call_impl</span><span class="nt">(self, *args, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1557</span> <span class="c1"># If we don&#39;t have any hooks, we want to skip the rest of the logic in</span>
<span class="g g-Whitespace">   </span><span class="mi">1558</span> <span class="c1"># this function, and just call forward.</span>
<span class="g g-Whitespace">   </span><span class="mi">1559</span> <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_backward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_backward_pre_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pre_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1560</span>         <span class="ow">or</span> <span class="n">_global_backward_pre_hooks</span> <span class="ow">or</span> <span class="n">_global_backward_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1561</span>         <span class="ow">or</span> <span class="n">_global_forward_hooks</span> <span class="ow">or</span> <span class="n">_global_forward_pre_hooks</span><span class="p">):</span>
<span class="ne">-&gt; </span><span class="mi">1562</span>     <span class="k">return</span> <span class="n">forward_call</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1564</span> <span class="k">try</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1565</span>     <span class="n">result</span> <span class="o">=</span> <span class="kc">None</span>

<span class="nn">File ~\anaconda3\envs\book\Lib\site-packages\torch\nn\modules\conv.py:458,</span> in <span class="ni">Conv2d.forward</span><span class="nt">(self, input)</span>
<span class="g g-Whitespace">    </span><span class="mi">457</span> <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">458</span>     <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_conv_forward</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>

<span class="nn">File ~\anaconda3\envs\book\Lib\site-packages\torch\nn\modules\conv.py:454,</span> in <span class="ni">Conv2d._conv_forward</span><span class="nt">(self, input, weight, bias)</span>
<span class="g g-Whitespace">    </span><span class="mi">450</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding_mode</span> <span class="o">!=</span> <span class="s1">&#39;zeros&#39;</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">451</span>     <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_reversed_padding_repeated_twice</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">padding_mode</span><span class="p">),</span>
<span class="g g-Whitespace">    </span><span class="mi">452</span>                     <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">453</span>                     <span class="n">_pair</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">dilation</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">groups</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">454</span> <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">455</span>                 <span class="bp">self</span><span class="o">.</span><span class="n">padding</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dilation</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">groups</span><span class="p">)</span>

<span class="ne">KeyboardInterrupt</span>: 
</pre></div>
</div>
</div>
</div>
<p>By augmenting the data and fine-tuning the model, we can potentially reduce the error rate and improve the model’s ability to generalize.</p>
</section>
<section id="evaluating-model-performance">
<h2>Evaluating Model Performance<a class="headerlink" href="#evaluating-model-performance" title="Link to this heading">#</a></h2>
<p>Once the model has been trained, it’s crucial to evaluate its performance using a validation set. In our case, we split the dataset into 80% training images and 20% validation images. The model’s performance on the validation set is a strong indicator of how well it will generalize to new, unseen data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plot the loss curves to evaluate training and validation performance</span>
<span class="n">learn</span><span class="o">.</span><span class="n">recorder</span><span class="o">.</span><span class="n">plot_loss</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;Axes: title={&#39;center&#39;: &#39;learning curve&#39;}, xlabel=&#39;steps&#39;, ylabel=&#39;loss&#39;&gt;
</pre></div>
</div>
<img alt="../_images/650f35681f0d4ad384d69d498374efad5a86250e23f6430e7607f05a04bc76b0.png" src="../_images/650f35681f0d4ad384d69d498374efad5a86250e23f6430e7607f05a04bc76b0.png" />
</div>
</div>
<p>The loss curve helps us understand whether the model is overfitting (learning too much from the training data but performing poorly on new data) or underfitting (failing to capture the complexity of the data).</p>
</section>
<section id="limitations-and-ethical-considerations">
<h2>Limitations and Ethical Considerations<a class="headerlink" href="#limitations-and-ethical-considerations" title="Link to this heading">#</a></h2>
<p>It’s important to recognize that while machine learning models like this one can assist in diagnosing medical conditions, they are not perfect. Misclassifications can occur, and it’s crucial to ensure that such models are evaluated rigorously before being used in clinical settings. Additionally, considerations like data privacy, informed consent, and bias in training data must be addressed to avoid unintended consequences, such as biased diagnoses for certain demographic groups.</p>
</section>
<section id="handling-overfitting">
<h2>Handling Overfitting<a class="headerlink" href="#handling-overfitting" title="Link to this heading">#</a></h2>
<p>One of the most common challenges in machine learning, particularly with smaller datasets like the ISIC dataset, is <strong>overfitting</strong>. Overfitting occurs when the model learns the details and noise in the training data to the extent that it negatively impacts its performance on new data. To mitigate overfitting, we can use techniques such as <strong>dropout</strong> and <strong>regularization</strong>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Apply dropout and regularization to improve generalization</span>
<span class="n">learn</span> <span class="o">=</span> <span class="n">vision_learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">resnet18</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">error_rate</span><span class="p">,</span> 
                       <span class="n">model_dir</span><span class="o">=</span><span class="s1">&#39;/tmp/model/&#39;</span><span class="p">,</span>
                       <span class="n">ps</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="c1"># probabilities used for the dropouts</span>
                    <span class="c1">#    cbs=ShortEpochCallback(.1, short_valid=False),</span>
                       <span class="p">)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fine_tune</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div><div class="output text_html"><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>error_rate</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>3.199423</td>
      <td>2.032626</td>
      <td>0.748193</td>
      <td>00:03</td>
    </tr>
  </tbody>
</table></div><div class="output text_html">
<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div><div class="output text_html"><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>error_rate</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>2.659537</td>
      <td>1.905746</td>
      <td>0.707615</td>
      <td>00:07</td>
    </tr>
    <tr>
      <td>1</td>
      <td>2.471174</td>
      <td>1.614642</td>
      <td>0.548638</td>
      <td>00:07</td>
    </tr>
    <tr>
      <td>2</td>
      <td>2.308626</td>
      <td>1.510100</td>
      <td>0.504169</td>
      <td>00:06</td>
    </tr>
    <tr>
      <td>3</td>
      <td>2.131850</td>
      <td>1.447852</td>
      <td>0.467482</td>
      <td>00:07</td>
    </tr>
    <tr>
      <td>4</td>
      <td>1.974621</td>
      <td>1.428242</td>
      <td>0.440245</td>
      <td>00:06</td>
    </tr>
    <tr>
      <td>5</td>
      <td>1.838841</td>
      <td>1.494769</td>
      <td>0.429127</td>
      <td>00:07</td>
    </tr>
    <tr>
      <td>6</td>
      <td>1.726485</td>
      <td>1.509884</td>
      <td>0.424125</td>
      <td>00:07</td>
    </tr>
    <tr>
      <td>7</td>
      <td>1.658963</td>
      <td>1.474761</td>
      <td>0.418566</td>
      <td>00:06</td>
    </tr>
    <tr>
      <td>8</td>
      <td>1.602255</td>
      <td>1.444819</td>
      <td>0.414675</td>
      <td>00:07</td>
    </tr>
    <tr>
      <td>9</td>
      <td>1.580153</td>
      <td>1.485377</td>
      <td>0.420233</td>
      <td>00:07</td>
    </tr>
  </tbody>
</table></div></div>
</div>
<p>By adding dropout to the network, we randomly disable a fraction of the neurons during training, which helps prevent the model from becoming too reliant on any single feature in the data.</p>
</section>
<section id="transfer-learning">
<h2>Transfer Learning<a class="headerlink" href="#transfer-learning" title="Link to this heading">#</a></h2>
<p>Transfer learning is particularly useful in biomedical engineering because medical datasets are often small and expensive to collect. By using a model pretrained on a large, general dataset and fine-tuning it on a smaller, domain-specific dataset, we can achieve high performance without needing a vast amount of labeled data.</p>
<p>In this notebook, we leveraged a pretrained ResNet model, which was originally trained on millions of general images, and fine-tuned it to specialize in classifying skin lesions.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Example of using a different pretrained model, such as EfficientNet</span>
<span class="n">learn</span> <span class="o">=</span> <span class="n">vision_learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">efficientnet_b0</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">error_rate</span><span class="p">,</span> 
                    <span class="c1">#    cbs=ShortEpochCallback(.1, short_valid=False),</span>
                       <span class="p">)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fine_tune</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div><div class="output text_html"><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>error_rate</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>3.211165</td>
      <td>2.640593</td>
      <td>0.889939</td>
      <td>00:04</td>
    </tr>
  </tbody>
</table></div><div class="output text_html">
<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div><div class="output text_html"><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>error_rate</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>2.742377</td>
      <td>1.971537</td>
      <td>0.689828</td>
      <td>00:05</td>
    </tr>
    <tr>
      <td>1</td>
      <td>2.629692</td>
      <td>1.749916</td>
      <td>0.586993</td>
      <td>00:05</td>
    </tr>
    <tr>
      <td>2</td>
      <td>2.525275</td>
      <td>1.714116</td>
      <td>0.554753</td>
      <td>00:05</td>
    </tr>
    <tr>
      <td>3</td>
      <td>2.372823</td>
      <td>1.741643</td>
      <td>0.534742</td>
      <td>00:05</td>
    </tr>
    <tr>
      <td>4</td>
      <td>2.299573</td>
      <td>1.752741</td>
      <td>0.535853</td>
      <td>00:05</td>
    </tr>
    <tr>
      <td>5</td>
      <td>2.243513</td>
      <td>1.792108</td>
      <td>0.531406</td>
      <td>00:05</td>
    </tr>
    <tr>
      <td>6</td>
      <td>2.158350</td>
      <td>1.798456</td>
      <td>0.533074</td>
      <td>00:05</td>
    </tr>
    <tr>
      <td>7</td>
      <td>2.102549</td>
      <td>1.737350</td>
      <td>0.518621</td>
      <td>00:05</td>
    </tr>
    <tr>
      <td>8</td>
      <td>2.066642</td>
      <td>1.729988</td>
      <td>0.526959</td>
      <td>00:05</td>
    </tr>
    <tr>
      <td>9</td>
      <td>2.045389</td>
      <td>1.736192</td>
      <td>0.530295</td>
      <td>00:05</td>
    </tr>
  </tbody>
</table></div></div>
</div>
<p>EfficientNet is another powerful architecture that can often provide even better performance than ResNet when fine-tuned for specific tasks.</p>
<p>The last line of our previous code tells fastai how to <em>fit</em> the model:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">fine_tune</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>The architecture only describes a <em>template</em> for a mathematical function; it doesn’t actually do anything until we provide values for the millions of parameters it contains.</p>
<p>This is the key to deep learning —determining how to fit the parameters of a model to get it to solve your problem. In order to fit a model, we have to provide at least one piece of information: how many times to look at each image (known as number of <em>epochs</em>). The number of epochs you select will largely depend on how much time you have available, and how long you find it takes in practice to fit your model. If you select a number that is too small, you can always train for more epochs later.</p>
<p>But why is the method called <code class="docutils literal notranslate"><span class="pre">fine_tune</span></code>, and not <code class="docutils literal notranslate"><span class="pre">fit</span></code>? fastai actually <em>does</em> have a method called <code class="docutils literal notranslate"><span class="pre">fit</span></code>, which does indeed fit a model. But in this case, we’ve started with a pretrained model, and we don’t want to throw away all those capabilities that it already has.</p>
<blockquote>
<div><p>Fine-tuning: A transfer learning technique where the parameters of a pretrained model are updated by training for additional epochs using a different task to that used for pretraining.</p>
</div></blockquote>
<p>When you use the <code class="docutils literal notranslate"><span class="pre">fine_tune</span></code> method, fastai will use these tricks for you. There are a few parameters you can set, but in the default form shown here, it does two steps:</p>
<ol class="arabic simple">
<li><p>Use one epoch to fit just those parts of the model necessary to get the new random head to work correctly with your dataset.</p></li>
<li><p>Use the number of epochs requested when calling the method to fit the entire model, updating the weights of the later layers (especially the head) faster than the earlier layers (which, as we’ll see, generally don’t require many changes from the pretrained weights).</p></li>
</ol>
<p>The <em>head</em> of a model is the part that is newly added to be specific to the new dataset. An <em>epoch</em> is one complete pass through the dataset. After calling <code class="docutils literal notranslate"><span class="pre">fit</span></code>, the results after each epoch are printed, showing the epoch number, the training and validation set losses (the “measure of performance” used for training the model), and any <em>metrics</em> you’ve requested (error rate, in this case).</p>
</section>
<section id="deploying-the-model-for-real-world-use">
<h2>Deploying the Model for Real-World Use<a class="headerlink" href="#deploying-the-model-for-real-world-use" title="Link to this heading">#</a></h2>
<p>Once the model is trained and validated, it can be deployed to assist healthcare professionals in real-world scenarios. For deployment on a local device or cloud platform, the model can be exported and integrated into medical software.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Export the model for deployment</span>
<span class="n">learn</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="s1">&#39;model.pkl&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>This exported model can then be loaded in other applications.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load the exported model</span>
<span class="n">learn_inf</span> <span class="o">=</span> <span class="n">load_learner</span><span class="p">(</span><span class="s1">&#39;model.pkl&#39;</span><span class="p">)</span>
<span class="n">pred</span><span class="p">,</span> <span class="n">pred_idx</span><span class="p">,</span> <span class="n">probs</span> <span class="o">=</span> <span class="n">learn_inf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">im</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Prediction: </span><span class="si">{</span><span class="n">pred</span><span class="si">}</span><span class="s2">; Probability: </span><span class="si">{</span><span class="n">probs</span><span class="p">[</span><span class="n">pred_idx</span><span class="p">]</span><span class="si">:</span><span class="s2">.04f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div><div class="output text_html"></div><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Prediction: 6; Probability: 0.8935
</pre></div>
</div>
</div>
</div>
</section>
<hr class="docutils" />
<section id="validation-sets-and-test-sets">
<h2>Validation Sets and Test Sets<a class="headerlink" href="#validation-sets-and-test-sets" title="Link to this heading">#</a></h2>
<p>When training a model, the process focuses on optimizing predictions based solely on the training data to determine weight parameters. However, we, as modelers, are indirectly influencing the model in a way the training process does not: we adjust hyperparameters based on performance observed in the validation data. This means that our exploration and adjustments can inadvertently lead to “overfitting” on the validation data itself, as we repeatedly tweak and test based on it. In the same way that the model is at risk of overfitting the training data, we are at risk of overfitting our hyperparameter choices to the validation data.</p>
<p>The solution to this dilemma is to add a further layer of withheld data: the <em>test set</em>. Just as the validation set is kept separate from training, the test set must be entirely reserved, even from our own tuning efforts. The test set should never be used to adjust or improve the model; instead, it is reserved solely for evaluating the final model’s performance. In this structure, the data is split into a hierarchy based on exposure: the training data is fully utilized, the validation data is partially used for tuning, and the test data is kept entirely hidden until the end. This hierarchy aligns with our modeling stages: training through backpropagation, manual hyperparameter tuning, and the ultimate evaluation of the model’s generalizability.</p>
<p>To get reliable accuracy estimates, both the test and validation sets should include enough data. For example, if you’re building a cat detector, you’ll want at least 30 images of cats in the validation set. If you have a large dataset, the standard 20% split for validation might be more than necessary; conversely, when data is plentiful, using some for validation usually has little impact on the model’s ability to generalize.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./chapters"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="17_kmeans.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Nonlinear Manifold Feature Extraction</p>
      </div>
    </a>
    <a class="right-next"
       href="23_NN_as_UA.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Neural Networks as Universal Approximators</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#neural-networks-a-brief-history">Neural Networks: A Brief History</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-to-learn-deep-learning">How to Learn Deep Learning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-software">The Software</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-a-neural-network">What Is a Neural Network?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#limitations-inherent-to-machine-learning">Limitations Inherent to Machine Learning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-our-medical-image-recognizer-works">How Our Medical Image Recognizer Works</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-neural-networks-make-predictions">How Neural Networks Make Predictions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#improving-the-model">Improving the Model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluating-model-performance">Evaluating Model Performance</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#limitations-and-ethical-considerations">Limitations and Ethical Considerations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#handling-overfitting">Handling Overfitting</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#transfer-learning">Transfer Learning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#deploying-the-model-for-real-world-use">Deploying the Model for Real-World Use</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#validation-sets-and-test-sets">Validation Sets and Test Sets</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Biagio Mandracchia
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>