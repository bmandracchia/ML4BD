{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "#hide\n",
    "from fastai.vision.all import *\n",
    "\n",
    "matplotlib.rc('image', cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Training a Digit Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll discuss the roles of arrays and tensors and of broadcasting, a powerful technique for using them expressively. \n",
    "We'll discuss the choice of a loss function for our basic classification task, and the role of mini-batches. \n",
    "We'll also describe the math that a basic neural network is actually doing. \n",
    "\n",
    "Finally, we'll put all these pieces together.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pixels: The Foundations of Computer Vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are just going to try to create a model that can classify any image as a 3 or a 7. So let's download a sample of MNIST that contains images of just these digits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.MNIST_SAMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "Path.BASE_PATH = path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see what's in this directory by using `ls`, a method added by fastai:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#3) [Path('labels.csv'),Path('valid'),Path('train')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The MNIST dataset follows a common layout for machine learning datasets: separate folders for the training set and the validation set (and/or test set). Let's see what's inside the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [Path('train/7'),Path('train/3')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(path/'train').ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a folder of 3s, and a folder of 7s. We say that \"3\" and \"7\" are the *labels* (or targets) in this dataset. Let's take a look in one of these folders (using `sorted` to ensure we all get the same order of files):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#6131) [Path('train/3/10.png'),Path('train/3/10000.png'),Path('train/3/10011.png'),Path('train/3/10031.png'),Path('train/3/10034.png'),Path('train/3/10042.png'),Path('train/3/10052.png'),Path('train/3/1007.png'),Path('train/3/10074.png'),Path('train/3/10091.png')...]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threes = (path/'train'/'3').ls().sorted()\n",
    "sevens = (path/'train'/'7').ls().sorted()\n",
    "threes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Here’s an image of a handwritten number 3, taken from the famous MNIST dataset of handwritten numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APCdP02+1a8W006znu7l+VigjLsQOpwO1dlb/CjVnkS3vNb8O6dqDkKtheaiFn3Hou1QcE8YBPcVg+LfCGqeCtYXS9WEPnvEJlML7lKEkA547qawatafqd/pN2LvTb24s7lQQJbeQowB6jI5r1D4Y6b4OvdXtdf8S+K45NY85phY3W6MeaCdrSTNw3IDcd8ZzyKx/i5pXiiLxMNZ8RC1kjvx/os1nJvh2KOFU8HgEHkc5zXntWdP0681a/hsbC3kubqY7Y4oxlmPXiu68OfBzxPq1yJNVtW0XTI/mnu73CbF74UkEn64HvVn4r+LdI1GDR/C3h2QzaTosXli5JJ858BeM9QAOvck9sV5nU1rdXFjdR3VpPLb3ETbo5YnKOh9QRyDV7UfE2v6vbi31PXNSvYA24RXN3JIufXDEjNZdFf/2Q==",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA9UlEQVR4AWNgGGSAEe4e2Upda8b/mwSvnloAF4MyDJY9+Pv31ZG/QPASTS72y8+/u/W4OFi4DiFLsoCV8XEyvCy9BGT++cfAsBlNJ7OICD9YSPvB369eaJJw7s+/X+vgHBQGX+r9vz9qUIRgHO5l74FO3S0H46PQAj9+gTzy4mo+E4o4lKOdlHQBJL9bDJssAwOncTlQ1ge7JAMD4/a/f7uhkhjm///PwHAXl87Qn3//quCQtLn29+9abuySSd///n3EiVVOa9ofYKSYostpFWvZFM//8Pfvr/WS6HIMu0GeB4KjYRhSDAzpYKkXzohUg0URtYQA/HZrR+ekLi0AAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im3_path = threes[1]\n",
    "im3 = Image.open(im3_path)\n",
    "im3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Here we are using the `Image` class from the *Python Imaging Library* (PIL), which is the most widely used Python package for opening, manipulating, and viewing images. Jupyter knows about PIL images, so it displays the image for us automatically.\n",
    "\n",
    "In a computer, everything is represented as a number. To view the numbers that make up this image, we have to convert it to a *NumPy array* or a *PyTorch tensor*. For instance, here's what a section of the image looks like, converted to a NumPy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,  29],\n",
       "       [  0,   0,   0,  48, 166, 224],\n",
       "       [  0,  93, 244, 249, 253, 187],\n",
       "       [  0, 107, 253, 253, 230,  48],\n",
       "       [  0,   3,  20,  20,  15,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array(im3)[4:10,4:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The `4:10` indicates we requested the rows from index 4 (included) to 10 (not included) and the same for the columns. NumPy indexes from top to bottom and left to right, so this section is located in the top-left corner of the image. Here's the same thing as a PyTorch tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,  29],\n",
       "        [  0,   0,   0,  48, 166, 224],\n",
       "        [  0,  93, 244, 249, 253, 187],\n",
       "        [  0, 107, 253, 253, 230,  48],\n",
       "        [  0,   3,  20,  20,  15,   0]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor(im3)[4:10,4:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can slice the array to pick just the part with the top of the digit in it, and then use a Pandas DataFrame to color-code the values using a gradient, which shows us clearly how the image is created from the pixel values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_37a93_row0_col0, #T_37a93_row0_col1, #T_37a93_row0_col2, #T_37a93_row0_col3, #T_37a93_row0_col4, #T_37a93_row0_col5, #T_37a93_row0_col6, #T_37a93_row0_col7, #T_37a93_row0_col8, #T_37a93_row0_col9, #T_37a93_row0_col10, #T_37a93_row0_col11, #T_37a93_row0_col12, #T_37a93_row0_col13, #T_37a93_row0_col14, #T_37a93_row0_col15, #T_37a93_row0_col16, #T_37a93_row0_col17, #T_37a93_row1_col0, #T_37a93_row1_col1, #T_37a93_row1_col2, #T_37a93_row1_col3, #T_37a93_row1_col4, #T_37a93_row1_col15, #T_37a93_row1_col16, #T_37a93_row1_col17, #T_37a93_row2_col0, #T_37a93_row2_col1, #T_37a93_row2_col2, #T_37a93_row2_col15, #T_37a93_row2_col16, #T_37a93_row2_col17, #T_37a93_row3_col0, #T_37a93_row3_col15, #T_37a93_row3_col16, #T_37a93_row3_col17, #T_37a93_row4_col0, #T_37a93_row4_col6, #T_37a93_row4_col7, #T_37a93_row4_col8, #T_37a93_row4_col9, #T_37a93_row4_col10, #T_37a93_row4_col15, #T_37a93_row4_col16, #T_37a93_row4_col17, #T_37a93_row5_col0, #T_37a93_row5_col5, #T_37a93_row5_col6, #T_37a93_row5_col7, #T_37a93_row5_col8, #T_37a93_row5_col9, #T_37a93_row5_col15, #T_37a93_row5_col16, #T_37a93_row5_col17, #T_37a93_row6_col0, #T_37a93_row6_col1, #T_37a93_row6_col2, #T_37a93_row6_col3, #T_37a93_row6_col4, #T_37a93_row6_col5, #T_37a93_row6_col6, #T_37a93_row6_col7, #T_37a93_row6_col8, #T_37a93_row6_col9, #T_37a93_row6_col14, #T_37a93_row6_col15, #T_37a93_row6_col16, #T_37a93_row6_col17, #T_37a93_row7_col0, #T_37a93_row7_col1, #T_37a93_row7_col2, #T_37a93_row7_col3, #T_37a93_row7_col4, #T_37a93_row7_col5, #T_37a93_row7_col6, #T_37a93_row7_col13, #T_37a93_row7_col14, #T_37a93_row7_col15, #T_37a93_row7_col16, #T_37a93_row7_col17, #T_37a93_row8_col0, #T_37a93_row8_col1, #T_37a93_row8_col2, #T_37a93_row8_col3, #T_37a93_row8_col4, #T_37a93_row8_col13, #T_37a93_row8_col14, #T_37a93_row8_col15, #T_37a93_row8_col16, #T_37a93_row8_col17, #T_37a93_row9_col0, #T_37a93_row9_col1, #T_37a93_row9_col2, #T_37a93_row9_col3, #T_37a93_row9_col4, #T_37a93_row9_col16, #T_37a93_row9_col17, #T_37a93_row10_col0, #T_37a93_row10_col1, #T_37a93_row10_col2, #T_37a93_row10_col3, #T_37a93_row10_col4, #T_37a93_row10_col5, #T_37a93_row10_col6, #T_37a93_row10_col17 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #ffffff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_37a93_row1_col5 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #efefef;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_37a93_row1_col6, #T_37a93_row1_col13 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #7c7c7c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_37a93_row1_col7 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #4a4a4a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_37a93_row1_col8, #T_37a93_row1_col9, #T_37a93_row1_col10, #T_37a93_row2_col5, #T_37a93_row2_col6, #T_37a93_row2_col7, #T_37a93_row2_col11, #T_37a93_row2_col12, #T_37a93_row2_col13, #T_37a93_row3_col4, #T_37a93_row3_col12, #T_37a93_row3_col13, #T_37a93_row4_col1, #T_37a93_row4_col2, #T_37a93_row4_col3, #T_37a93_row4_col12, #T_37a93_row4_col13, #T_37a93_row5_col12, #T_37a93_row6_col11, #T_37a93_row9_col11, #T_37a93_row10_col11, #T_37a93_row10_col12, #T_37a93_row10_col13, #T_37a93_row10_col14, #T_37a93_row10_col15, #T_37a93_row10_col16 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_37a93_row1_col11 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #606060;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_37a93_row1_col12 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #4d4d4d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_37a93_row1_col14 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #bbbbbb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_37a93_row2_col3 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #e4e4e4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_37a93_row2_col4, #T_37a93_row8_col6 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #6b6b6b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_37a93_row2_col8, #T_37a93_row2_col14, #T_37a93_row3_col14 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #171717;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_37a93_row2_col9, #T_37a93_row3_col11 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #4b4b4b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_37a93_row2_col10, #T_37a93_row7_col10, #T_37a93_row8_col8, #T_37a93_row8_col10, #T_37a93_row9_col8, #T_37a93_row9_col10 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #010101;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_37a93_row3_col1 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #272727;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_37a93_row3_col2 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #0a0a0a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_37a93_row3_col3 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #050505;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_37a93_row3_col5 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #333333;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_37a93_row3_col6 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #e6e6e6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_37a93_row3_col7, #T_37a93_row3_col10 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #fafafa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_37a93_row3_col8 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #fbfbfb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_37a93_row3_col9 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #fdfdfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_37a93_row4_col4 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #1b1b1b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_37a93_row4_col5 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #e0e0e0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_37a93_row4_col11 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #4e4e4e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_37a93_row4_col14 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #767676;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_37a93_row5_col1 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #fcfcfc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_37a93_row5_col2, #T_37a93_row5_col3 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #f6f6f6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_37a93_row5_col4, #T_37a93_row7_col7 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #f8f8f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_37a93_row5_col10, #T_37a93_row10_col7 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #e8e8e8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_37a93_row5_col11 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #222222;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_37a93_row5_col13, #T_37a93_row6_col12 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #090909;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_37a93_row5_col14 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #d0d0d0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_37a93_row6_col10, #T_37a93_row7_col11, #T_37a93_row9_col6 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #060606;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_37a93_row6_col13 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #979797;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_37a93_row7_col8 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #b6b6b6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_37a93_row7_col9 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #252525;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_37a93_row7_col12 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #999999;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_37a93_row8_col5 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #f9f9f9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_37a93_row8_col7 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #101010;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_37a93_row8_col9, #T_37a93_row9_col9 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #020202;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_37a93_row8_col11 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #545454;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_37a93_row8_col12 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #f1f1f1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_37a93_row9_col5 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #f7f7f7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_37a93_row9_col7 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #030303;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_37a93_row9_col12 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #181818;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_37a93_row9_col13 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #303030;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_37a93_row9_col14 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #a9a9a9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_37a93_row9_col15 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #fefefe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_37a93_row10_col8, #T_37a93_row10_col9 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #bababa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_37a93_row10_col10 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #393939;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_37a93\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_37a93_level0_col0\" class=\"col_heading level0 col0\" >0</th>\n",
       "      <th id=\"T_37a93_level0_col1\" class=\"col_heading level0 col1\" >1</th>\n",
       "      <th id=\"T_37a93_level0_col2\" class=\"col_heading level0 col2\" >2</th>\n",
       "      <th id=\"T_37a93_level0_col3\" class=\"col_heading level0 col3\" >3</th>\n",
       "      <th id=\"T_37a93_level0_col4\" class=\"col_heading level0 col4\" >4</th>\n",
       "      <th id=\"T_37a93_level0_col5\" class=\"col_heading level0 col5\" >5</th>\n",
       "      <th id=\"T_37a93_level0_col6\" class=\"col_heading level0 col6\" >6</th>\n",
       "      <th id=\"T_37a93_level0_col7\" class=\"col_heading level0 col7\" >7</th>\n",
       "      <th id=\"T_37a93_level0_col8\" class=\"col_heading level0 col8\" >8</th>\n",
       "      <th id=\"T_37a93_level0_col9\" class=\"col_heading level0 col9\" >9</th>\n",
       "      <th id=\"T_37a93_level0_col10\" class=\"col_heading level0 col10\" >10</th>\n",
       "      <th id=\"T_37a93_level0_col11\" class=\"col_heading level0 col11\" >11</th>\n",
       "      <th id=\"T_37a93_level0_col12\" class=\"col_heading level0 col12\" >12</th>\n",
       "      <th id=\"T_37a93_level0_col13\" class=\"col_heading level0 col13\" >13</th>\n",
       "      <th id=\"T_37a93_level0_col14\" class=\"col_heading level0 col14\" >14</th>\n",
       "      <th id=\"T_37a93_level0_col15\" class=\"col_heading level0 col15\" >15</th>\n",
       "      <th id=\"T_37a93_level0_col16\" class=\"col_heading level0 col16\" >16</th>\n",
       "      <th id=\"T_37a93_level0_col17\" class=\"col_heading level0 col17\" >17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_37a93_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_37a93_row0_col0\" class=\"data row0 col0\" >0</td>\n",
       "      <td id=\"T_37a93_row0_col1\" class=\"data row0 col1\" >0</td>\n",
       "      <td id=\"T_37a93_row0_col2\" class=\"data row0 col2\" >0</td>\n",
       "      <td id=\"T_37a93_row0_col3\" class=\"data row0 col3\" >0</td>\n",
       "      <td id=\"T_37a93_row0_col4\" class=\"data row0 col4\" >0</td>\n",
       "      <td id=\"T_37a93_row0_col5\" class=\"data row0 col5\" >0</td>\n",
       "      <td id=\"T_37a93_row0_col6\" class=\"data row0 col6\" >0</td>\n",
       "      <td id=\"T_37a93_row0_col7\" class=\"data row0 col7\" >0</td>\n",
       "      <td id=\"T_37a93_row0_col8\" class=\"data row0 col8\" >0</td>\n",
       "      <td id=\"T_37a93_row0_col9\" class=\"data row0 col9\" >0</td>\n",
       "      <td id=\"T_37a93_row0_col10\" class=\"data row0 col10\" >0</td>\n",
       "      <td id=\"T_37a93_row0_col11\" class=\"data row0 col11\" >0</td>\n",
       "      <td id=\"T_37a93_row0_col12\" class=\"data row0 col12\" >0</td>\n",
       "      <td id=\"T_37a93_row0_col13\" class=\"data row0 col13\" >0</td>\n",
       "      <td id=\"T_37a93_row0_col14\" class=\"data row0 col14\" >0</td>\n",
       "      <td id=\"T_37a93_row0_col15\" class=\"data row0 col15\" >0</td>\n",
       "      <td id=\"T_37a93_row0_col16\" class=\"data row0 col16\" >0</td>\n",
       "      <td id=\"T_37a93_row0_col17\" class=\"data row0 col17\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_37a93_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_37a93_row1_col0\" class=\"data row1 col0\" >0</td>\n",
       "      <td id=\"T_37a93_row1_col1\" class=\"data row1 col1\" >0</td>\n",
       "      <td id=\"T_37a93_row1_col2\" class=\"data row1 col2\" >0</td>\n",
       "      <td id=\"T_37a93_row1_col3\" class=\"data row1 col3\" >0</td>\n",
       "      <td id=\"T_37a93_row1_col4\" class=\"data row1 col4\" >0</td>\n",
       "      <td id=\"T_37a93_row1_col5\" class=\"data row1 col5\" >29</td>\n",
       "      <td id=\"T_37a93_row1_col6\" class=\"data row1 col6\" >150</td>\n",
       "      <td id=\"T_37a93_row1_col7\" class=\"data row1 col7\" >195</td>\n",
       "      <td id=\"T_37a93_row1_col8\" class=\"data row1 col8\" >254</td>\n",
       "      <td id=\"T_37a93_row1_col9\" class=\"data row1 col9\" >255</td>\n",
       "      <td id=\"T_37a93_row1_col10\" class=\"data row1 col10\" >254</td>\n",
       "      <td id=\"T_37a93_row1_col11\" class=\"data row1 col11\" >176</td>\n",
       "      <td id=\"T_37a93_row1_col12\" class=\"data row1 col12\" >193</td>\n",
       "      <td id=\"T_37a93_row1_col13\" class=\"data row1 col13\" >150</td>\n",
       "      <td id=\"T_37a93_row1_col14\" class=\"data row1 col14\" >96</td>\n",
       "      <td id=\"T_37a93_row1_col15\" class=\"data row1 col15\" >0</td>\n",
       "      <td id=\"T_37a93_row1_col16\" class=\"data row1 col16\" >0</td>\n",
       "      <td id=\"T_37a93_row1_col17\" class=\"data row1 col17\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_37a93_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_37a93_row2_col0\" class=\"data row2 col0\" >0</td>\n",
       "      <td id=\"T_37a93_row2_col1\" class=\"data row2 col1\" >0</td>\n",
       "      <td id=\"T_37a93_row2_col2\" class=\"data row2 col2\" >0</td>\n",
       "      <td id=\"T_37a93_row2_col3\" class=\"data row2 col3\" >48</td>\n",
       "      <td id=\"T_37a93_row2_col4\" class=\"data row2 col4\" >166</td>\n",
       "      <td id=\"T_37a93_row2_col5\" class=\"data row2 col5\" >224</td>\n",
       "      <td id=\"T_37a93_row2_col6\" class=\"data row2 col6\" >253</td>\n",
       "      <td id=\"T_37a93_row2_col7\" class=\"data row2 col7\" >253</td>\n",
       "      <td id=\"T_37a93_row2_col8\" class=\"data row2 col8\" >234</td>\n",
       "      <td id=\"T_37a93_row2_col9\" class=\"data row2 col9\" >196</td>\n",
       "      <td id=\"T_37a93_row2_col10\" class=\"data row2 col10\" >253</td>\n",
       "      <td id=\"T_37a93_row2_col11\" class=\"data row2 col11\" >253</td>\n",
       "      <td id=\"T_37a93_row2_col12\" class=\"data row2 col12\" >253</td>\n",
       "      <td id=\"T_37a93_row2_col13\" class=\"data row2 col13\" >253</td>\n",
       "      <td id=\"T_37a93_row2_col14\" class=\"data row2 col14\" >233</td>\n",
       "      <td id=\"T_37a93_row2_col15\" class=\"data row2 col15\" >0</td>\n",
       "      <td id=\"T_37a93_row2_col16\" class=\"data row2 col16\" >0</td>\n",
       "      <td id=\"T_37a93_row2_col17\" class=\"data row2 col17\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_37a93_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_37a93_row3_col0\" class=\"data row3 col0\" >0</td>\n",
       "      <td id=\"T_37a93_row3_col1\" class=\"data row3 col1\" >93</td>\n",
       "      <td id=\"T_37a93_row3_col2\" class=\"data row3 col2\" >244</td>\n",
       "      <td id=\"T_37a93_row3_col3\" class=\"data row3 col3\" >249</td>\n",
       "      <td id=\"T_37a93_row3_col4\" class=\"data row3 col4\" >253</td>\n",
       "      <td id=\"T_37a93_row3_col5\" class=\"data row3 col5\" >187</td>\n",
       "      <td id=\"T_37a93_row3_col6\" class=\"data row3 col6\" >46</td>\n",
       "      <td id=\"T_37a93_row3_col7\" class=\"data row3 col7\" >10</td>\n",
       "      <td id=\"T_37a93_row3_col8\" class=\"data row3 col8\" >8</td>\n",
       "      <td id=\"T_37a93_row3_col9\" class=\"data row3 col9\" >4</td>\n",
       "      <td id=\"T_37a93_row3_col10\" class=\"data row3 col10\" >10</td>\n",
       "      <td id=\"T_37a93_row3_col11\" class=\"data row3 col11\" >194</td>\n",
       "      <td id=\"T_37a93_row3_col12\" class=\"data row3 col12\" >253</td>\n",
       "      <td id=\"T_37a93_row3_col13\" class=\"data row3 col13\" >253</td>\n",
       "      <td id=\"T_37a93_row3_col14\" class=\"data row3 col14\" >233</td>\n",
       "      <td id=\"T_37a93_row3_col15\" class=\"data row3 col15\" >0</td>\n",
       "      <td id=\"T_37a93_row3_col16\" class=\"data row3 col16\" >0</td>\n",
       "      <td id=\"T_37a93_row3_col17\" class=\"data row3 col17\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_37a93_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_37a93_row4_col0\" class=\"data row4 col0\" >0</td>\n",
       "      <td id=\"T_37a93_row4_col1\" class=\"data row4 col1\" >107</td>\n",
       "      <td id=\"T_37a93_row4_col2\" class=\"data row4 col2\" >253</td>\n",
       "      <td id=\"T_37a93_row4_col3\" class=\"data row4 col3\" >253</td>\n",
       "      <td id=\"T_37a93_row4_col4\" class=\"data row4 col4\" >230</td>\n",
       "      <td id=\"T_37a93_row4_col5\" class=\"data row4 col5\" >48</td>\n",
       "      <td id=\"T_37a93_row4_col6\" class=\"data row4 col6\" >0</td>\n",
       "      <td id=\"T_37a93_row4_col7\" class=\"data row4 col7\" >0</td>\n",
       "      <td id=\"T_37a93_row4_col8\" class=\"data row4 col8\" >0</td>\n",
       "      <td id=\"T_37a93_row4_col9\" class=\"data row4 col9\" >0</td>\n",
       "      <td id=\"T_37a93_row4_col10\" class=\"data row4 col10\" >0</td>\n",
       "      <td id=\"T_37a93_row4_col11\" class=\"data row4 col11\" >192</td>\n",
       "      <td id=\"T_37a93_row4_col12\" class=\"data row4 col12\" >253</td>\n",
       "      <td id=\"T_37a93_row4_col13\" class=\"data row4 col13\" >253</td>\n",
       "      <td id=\"T_37a93_row4_col14\" class=\"data row4 col14\" >156</td>\n",
       "      <td id=\"T_37a93_row4_col15\" class=\"data row4 col15\" >0</td>\n",
       "      <td id=\"T_37a93_row4_col16\" class=\"data row4 col16\" >0</td>\n",
       "      <td id=\"T_37a93_row4_col17\" class=\"data row4 col17\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_37a93_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_37a93_row5_col0\" class=\"data row5 col0\" >0</td>\n",
       "      <td id=\"T_37a93_row5_col1\" class=\"data row5 col1\" >3</td>\n",
       "      <td id=\"T_37a93_row5_col2\" class=\"data row5 col2\" >20</td>\n",
       "      <td id=\"T_37a93_row5_col3\" class=\"data row5 col3\" >20</td>\n",
       "      <td id=\"T_37a93_row5_col4\" class=\"data row5 col4\" >15</td>\n",
       "      <td id=\"T_37a93_row5_col5\" class=\"data row5 col5\" >0</td>\n",
       "      <td id=\"T_37a93_row5_col6\" class=\"data row5 col6\" >0</td>\n",
       "      <td id=\"T_37a93_row5_col7\" class=\"data row5 col7\" >0</td>\n",
       "      <td id=\"T_37a93_row5_col8\" class=\"data row5 col8\" >0</td>\n",
       "      <td id=\"T_37a93_row5_col9\" class=\"data row5 col9\" >0</td>\n",
       "      <td id=\"T_37a93_row5_col10\" class=\"data row5 col10\" >43</td>\n",
       "      <td id=\"T_37a93_row5_col11\" class=\"data row5 col11\" >224</td>\n",
       "      <td id=\"T_37a93_row5_col12\" class=\"data row5 col12\" >253</td>\n",
       "      <td id=\"T_37a93_row5_col13\" class=\"data row5 col13\" >245</td>\n",
       "      <td id=\"T_37a93_row5_col14\" class=\"data row5 col14\" >74</td>\n",
       "      <td id=\"T_37a93_row5_col15\" class=\"data row5 col15\" >0</td>\n",
       "      <td id=\"T_37a93_row5_col16\" class=\"data row5 col16\" >0</td>\n",
       "      <td id=\"T_37a93_row5_col17\" class=\"data row5 col17\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_37a93_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_37a93_row6_col0\" class=\"data row6 col0\" >0</td>\n",
       "      <td id=\"T_37a93_row6_col1\" class=\"data row6 col1\" >0</td>\n",
       "      <td id=\"T_37a93_row6_col2\" class=\"data row6 col2\" >0</td>\n",
       "      <td id=\"T_37a93_row6_col3\" class=\"data row6 col3\" >0</td>\n",
       "      <td id=\"T_37a93_row6_col4\" class=\"data row6 col4\" >0</td>\n",
       "      <td id=\"T_37a93_row6_col5\" class=\"data row6 col5\" >0</td>\n",
       "      <td id=\"T_37a93_row6_col6\" class=\"data row6 col6\" >0</td>\n",
       "      <td id=\"T_37a93_row6_col7\" class=\"data row6 col7\" >0</td>\n",
       "      <td id=\"T_37a93_row6_col8\" class=\"data row6 col8\" >0</td>\n",
       "      <td id=\"T_37a93_row6_col9\" class=\"data row6 col9\" >0</td>\n",
       "      <td id=\"T_37a93_row6_col10\" class=\"data row6 col10\" >249</td>\n",
       "      <td id=\"T_37a93_row6_col11\" class=\"data row6 col11\" >253</td>\n",
       "      <td id=\"T_37a93_row6_col12\" class=\"data row6 col12\" >245</td>\n",
       "      <td id=\"T_37a93_row6_col13\" class=\"data row6 col13\" >126</td>\n",
       "      <td id=\"T_37a93_row6_col14\" class=\"data row6 col14\" >0</td>\n",
       "      <td id=\"T_37a93_row6_col15\" class=\"data row6 col15\" >0</td>\n",
       "      <td id=\"T_37a93_row6_col16\" class=\"data row6 col16\" >0</td>\n",
       "      <td id=\"T_37a93_row6_col17\" class=\"data row6 col17\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_37a93_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_37a93_row7_col0\" class=\"data row7 col0\" >0</td>\n",
       "      <td id=\"T_37a93_row7_col1\" class=\"data row7 col1\" >0</td>\n",
       "      <td id=\"T_37a93_row7_col2\" class=\"data row7 col2\" >0</td>\n",
       "      <td id=\"T_37a93_row7_col3\" class=\"data row7 col3\" >0</td>\n",
       "      <td id=\"T_37a93_row7_col4\" class=\"data row7 col4\" >0</td>\n",
       "      <td id=\"T_37a93_row7_col5\" class=\"data row7 col5\" >0</td>\n",
       "      <td id=\"T_37a93_row7_col6\" class=\"data row7 col6\" >0</td>\n",
       "      <td id=\"T_37a93_row7_col7\" class=\"data row7 col7\" >14</td>\n",
       "      <td id=\"T_37a93_row7_col8\" class=\"data row7 col8\" >101</td>\n",
       "      <td id=\"T_37a93_row7_col9\" class=\"data row7 col9\" >223</td>\n",
       "      <td id=\"T_37a93_row7_col10\" class=\"data row7 col10\" >253</td>\n",
       "      <td id=\"T_37a93_row7_col11\" class=\"data row7 col11\" >248</td>\n",
       "      <td id=\"T_37a93_row7_col12\" class=\"data row7 col12\" >124</td>\n",
       "      <td id=\"T_37a93_row7_col13\" class=\"data row7 col13\" >0</td>\n",
       "      <td id=\"T_37a93_row7_col14\" class=\"data row7 col14\" >0</td>\n",
       "      <td id=\"T_37a93_row7_col15\" class=\"data row7 col15\" >0</td>\n",
       "      <td id=\"T_37a93_row7_col16\" class=\"data row7 col16\" >0</td>\n",
       "      <td id=\"T_37a93_row7_col17\" class=\"data row7 col17\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_37a93_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_37a93_row8_col0\" class=\"data row8 col0\" >0</td>\n",
       "      <td id=\"T_37a93_row8_col1\" class=\"data row8 col1\" >0</td>\n",
       "      <td id=\"T_37a93_row8_col2\" class=\"data row8 col2\" >0</td>\n",
       "      <td id=\"T_37a93_row8_col3\" class=\"data row8 col3\" >0</td>\n",
       "      <td id=\"T_37a93_row8_col4\" class=\"data row8 col4\" >0</td>\n",
       "      <td id=\"T_37a93_row8_col5\" class=\"data row8 col5\" >11</td>\n",
       "      <td id=\"T_37a93_row8_col6\" class=\"data row8 col6\" >166</td>\n",
       "      <td id=\"T_37a93_row8_col7\" class=\"data row8 col7\" >239</td>\n",
       "      <td id=\"T_37a93_row8_col8\" class=\"data row8 col8\" >253</td>\n",
       "      <td id=\"T_37a93_row8_col9\" class=\"data row8 col9\" >253</td>\n",
       "      <td id=\"T_37a93_row8_col10\" class=\"data row8 col10\" >253</td>\n",
       "      <td id=\"T_37a93_row8_col11\" class=\"data row8 col11\" >187</td>\n",
       "      <td id=\"T_37a93_row8_col12\" class=\"data row8 col12\" >30</td>\n",
       "      <td id=\"T_37a93_row8_col13\" class=\"data row8 col13\" >0</td>\n",
       "      <td id=\"T_37a93_row8_col14\" class=\"data row8 col14\" >0</td>\n",
       "      <td id=\"T_37a93_row8_col15\" class=\"data row8 col15\" >0</td>\n",
       "      <td id=\"T_37a93_row8_col16\" class=\"data row8 col16\" >0</td>\n",
       "      <td id=\"T_37a93_row8_col17\" class=\"data row8 col17\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_37a93_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_37a93_row9_col0\" class=\"data row9 col0\" >0</td>\n",
       "      <td id=\"T_37a93_row9_col1\" class=\"data row9 col1\" >0</td>\n",
       "      <td id=\"T_37a93_row9_col2\" class=\"data row9 col2\" >0</td>\n",
       "      <td id=\"T_37a93_row9_col3\" class=\"data row9 col3\" >0</td>\n",
       "      <td id=\"T_37a93_row9_col4\" class=\"data row9 col4\" >0</td>\n",
       "      <td id=\"T_37a93_row9_col5\" class=\"data row9 col5\" >16</td>\n",
       "      <td id=\"T_37a93_row9_col6\" class=\"data row9 col6\" >248</td>\n",
       "      <td id=\"T_37a93_row9_col7\" class=\"data row9 col7\" >250</td>\n",
       "      <td id=\"T_37a93_row9_col8\" class=\"data row9 col8\" >253</td>\n",
       "      <td id=\"T_37a93_row9_col9\" class=\"data row9 col9\" >253</td>\n",
       "      <td id=\"T_37a93_row9_col10\" class=\"data row9 col10\" >253</td>\n",
       "      <td id=\"T_37a93_row9_col11\" class=\"data row9 col11\" >253</td>\n",
       "      <td id=\"T_37a93_row9_col12\" class=\"data row9 col12\" >232</td>\n",
       "      <td id=\"T_37a93_row9_col13\" class=\"data row9 col13\" >213</td>\n",
       "      <td id=\"T_37a93_row9_col14\" class=\"data row9 col14\" >111</td>\n",
       "      <td id=\"T_37a93_row9_col15\" class=\"data row9 col15\" >2</td>\n",
       "      <td id=\"T_37a93_row9_col16\" class=\"data row9 col16\" >0</td>\n",
       "      <td id=\"T_37a93_row9_col17\" class=\"data row9 col17\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_37a93_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_37a93_row10_col0\" class=\"data row10 col0\" >0</td>\n",
       "      <td id=\"T_37a93_row10_col1\" class=\"data row10 col1\" >0</td>\n",
       "      <td id=\"T_37a93_row10_col2\" class=\"data row10 col2\" >0</td>\n",
       "      <td id=\"T_37a93_row10_col3\" class=\"data row10 col3\" >0</td>\n",
       "      <td id=\"T_37a93_row10_col4\" class=\"data row10 col4\" >0</td>\n",
       "      <td id=\"T_37a93_row10_col5\" class=\"data row10 col5\" >0</td>\n",
       "      <td id=\"T_37a93_row10_col6\" class=\"data row10 col6\" >0</td>\n",
       "      <td id=\"T_37a93_row10_col7\" class=\"data row10 col7\" >43</td>\n",
       "      <td id=\"T_37a93_row10_col8\" class=\"data row10 col8\" >98</td>\n",
       "      <td id=\"T_37a93_row10_col9\" class=\"data row10 col9\" >98</td>\n",
       "      <td id=\"T_37a93_row10_col10\" class=\"data row10 col10\" >208</td>\n",
       "      <td id=\"T_37a93_row10_col11\" class=\"data row10 col11\" >253</td>\n",
       "      <td id=\"T_37a93_row10_col12\" class=\"data row10 col12\" >253</td>\n",
       "      <td id=\"T_37a93_row10_col13\" class=\"data row10 col13\" >253</td>\n",
       "      <td id=\"T_37a93_row10_col14\" class=\"data row10 col14\" >253</td>\n",
       "      <td id=\"T_37a93_row10_col15\" class=\"data row10 col15\" >187</td>\n",
       "      <td id=\"T_37a93_row10_col16\" class=\"data row10 col16\" >22</td>\n",
       "      <td id=\"T_37a93_row10_col17\" class=\"data row10 col17\" >0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fa18d4f9850>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide_output\n",
    "im3_t = tensor(im3)\n",
    "df = pd.DataFrame(im3_t[4:15,4:22])\n",
    "df.style.set_properties(**{'font-size':'6pt'}).background_gradient('Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the background white pixels are stored as the number 0, black is the number 255, and shades of gray are between the two. The entire image contains 28 pixels across and 28 pixels down, for a total of 784 pixels.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pixel Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a baseline, let-s's find the average pixel value for every pixel of the 3s, then do the same for the 7s. This will give us two group averages, defining what we might call the \"ideal\" 3 and 7. Then, to classify an image as one digit or the other, we see which of these two ideal digits the image is most similar to. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step one for our simple model is to get the average of pixel values for each of our two groups. \n",
    "\n",
    "Let's create a tensor containing all of our 3s stacked together. To create a tensor containing all the images in a directory, we will first use a Python list comprehension to create a plain list of the single image tensors.\n",
    "\n",
    "We will use Jupyter to do some little checks of our work along the way—in this case, making sure that the number of returned items seems reasonable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6131, 6265)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seven_tensors = [tensor(Image.open(o)) for o in sevens]\n",
    "three_tensors = [tensor(Image.open(o)) for o in threes]\n",
    "len(three_tensors),len(seven_tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We'll also check that one of the images looks okay. Since we now have tensors (which Jupyter by default will print as values), rather than PIL images (which Jupyter by default will display as images), we need to use fastai's `show_image` function to display it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_image(three_tensors[1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For every pixel position, we want to compute the average over all the images of the intensity of that pixel. To do this we first combine all the images in this list into a single three-dimensional tensor. The most common way to describe such a tensor is to call it a *rank-3 tensor*. We often need to stack up individual tensors in a collection into a single tensor. Unsurprisingly, PyTorch comes with a function called `stack` that we can use for this purpose.\n",
    "\n",
    "Some operations in PyTorch, such as taking a mean, require us to *cast* our integer types to float types. Since we'll be needing this later, we'll also cast our stacked tensor to `float` now. Casting in PyTorch is as simple as typing the name of the type you wish to cast to, and treating it as a method.\n",
    "\n",
    "Generally when images are floats, the pixel values are expected to be between 0 and 1, so we will also divide by 255 here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6131, 28, 28])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_sevens = torch.stack(seven_tensors).float()/255\n",
    "stacked_threes = torch.stack(three_tensors).float()/255\n",
    "stacked_threes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Perhaps the most important attribute of a tensor is its *shape*. This tells you the length of each axis. In this case, we can see that we have 6,131 images, each of size 28×28 pixels. There is nothing specifically about this tensor that says that the first axis is the number of images, the second is the height, and the third is the width—the semantics of a tensor are entirely up to us, and how we construct it. As far as PyTorch is concerned, it is just a bunch of numbers in memory.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can compute what the ideal 3 looks like. We calculate the mean of all the image tensors by taking the mean along dimension 0 of our stacked, rank-3 tensor. This is the dimension that indexes over all the images.\n",
    "\n",
    "In other words, for every pixel position, this will compute the average of that pixel over all images. The result will be one value for every pixel position, or a single image. Here it is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean3 = stacked_threes.mean(0)\n",
    "show_image(mean3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to this dataset, this is the ideal number 3! (You may not like it, but this is what peak number 3 performance looks like.) You can see how it's very dark where all the images agree it should be dark, but it becomes wispy and blurry where the images disagree. \n",
    "\n",
    "Let's do the same thing for the 7s, but put all the steps together at once to save some time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean7 = stacked_sevens.mean(0)\n",
    "show_image(mean7);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's now pick an arbitrary 3 and measure its *distance* from our \"ideal digits.\"\n",
    "\n",
    "> How would you calculate how similar a particular image is to each of our ideal digits?\n",
    "\n",
    "Here's a sample 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a_3 = stacked_threes[1]\n",
    "show_image(a_3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "How can we determine its distance from our ideal 3? We can't just add up the differences between the pixels of this image and the ideal digit. Some differences will be positive while others will be negative, and these differences will cancel out, resulting in a situation where an image that is too dark in some places and too light in others might be shown as having zero total differences from the ideal. That would be misleading!\n",
    "\n",
    "To avoid this, there are two main ways data scientists measure distance in this context:\n",
    "\n",
    "- Take the mean of the *absolute value* of differences (absolute value is the function that replaces negative values with positive values). This is called the *mean absolute difference* or *L1 norm*\n",
    "- Take the mean of the *square* of differences (which makes everything positive) and then take the *square root* (which undoes the squaring). This is called the *root mean squared error* (RMSE) or *L2 norm*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's try both of these now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1114), tensor(0.2021))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_3_abs = (a_3 - mean3).abs().mean()\n",
    "dist_3_sqr = ((a_3 - mean3)**2).mean().sqrt()\n",
    "dist_3_abs,dist_3_sqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1586), tensor(0.3021))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_7_abs = (a_3 - mean7).abs().mean()\n",
    "dist_7_sqr = ((a_3 - mean7)**2).mean().sqrt()\n",
    "dist_7_abs,dist_7_sqr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In both cases, the distance between our 3 and the \"ideal\" 3 is less than the distance to the ideal 7. So our simple model will give the right prediction in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch already provides both of these as *loss functions*. You'll find these inside `torch.nn.functional`, which the PyTorch team recommends importing as `F` (and is available by default under that name in fastai):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1586), tensor(0.3021))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.l1_loss(a_3.float(),mean7), F.mse_loss(a_3,mean7).sqrt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here `mse` stands for *mean squared error*, and `l1` refers to the standard mathematical jargon for *mean absolute value* (in math it's called the *L1 norm*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    ">  Intuitively, the difference between L1 norm and mean squared error (MSE) is that the latter will penalize bigger mistakes more heavily than the former (and be more lenient with small mistakes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just completed various mathematical operations on PyTorch tensors. Let's have a look at those two very important data structures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### NumPy Arrays and PyTorch Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[NumPy](https://numpy.org/) is the most widely used library for scientific and numeric programming in Python. It provides very similar functionality and a very similar API to that provided by PyTorch; however, it does not support using the GPU or calculating gradients, which are both critical for deep learning. Therefore, we will generally use PyTorch tensors instead of NumPy arrays, where possible.\n",
    "\n",
    "(Note that fastai adds some features to NumPy and PyTorch to make them a bit more similar to each other. If any code in this notebook doesn't work on your computer, it's possible that you forgot to include a line like this at the start of your notebook: `from fastai.vision.all import *`.)\n",
    "\n",
    "But what are arrays and tensors, and why should you care?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Python is slow compared to many languages. Anything fast in Python, NumPy, or PyTorch is likely to be a wrapper for a compiled object written (and optimized) in another language—specifically C. In fact, **NumPy arrays and PyTorch tensors can finish computations many thousands of times faster than using pure Python.**\n",
    "\n",
    "A NumPy array is a multidimensional table of data, with all items of the same type. Since that can be any type at all, they can even be arrays of arrays, with the innermost arrays potentially being different sizes—this is called a \"jagged array.\" By \"multidimensional table\" we mean, for instance, a list (dimension of one), a table or matrix (dimension of two), a \"table of tables\" or \"cube\" (dimension of three), and so forth. If the items are all of some simple type such as integer or float, then NumPy will store them as a compact C data structure in memory. This is where NumPy shines. NumPy has a wide variety of operators and methods that can run computations on these compact structures at the same speed as optimized C, because they are written in optimized C.\n",
    "\n",
    "A PyTorch tensor is nearly the same thing as a NumPy array, but with an additional restriction that unlocks some additional capabilities. It's the same in that it, too, is a multidimensional table of data, with all items of the same type. However, the restriction is that a tensor cannot use just any old type—it has to use a single basic numeric type for all components. For example, a PyTorch tensor cannot be jagged. It is always a regularly shaped multidimensional rectangular structure.\n",
    "\n",
    "The vast majority of methods and operators supported by NumPy on these structures are also supported by PyTorch, but PyTorch tensors have additional capabilities. One major capability is that these structures can live on the GPU, in which case their computation will be optimized for the GPU and can run much faster (given lots of values to work on). In addition, PyTorch can automatically calculate derivatives of these operations, including combinations of operations. As you'll see, it would be impossible to do deep learning in practice without this capability.\n",
    "\n",
    "> To take advantage of Pytorch speed, try to avoid as much as possible writing loops, and replace them by commands that work directly on arrays or tensors.\n",
    "\n",
    "Perhaps the most important new coding skill for a Python programmer to learn is how to effectively use the array/tensor APIs. Here's a summary of the key things you need to know for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To create an array or tensor, pass a list (or list of lists, or list of lists of lists, etc.) to `array()` or `tensor()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[1,2,3],[4,5,6]]\n",
    "arr = array (data)\n",
    "tns = tensor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr  # numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tns  # pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "All the operations that follow are shown on tensors, but the syntax and results for NumPy arrays is identical.\n",
    "\n",
    "You can select a row (note that, like lists in Python, tensors are 0-indexed so 1 refers to the second row/column):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 5, 6])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tns[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or a column, by using `:` to indicate *all of the first axis* (we sometimes refer to the dimensions of tensors/arrays as *axes*):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 5])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tns[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "You can combine these with Python slice syntax (`[start:end]` with `end` being excluded) to select part of a row or column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 6])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tns[1,1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And you can use the standard operators such as `+`, `-`, `*`, `/`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 3, 4],\n",
       "        [5, 6, 7]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tns+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Tensors have a type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.LongTensor'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tns.type()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And will automatically change type as needed, for example from `int` to `float`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.5000, 3.0000, 4.5000],\n",
       "        [6.0000, 7.5000, 9.0000]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tns*1.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, is our baseline model any good? To quantify this, we must define a metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Computing Metrics Using Broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that a metric is a number that is calculated based on the predictions of our model, and the correct labels in our dataset, in order to tell us how good our model is. For instance, we could use either of the functions we saw in the previous section, mean squared error, or mean absolute error, and take the average of them over the whole dataset. However, neither of these are numbers that are very understandable to most people; in practice, we normally use *accuracy* as the metric for classification models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1010, 28, 28]), torch.Size([1028, 28, 28]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_3_tens = torch.stack([tensor(Image.open(o)) \n",
    "                            for o in (path/'valid'/'3').ls()])\n",
    "valid_3_tens = valid_3_tens.float()/255\n",
    "valid_7_tens = torch.stack([tensor(Image.open(o)) \n",
    "                            for o in (path/'valid'/'7').ls()])\n",
    "valid_7_tens = valid_7_tens.float()/255\n",
    "valid_3_tens.shape,valid_7_tens.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "It's good to get in the habit of checking shapes as you go. Here we see two tensors, one representing the 3s validation set of 1,010 images of size 28×28, and one representing the 7s validation set of 1,028 images of size 28×28.\n",
    "\n",
    "We ultimately want to write a function, `is_3`, that will decide if an arbitrary image is a 3 or a 7. It will do this by deciding which of our two \"ideal digits\" this arbitrary image is closer to. For that we need to define a notion of distance—that is, a function that calculates the distance between two images.\n",
    "\n",
    "We can write a simple function that calculates the mean absolute error using an expression very similar to the one we wrote in the last section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1114)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mnist_distance(a,b): return (a-b).abs().mean((-1,-2))\n",
    "mnist_distance(a_3, mean3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This is the same value we previously calculated for the distance between these two images, the ideal 3 `mean3` and the arbitrary sample 3 `a_3`, which are both single-image tensors with a shape of `[28,28]`.\n",
    "\n",
    "But in order to calculate a metric for overall accuracy, we will need to calculate the distance to the ideal 3 for _every_ image in the validation set. How do we do that calculation? We could write a loop over all of the single-image tensors that are stacked within our validation set tensor, `valid_3_tens`, which has a shape of `[1010,28,28]` representing 1,010 images. But there is a better way.\n",
    "\n",
    "Something very interesting happens when we take this exact same distance function, designed for comparing two single images, but pass in as an argument `valid_3_tens`, the tensor that represents the 3s validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.1488, 0.1145, 0.1158,  ..., 0.1129, 0.1419, 0.1669]),\n",
       " torch.Size([1010]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_3_dist = mnist_distance(valid_3_tens, mean3)\n",
    "valid_3_dist, valid_3_dist.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Instead of complaining about shapes not matching, it returned the distance for every single image as a vector (i.e., a rank-1 tensor) of length 1,010 (the number of 3s in our validation set). How did that happen?\n",
    "\n",
    "Take another look at our function `mnist_distance`, and you'll see we have there the subtraction `(a-b)`. The magic trick is that PyTorch, when it tries to perform a simple subtraction operation between two tensors of different ranks, will use *broadcasting*. That is, it will automatically expand the tensor with the smaller rank to have the same size as the one with the larger rank. Broadcasting is an important capability that makes tensor code much easier to write.\n",
    "\n",
    "After broadcasting so the two argument tensors have the same rank, PyTorch applies its usual logic for two tensors of the same rank: it performs the operation on each corresponding element of the two tensors, and returns the tensor result. For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 3, 4])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor([1,2,3]) + tensor(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in this case, PyTorch treats `mean3`, a rank-2 tensor representing a single image, as if it were 1,010 copies of the same image, and then subtracts each of those copies from each 3 in our validation set. What shape would you expect this tensor to have? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1010, 28, 28])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(valid_3_tens-mean3).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We are calculating the difference between our \"ideal 3\" and each of the 1,010 3s in the validation set, for each of 28×28 images, resulting in the shape `[1010,28,28]`.\n",
    "\n",
    "There are a couple of important points about how broadcasting is implemented, which make it valuable not just for expressivity but also for performance:\n",
    "\n",
    "- PyTorch doesn't *actually* copy `mean3` 1,010 times. It *pretends* it were a tensor of that shape, but doesn't actually allocate any additional memory\n",
    "- It does the whole calculation in C (or, if you're using a GPU, in CUDA, the equivalent of C on the GPU), tens of thousands of times faster than pure Python (up to millions of times faster on a GPU!).\n",
    "\n",
    "This is true of all broadcasting and elementwise operations and functions done in PyTorch. *It's the most important technique for you to know to create efficient PyTorch code.*\n",
    "\n",
    "Next in `mnist_distance` we see `abs`. You might be able to guess now what this does when applied to a tensor. It applies the method to each individual element in the tensor, and returns a tensor of the results (that is, it applies the method \"elementwise\"). So in this case, we'll get back 1,010 matrices of absolute values.\n",
    "\n",
    "Finally, our function calls `mean((-1,-2))`. The tuple `(-1,-2)` represents a range of axes. In Python, `-1` refers to the last element, and `-2` refers to the second-to-last. So in this case, this tells PyTorch that we want to take the mean ranging over the values indexed by the last two axes of the tensor. The last two axes are the horizontal and vertical dimensions of an image. After taking the mean over the last two axes, we are left with just the first tensor axis, which indexes over our images, which is why our final size was `(1010)`. In other words, for every image, we averaged the intensity of all the pixels in that image.\n",
    "\n",
    "\n",
    "We can use `mnist_distance` to figure out whether an image is a 3 or not by using the following logic: if the distance between the digit in question and the ideal 3 is less than the distance to the ideal 7, then it's a 3. This function will automatically do broadcasting and be applied elementwise, just like all PyTorch functions and operators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_3(x): return mnist_distance(x,mean3) < mnist_distance(x,mean7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's test it on our example case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(True), tensor(1.))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_3(a_3), is_3(a_3).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that when we convert the Boolean response to a float, we get `1.0` for `True` and `0.0` for `False`. Thanks to broadcasting, we can also test it on the full validation set of 3s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True,  ..., True, True, True])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_3(valid_3_tens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now we can calculate the accuracy for each of the 3s and 7s by taking the average of that function for all 3s and its inverse for all 7s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.9168), tensor(0.9854), tensor(0.9511))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_3s =      is_3(valid_3_tens).float() .mean()\n",
    "accuracy_7s = (1 - is_3(valid_7_tens).float()).mean()\n",
    "\n",
    "accuracy_3s,accuracy_7s,(accuracy_3s+accuracy_7s)/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks like a pretty good start! We're getting over 90% accuracy on both 3s and 7s, and we've seen how to define a metric conveniently using broadcasting.\n",
    "\n",
    "But let's be honest: 3s and 7s are very different-looking digits. And we're only classifying 2 out of the 10 possible digits so far. So we're going to need to do better!\n",
    "\n",
    "To do better, perhaps it is time to try a system that does some real learning—that is, that can automatically modify itself to improve its performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Gradient Descent: Recap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "To summarize, at the beginning, the weights of our model can be random (training *from scratch*) or come from a pretrained model (*transfer learning*). In the first case, the output we will get from our inputs won't have anything to do with what we want, and even in the second case, it's very likely the pretrained model won't be very good at the specific task we are targeting. So the model will need to *learn* better weights.\n",
    "\n",
    "We begin by comparing the outputs the model gives us with our targets (we have labeled data, so we know what result the model should give) using a *loss function*, which returns a number that we want to make as low as possible by improving our weights. To do this, we take a few data items (such as images) from the training set and feed them to our model. We compare the corresponding targets using our loss function, and the score we get tells us how wrong our predictions were. We then change the weights a little bit to make it slightly better.\n",
    "\n",
    "To find how to change the weights to make the loss a bit better, we use calculus to calculate the *gradients*. (Actually, we let PyTorch do it for us!). We use the magnitude of the gradient (i.e., the steepness of the slope) to tell us how big a step to take; specifically, we multiply the gradient by a number we choose called the *learning rate* to decide on the step size. We then *iterate* until we have reached the lowest point, which will be our parking lot, then we can *stop*.\n",
    "\n",
    "All of that we just saw can be transposed directly to the MNIST dataset, except for the loss function. Let's now see how we can define a good training objective. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The MNIST Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already have our independent variables `x`—these are the images themselves. We'll concatenate them all into a single tensor, and also change them from a list of matrices (a rank-3 tensor) to a list of vectors (a rank-2 tensor). We can do this using `view`, which is a PyTorch method that changes the shape of a tensor without changing its contents. `-1` is a special parameter to `view` that means \"make this axis as big as necessary to fit all the data\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.cat([stacked_threes, stacked_sevens]).view(-1, 28*28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a label for each image. We'll use `1` for 3s and `0` for 7s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([12396, 784]), torch.Size([12396, 1]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = tensor([1]*len(threes) + [0]*len(sevens)).unsqueeze(1)\n",
    "train_x.shape,train_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A `Dataset` in PyTorch is required to return a tuple of `(x,y)` when indexed. Python provides a `zip` function which, when combined with `list`, provides a simple way to get this functionality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784]), tensor([1]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset = list(zip(train_x,train_y))\n",
    "x,y = dset[0]\n",
    "x.shape,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_x = torch.cat([valid_3_tens, valid_7_tens]).view(-1, 28*28)\n",
    "valid_y = tensor([1]*len(valid_3_tens) + [0]*len(valid_7_tens)).unsqueeze(1)\n",
    "valid_dset = list(zip(valid_x,valid_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need an (initially random) weight for every pixel (this is the *initialize* step in our seven-step process):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(size, std=1.0): return (torch.randn(size)*std).requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = init_params((28*28,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The function `weights*pixels` won't be flexible enough—it is always equal to 0 when the pixels are equal to 0 (i.e., its *intercept* is 0). We need to add a *bias*. We'll initialize it to a random number too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = init_params(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">In neural networks, the `w` in the equation `y=w*x+b` is called the *weights*, and the `b` is called the *bias*. Together, the weights and bias make up the *parameters*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now calculate a prediction for one image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-13.0157], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_x[0]*weights.T).sum() + bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "While we could use a Python `for` loop to calculate the prediction for each image, that would be very slow. Because Python loops don't run on the GPU, and because Python is a slow language for loops in general, we need to represent as much of the computation in a model as possible using higher-level functions.\n",
    "\n",
    "In this case, there's an extremely convenient mathematical operation that calculates `w*x` for every row of a matrix—it's called *matrix multiplication*. <<matmul>> shows what matrix multiplication looks like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"Matrix multiplication\" width=\"400\" caption=\"Matrix multiplication\" src=\"images/Lesson4_matmul2.svg\" id=\"matmul\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This image shows two matrices, `A` and `B`, being multiplied together. Each item of the result, which we'll call `AB`, contains each item of its corresponding row of `A` multiplied by each item of its corresponding column of `B`, added together. For instance, row 1, column 2 (the yellow dot with a red border) is calculated as $a_{1,1} * b_{1,2} + a_{1,2} * b_{2,2}$. \n",
    "\n",
    "In Python, matrix multiplication is represented with the `@` operator. Let's try it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-13.0157],\n",
       "        [  2.1974],\n",
       "        [ -1.4221],\n",
       "        ...,\n",
       "        [ -6.1881],\n",
       "        [ -3.9343],\n",
       "        [ -9.6109]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def linear1(xb): return xb@weights + bias\n",
    "preds = linear1(train_x)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first element is the same as we calculated before, as we'd expect. This equation, `batch@weights + bias`, is one of the two fundamental equations of any neural network (the other one is the *activation function*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's check our accuracy. To decide if an output represents a 3 or a 7, we can just check whether it's greater than 0.0, so our accuracy for each item can be calculated (using broadcasting, so no loops!) with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False],\n",
       "        [ True],\n",
       "        [False],\n",
       "        ...,\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrects = (preds>0.0).float() == train_y\n",
    "corrects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5614714622497559"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrects.float().mean().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now let's see what the change in accuracy is for a small change in one of the weights (note that we have to ask PyTorch not to calculate gradients as we do this, which is what `with torch.no_grad()` is doing here):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad(): weights[0] *= 1.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5614714622497559"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = linear1(train_x)\n",
    "((preds>0.0).float() == train_y).float().mean().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "As we've seen, we need gradients in order to improve our model using SGD, and in order to calculate gradients we need some *loss function* that represents how good our model is. That is because the gradients are a measure of how that loss function changes with small tweaks to the weights.\n",
    "\n",
    "So, we need to choose a loss function. The obvious approach would be to use accuracy, which is our metric, as our loss function as well. In this case, we would calculate our prediction for each image, collect these values to calculate an overall accuracy, and then calculate the gradients of each weight with respect to that overall accuracy.\n",
    "\n",
    "Unfortunately, we have a significant technical problem here. The gradient of a function is its *slope*, or its steepness, which can be defined as *rise over run*—that is, how much the value of the function goes up or down, divided by how much we changed the input. We can write this in mathematically as: `(y_new - y_old) / (x_new - x_old)`. This gives us a good approximation of the gradient when `x_new` is very similar to `x_old`, meaning that their difference is very small. But accuracy only changes at all when a prediction changes from a 3 to a 7, or vice versa. The problem is that a small change in weights from `x_old` to `x_new` isn't likely to cause any prediction to change, so `(y_new - y_old)` will almost always be 0. In other words, the gradient is 0 almost everywhere."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A very small change in the value of a weight will often not actually change the accuracy at all. This means it is not useful to use accuracy as a loss function—if we do, most of the time our gradients will actually be 0, and the model will not be able to learn from that number.\n",
    "\n",
    "> In mathematical terms, accuracy is a function that is constant almost everywhere (except at the threshold, 0.5), so its derivative is nil almost everywhere (and infinity at the threshold). This then gives gradients that are 0 or infinite, which are useless for updating the model.\n",
    "\n",
    "Instead, we need a loss function which, when our weights result in slightly better predictions, gives us a slightly better loss. So what does a \"slightly better prediction\" look like, exactly? Well, in this case, it means that if the correct answer is a 3 the score is a little higher, or if the correct answer is a 7 the score is a little lower.\n",
    "\n",
    "Let's write such a function now. What form does it take?\n",
    "\n",
    "The loss function receives not the images themselves, but the predictions from the model. Let's make one argument, `prds`, of values between 0 and 1, where each value is the prediction that an image is a 3. It is a vector (i.e., a rank-1 tensor), indexed over the images.\n",
    "\n",
    "The purpose of the loss function is to measure the difference between predicted values and the true values — that is, the targets (aka labels). Let's make another argument, `trgts`, with values of 0 or 1 which tells whether an image actually is a 3 or not. It is also a vector (i.e., another rank-1 tensor), indexed over the images.\n",
    "\n",
    "So, for instance, suppose we had three images which we knew were a 3, a 7, and a 3. And suppose our model predicted with high confidence (`0.9`) that the first was a 3, with slight confidence (`0.4`) that the second was a 7, and with fair confidence (`0.2`), but incorrectly, that the last was a 7. This would mean our loss function would receive these values as its inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "trgts  = tensor([1,0,1])\n",
    "prds   = tensor([0.9, 0.4, 0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Here's a first try at a loss function that measures the distance between `predictions` and `targets`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_loss(predictions, targets):\n",
    "    return torch.where(targets==1, 1-predictions, predictions).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're using a new function, `torch.where(a,b,c)`. This is the same as running the list comprehension `[b[i] if a[i] else c[i] for i in range(len(a))]`, except it works on tensors, at C/CUDA speed. In plain English, this function will measure how distant each prediction is from 1 if it should be 1, and how distant it is from 0 if it should be 0, and then it will take the mean of all those distances.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's try it on our `prds` and `trgts`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1000, 0.4000, 0.8000])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.where(trgts==1, 1-prds, prds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that this function returns a lower number when predictions are more accurate, when accurate predictions are more confident (higher absolute values), and when inaccurate predictions are less confident. In PyTorch, we always assume that a lower value of a loss function is better. Since we need a scalar for the final loss, `mnist_loss` takes the mean of the previous tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4333)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_loss(prds,trgts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For instance, if we change our prediction for the one \"false\" target from `0.2` to `0.8` the loss will go down, indicating that this is a better prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2333)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_loss(tensor([0.9, 0.4, 0.8]),trgts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One problem with `mnist_loss` as currently defined is that it assumes that predictions are always between 0 and 1. We need to ensure, then, that this is actually the case! As it happens, there is a function that does exactly that—let's take a look."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `sigmoid` function always outputs a number between 0 and 1. It's defined as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x): return 1/(1+torch.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch defines an accelerated version for us, so we don’t really need our own. This is an important function in deep learning, since we often want to ensure values are between 0 and 1. This is what it looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_function(f, tx=None, ty=None, title=None, min=-2, max=2, figsize=(6,4)):\n",
    "    x = torch.linspace(min,max,100)\n",
    "    fig,ax = plt.subplots(figsize=figsize)\n",
    "    ax.plot(x,f(x))\n",
    "    if tx is not None: ax.set_xlabel(tx)\n",
    "    if ty is not None: ax.set_ylabel(ty)\n",
    "    if title is not None: ax.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgQAAAF2CAYAAAARAIDBAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA+PElEQVR4nO3deVhU9eIG8HdmgBnWYR92ENw3UBBEK7VIrppl91ZetUQzb5lZRveWeFPrZtGepZampZaalqV10+sSaf1K3FjcRXFjk2GTGRiWgZnz+8OaLldQBoHDzLyf55knOZwz855Y5uWc7/keiSAIAoiIiMimScUOQEREROJjISAiIiIWAiIiImIhICIiIrAQEBEREVgIiIiICCwEREREBBYCIiIiAgsBERERgYWAyKaEhYVh2rRpYse4obVr10IikeDSpUs3XdcS9ofIUrAQEFmJ48eP44EHHkBoaCgUCgUCAwNx9913Y+nSpWJHIyILIOG9DIgs3/79+zFq1CiEhIQgKSkJfn5+yM/Px4EDB3D+/Hnk5uYCAOrr6yGVSmFvby9y4pYZDAY0NDRALpdDIpHccN2wsDCMHDkSa9eu7ZxwRFbMTuwARHTrXn31VSiVShw+fBju7u5NPldSUmL6t1wu7+Rk5pPJZJDJZGLHILI5PGVAZAXOnz+Pfv36XVcGAMDX19f07+bOuR87dgwjRoyAo6MjgoKCsHjxYqxZs+a68/hhYWG45557sG/fPsTExMDR0REDBgzAvn37AADffPMNBgwYAIVCgejoaGRlZV2X5ccff8Ttt98OZ2dnuLu747777sPp06ebrNPcGAJBELB48WIEBQXByckJo0aNwsmTJ83+/0RELeMRAiIrEBoaivT0dJw4cQL9+/dv9XaFhYUYNWoUJBIJUlJS4OzsjNWrV7d4JCE3NxeTJ0/G448/jocffhhvv/02xo8fjxUrVmD+/Pl48sknAQCpqal46KGHkJOTA6n02t8dP/zwA8aMGYPw8HC89NJLqK2txdKlSzF8+HBkZmYiLCysxZwLFy7E4sWLMXbsWIwdOxaZmZkYPXo09Hp96/8nEdGNCURk8Xbv3i3IZDJBJpMJ8fHxwvPPPy/s2rVL0Ov1TdYLDQ0VkpKSTB/PmTNHkEgkQlZWlmlZeXm54OnpKQAQLl682GRbAML+/ftNy3bt2iUAEBwdHYXLly+blq9cuVIAIOzdu9e0LCoqSvD19RXKy8tNy44ePSpIpVJh6tSppmVr1qxp8tolJSWCg4ODMG7cOMFoNJrWmz9/vgCgyf4QUdvxlAGRFbj77ruRnp6Oe++9F0ePHsWbb76JxMREBAYG4rvvvmtxu507dyI+Ph5RUVGmZZ6enpgyZUqz6/ft2xfx8fGmj+Pi4gAAd955J0JCQq5bfuHCBQDAlStXkJ2djWnTpsHT09O03sCBA3H33Xdjx44dLWb84YcfoNfrMWfOnCaDDOfOndviNkRkPhYCIisxZMgQfPPNN7h69SoOHTqElJQUVFVV4YEHHsCpU6ea3eby5cvo3r37dcubWwagyZs+ACiVSgBAcHBws8uvXr1qeh0A6NWr13XP2adPH5SVlUGn07WYEQB69OjRZLmPjw88PDya3YaIzMdCQGRlHBwcMGTIELz22mv46KOP0NDQgK+++qpdnrul0f8tLRd4VTORxWAhILJiMTExAK4dsm9OaGioaY6C/9bcslsRGhoKAMjJybnuc2fOnIG3tzecnZ1vuO25c+eaLC8tLTUdgSCiW8dCQGQF9u7d2+xf47+fm2/uUD0AJCYmIj09HdnZ2aZlFRUV2LBhQ7vm8/f3R1RUFNatW4fKykrT8hMnTmD37t0YO3Zsi9smJCTA3t4eS5cubbKPS5YsadeMRLaOlx0SWYE5c+agpqYG999/P3r37g29Xo/9+/dj8+bNCAsLw/Tp05vd7vnnn8f69etx9913Y86cOabLDkNCQlBRUXHTmQLN8dZbb2HMmDGIj4/HjBkzTJcdKpVKvPTSSy1u5+Pjg7///e9ITU3FPffcg7FjxyIrKwv/+c9/4O3t3W75iGwdCwGRFXj77bfx1VdfYceOHfj444+h1+sREhKCJ598Ei+++GKzExYB1wYD7t27F08//TRee+01+Pj4YPbs2XB2dsbTTz8NhULRbhkTEhKwc+dOLFq0CAsXLoS9vT1GjBiBN954A926dbvhtosXL4ZCocCKFSuwd+9exMXFYffu3Rg3bly75SOydbyXARFdZ+7cuVi5ciWqq6s5jTCRjeAYAiIbV1tb2+Tj8vJyfP7557jttttYBohsCE8ZENm4+Ph4jBw5En369IFarcYnn3wCrVaLBQsWiB2NiDoRCwGRjRs7diy2bNmCjz/+GBKJBIMHD8Ynn3yCO+64Q+xoRNSJOIaAiIiIOIaAiIiIWAiIiIgIFjKGwGg0oqioCK6uru06UQoREZG1EwQBVVVVCAgIgFTa8nEAiygERUVF191NjYiIiFovPz8fQUFBLX7eIgqBq6srgGs74+bmJnIaIiIiy6HVahEcHGx6L22JRRSC308TuLm5sRAQERG1wc1OuXNQIREREbEQEBERURsKwc8//4zx48cjICAAEokE27Ztu+k2+/btw+DBgyGXy9G9e3esXbu2DVGJiIioo5hdCHQ6HSIjI7F8+fJWrX/x4kWMGzcOo0aNQnZ2NubOnYvHHnsMu3btMjssERERdQyzBxWOGTMGY8aMafX6K1asQLdu3fDOO+8AAPr06YNffvkF7733HhITE819eSIiIuoAHT6GID09HQkJCU2WJSYmIj09vcVt6uvrodVqmzyIiIio43R4ISguLoZKpWqyTKVSQavVXncf9t+lpqZCqVSaHpyUiIiIqGN1yasMUlJSoNFoTI/8/HyxIxEREVm1Dp+YyM/PD2q1uskytVoNNzc3ODo6NruNXC6HXC7v6GhERET0mw4/QhAfH4+0tLQmy/bs2YP4+PiOfmkiIiJqJbOPEFRXVyM3N9f08cWLF5GdnQ1PT0+EhIQgJSUFhYWF+OyzzwAATzzxBJYtW4bnn38ejz76KH788Ud8+eWX2L59e/vtBRERkYWo1RtQrK3DFU0t1No6qLX1UGvrUKKtR0lVHUb28sXsUd07PZfZheDIkSMYNWqU6ePk5GQAQFJSEtauXYsrV64gLy/P9Plu3bph+/btePbZZ/H+++8jKCgIq1ev5iWHRERkdQRBQLlOj4KrtcivqEFRZS2KKmtRWFmHwspaXNHUorKm4YbPoXJTdFLapiSCIAiivLIZtFotlEolNBoNb25ERESiajQYUVhZi4tlOlwur8Hl8hrkVVz7d8HVWtQ2GG76HI72Mvi7K6ByVcBPqYCvmxwqVwVUbgqE+zijj3/7vde19j3UIu52SERE1Nk0tQ3ILanG+ZJqnC+txvlSHS6WVSOvogYNhpb/lpZIAJWrAsGejgh0d0SAuyMCPa7911+pgL/SEW4Ku5vefbCzsRAQEZFNq9UbcFZdhZziKuSoq0z/Lqmqb3EbuZ0UYV7OCPFyQpiXE0K8nBHq6YRgTycEuCsgt5N14h60DxYCIiKyGVd1ehwv1OBEkQanr1ThVJEGF8t0MLbwB7/KTY7uvi7o7uOCCF8XhHu7oJuPM/zdFJBKu9Zf+LeKhYCIiKySrr4Rxwo0yM6vxPHCShwr0KDgavMz5Ho5O6C3vyt6qlzRS+WKHipX9FC5wE1h38mpxcNCQEREFk8QBFwur8GRy1eRcbkCWXmVOKuuavYv/zAvJ/QLVKJfgBv6+ruhb4AbfF3FGdnflbAQEBGRxTEaBeSoq3DgQjkOXazA4UtXUVZ9/Tn/AKUCUSHuGBjkjoGBSvQLVELpaDt/9ZuDhYCIiLo8QRBwsUyHX3LLsD+3HAcvluPq/1zP7yCTYkCQEjGhHhgU4oFBIe6iXdNviVgIiIioS9LUNOD/ckvxf2fL8EtuGQorm57/d7SXISbMA0PDvRDbzRMDApVQ2Fve6P6ugoWAiIi6BEEQcKa4CntzSrDvTCky8q7C8F+DABxkUkSHeuC2Ht4YGu6FgUFK2Mu65E17LRILARERiabRYMShSxXYfVKNPafU1x0F6KlywR09fHBbD2/EdfOCowOPAHQUFgIiIupU+kYjfs0tw/fHruCH02poav8YC6Cwl+K27t4Y2csXI3v5IMjDScSktoWFgIiIOlyjwYhffisBu08WQ1vXaPqcp7MD7urti9H9/HBbd28eBRAJCwEREXUIQRBwrECDrVmF+P5YEcqq9abP+bjKMaa/H8YO8MeQME/IrGzWP0vEQkBERO1Kra3D15kF2HKkABfKdKblXs4OGDvAH/cM9EcMS0CXw0JARES3rMFgRNppNb48UoB9OSWmGQIV9lKM7uuH+wcF4rYe3rwqoAtjISAiojYrqqzFF4fysOlwPkr/6+6AQ8I88GBMMMYO8IeLnG81loBfJSIiMosgCPg1txzr0i8h7bTadDTA20WOB6KD8GBMECJ8XMQNSWZjISAiolapazBgW1YhPv31Is6qq03Lh4Z74uGhoRjd1w8OdjwlYKlYCIiI6IbKq+uxbv8lrD+YhwrdtSsFnBxkeDA6CA8PDUUPlavICak9sBAQEVGzCq7WYPX/XcSmw3moazACAALdHTFtWBgeGhLMuwZaGRYCIiJq4nxpNZb/mItvjxaZ7iUwMEiJJ0ZEYHRfFex4pYBVYiEgIiIA14rA0rRz+O5okWmg4G3dvTFrZASGRXhBIuG8AdaMhYCIyMZdLNPh/R/ONikCCX1UmHNnd0QGu4uajToPCwERkY1Sa+vwfto5bD6cbzo1kNBHhbkJPdA/UClyOupsLARERDZGU9uAlT+dx6e/XjQNFhzVywfPje7FImDDWAiIiGxEo8GIjYfy8N6es7hac+2Ww9GhHnjhT70R281T5HQkNhYCIiIbsC+nBIu3n0ZuybUJhXr4uuD5P/VGQh9fDhYkACwERERW7WKZDi//+yT25ZQCADyc7JE8uhcmDQnm5YPUBAsBEZEVqtUb8OG+XKz86QL0BiPsZRJMGxaGp+7swQmFqFksBEREVmbPKTVe/vdJFFytBQDc0dMHL9/bD928nUVORl0ZCwERkZVQa+uw8NsT2HVSDQAIUCqwcHxfJPbz4zgBuikWAiIiC2c0Cth0OB+pO06jqr4RdlIJHrs9HE/f1R1ODvw1T63D7xQiIgt2sUyHeV8fw8GLFQCAyGB3vPGXAejt5yZyMrI0LARERBbIaBTwWfolvL7zDOoajHC0l+Hvib0wbVgYZFKeHiDzsRAQEVmYgqs1+MdXx5B+oRwAMLy7F17/80AEezqJnIwsGQsBEZGFEAQBXx0pwL++P4Xq+kY42sswf2xvTIkLhZRHBegWsRAQEVmAyho9Ur45jv+cKAYAxIR64O0HIxHGSwmpnbAQEBF1cQcvlGPu5mxc0dTBTirBc6N74W93hHOsALUrFgIioi6q0WDE+2nnsHxvLowCEOblhA8mDcLAIHexo5EVYiEgIuqCSrR1mPNFlulywgejg/DSvf3gLOevbeoY/M4iIupi9ueW4elNWSir1sNFbofX/jwA90YGiB2LrBwLARFRF2E0Cli2NxdLfjgLowD09nPFh1MGI9zHRexoZANYCIiIugBNbQPmbsrC3t9uU/xQTBD+dV9/KOxlIicjW8FCQEQksnPqKvzt8wxcLNNBbifF4gn98WBMsNixyMawEBARiWjXyWIkb86GTm9AoLsjVj4Sjf6BSrFjkQ1iISAiEoHRKOD9tHN4P+0cAGBouCeWTx4MLxe5yMnIVrEQEBF1sroGA5776ii2H7sCAJg+PAzzx/aBvUwqcjKyZW367lu+fDnCwsKgUCgQFxeHQ4cO3XD9JUuWoFevXnB0dERwcDCeffZZ1NXVtSkwEZElK6mqw8SPD2D7sSuwk0rw5l8GYtH4fiwDJDqzjxBs3rwZycnJWLFiBeLi4rBkyRIkJiYiJycHvr6+162/ceNGzJs3D59++imGDRuGs2fPYtq0aZBIJHj33XfbZSeIiCzBqSItHlt3GEWaOrg72eOjKdGIj/ASOxYRAEAiCIJgzgZxcXEYMmQIli1bBgAwGo0IDg7GnDlzMG/evOvWf+qpp3D69GmkpaWZlj333HM4ePAgfvnll1a9plarhVKphEajgZubmzlxiYi6hJ/PlmLW+gzo9AaEezvjk2lD0I03JqJO0Nr3ULOOUen1emRkZCAhIeGPJ5BKkZCQgPT09Ga3GTZsGDIyMkynFS5cuIAdO3Zg7NixLb5OfX09tFptkwcRkaX66kg+Hl17GDq9AfHhXtj65HCWAepyzDplUFZWBoPBAJVK1WS5SqXCmTNnmt1m8uTJKCsrw2233QZBENDY2IgnnngC8+fPb/F1UlNT8fLLL5sTjYioyxEEAct+zMU7e84CAO6LCsBbD0TCwY7jBajr6fDvyn379uG1117Dhx9+iMzMTHzzzTfYvn07XnnllRa3SUlJgUajMT3y8/M7OiYRUbtqNBgxf+sJUxmYNTIC7z0UxTJAXZZZRwi8vb0hk8mgVqubLFer1fDz82t2mwULFuCRRx7BY489BgAYMGAAdDod/va3v+Gf//wnpNLrfzjkcjnkcl6LS0SWqa7BgGc2ZWHXSTUkEuDle/thanyY2LGIbsisqurg4IDo6OgmAwSNRiPS0tIQHx/f7DY1NTXXvenLZNfm5jZzPCMRUZdXXd+IGesOY9dJNRxkUnw0JZplgCyC2ZcdJicnIykpCTExMYiNjcWSJUug0+kwffp0AMDUqVMRGBiI1NRUAMD48ePx7rvvYtCgQYiLi0Nubi4WLFiA8ePHm4oBEZE1uKrTY9rawziaXwlnBxlWTY3BsO7eYsciahWzC8HEiRNRWlqKhQsXori4GFFRUdi5c6dpoGFeXl6TIwIvvvgiJBIJXnzxRRQWFsLHxwfjx4/Hq6++2n57QUQksmJNHR755CDOlVTDw8kea6fHIjLYXexYRK1m9jwEYuA8BETUlRVcrcHkVQeRV1EDPzcFPp8Rix4qV7FjEQFo/Xso72VARHQL8sprMGnVARRW1iLE0wkbHotDsKeT2LGIzMZCQETURhdKqzF51UEUa+sQ7u2MDTPj4K90FDsWUZuwEBARtcE5dRUmrTqIsup69PB1wYaZcfB1VYgdi6jNWAiIiMx0Tl2Fv358AOU6Pfr4u2H9jFh4uXDuFLJsLARERGbILanGpFUHUa7To3+gG9bPiIO7k4PYsYhuGefQJCJqpfOl1Zi06gDKquvR159lgKwLCwERUStcLNNh8qoDKK2qR28/V6x/jGWArAsLARHRTeRX1GDyqgNQa+vRU+WCDY/FwdOZZYCsCwsBEdENqLV1mLL6IK5o6tDd1wUbHhvKAYRklVgIiIhaUKHT4+HV12YgDPW6NumQjyvLAFknFgIiomZo6xow9dNr9ybwc1Ng/Yw4qNw4zwBZLxYCIqL/UaNvxKNrDuNEoRZezg5Yz+mIyQawEBAR/ZcGgxGz1mfiyOWrcFPY4fMZceju6yJ2LKIOx0JARPQbo1HAP746ip/OlsLRXoY102PRN4B3WCXbwEJARARAEAQs3n4a27KLYCeV4MOHByM61EPsWESdhoWAiAjARz+dx6e/XgQAvP1gJEb18hU5EVHnYiEgIpu3+XAe3tyZAwBYcE9fTBgUKHIios7HQkBENm1vTgnmbz0BAJg1MgIzbusmciIicbAQEJHNOl6gwewNmTAYBfx5cCCeT+wldiQi0bAQEJFNyq+owfS1h1GjN+D2Ht54/c8DIZFIxI5FJBoWAiKyOZU1eiStOYSy6nr08XfDh1MGw8GOvw7JtvEngIhsSn2jATM/O4ILpToEKBVYM20IXBX2YsciEh0LARHZDEEQ8PyWYzh86SpcFXZY+2gs/JS8PwERwEJARDbk/bRz+Pa3iYdWPByNnipXsSMRdRksBERkE7ZlFWLJD+cAAIsn9Mfw7t4iJyLqWlgIiMjqHb5Ugee3HAMAPD4iHH+NDRE5EVHXw0JARFYtr7wGf/vsCPQGI/7Uzw8vJPYWOxJRl8RCQERWq6quATPWHcbVmgYMCFTivYlRkEo51wBRc1gIiMgqGYwCntmUjXMl1VC5ybE6KQaODjKxYxF1WSwERGSV3tx5Bj+eKYHcToqPH4mByo2XFxLdCAsBEVmdLRkFWPnzBQDAWw9GIjLYXdxARBaAhYCIrErG5auY/81xAMCcO7vj3sgAkRMRWQYWAiKyGsWaOjyxPgN6gxGJ/VR4NqGn2JGILAYLARFZhboGAx5fn4HSqnr09nPFuw/xigIic7AQEJHFEwQBC7adwNH8Sigd7fHxIzFwltuJHYvIorAQEJHF+yz9Mr7KKIBUAiybPAghXk5iRyKyOCwERGTR0s+X41/fnwIApIzpg9t7+IiciMgysRAQkcUqqqzFUxszYTAKmBAVgMdu7yZ2JCKLxUJARBaprsGAWeszUK7To6+/G1L/PBASCQcRErUVCwERWaSX/30SRws0cHeyx8pHojktMdEtYiEgIouz6VAevjiUD4kE+OCvgxDsyUGERLeKhYCILEp2fiUWfnsSAPD30b1wR08OIiRqDywERGQxKnR6PPnbTISj+6owa0SE2JGIrAYLARFZhGu3M85CkaYO4d7OeOehSM5ESNSOWAiIyCK8n3YO/3euDI72Mnz0cDRcFfZiRyKyKiwERNTl7c0pwQdp5wAAqX8egF5+riInIrI+LARE1KXlV9Tg2c3ZAICHh4ZgwqBAcQMRWak2FYLly5cjLCwMCoUCcXFxOHTo0A3Xr6ysxOzZs+Hv7w+5XI6ePXtix44dbQpMRLajvtGA2RszUVnTgMggJRbc01fsSERWy+zbgW3evBnJyclYsWIF4uLisGTJEiQmJiInJwe+vr7Xra/X63H33XfD19cXW7ZsQWBgIC5fvgx3d/f2yE9EVmzx96dx7LfJh5ZPGQy5HScfIuooEkEQBHM2iIuLw5AhQ7Bs2TIAgNFoRHBwMObMmYN58+Zdt/6KFSvw1ltv4cyZM7C3b9sgIK1WC6VSCY1GAzc3tzY9BxFZlu+OFuHpL7IAAGumD8GoXtf/wUFEN9fa91CzThno9XpkZGQgISHhjyeQSpGQkID09PRmt/nuu+8QHx+P2bNnQ6VSoX///njttddgMBhafJ36+npotdomDyKyHedLq5Hy9TEAwFOjurMMEHUCswpBWVkZDAYDVCpVk+UqlQrFxcXNbnPhwgVs2bIFBoMBO3bswIIFC/DOO+9g8eLFLb5OamoqlEql6REcHGxOTCKyYLV6A2ZvyIROb8DQcE/MTeghdiQim9DhVxkYjUb4+vri448/RnR0NCZOnIh//vOfWLFiRYvbpKSkQKPRmB75+fkdHZOIuohF353AmeIqeLvI8cFfB8FOxouhiDqDWYMKvb29IZPJoFarmyxXq9Xw8/Nrdht/f3/Y29tDJvtjMFCfPn1QXFwMvV4PBweH67aRy+WQy+XmRCMiK7AlowBfHimAVAJ8MCkKvm4KsSMR2QyzqreDgwOio6ORlpZmWmY0GpGWlob4+Phmtxk+fDhyc3NhNBpNy86ePQt/f/9mywAR2aZz6ios2HYCADA3oSeGRXiLnIjItph9LC45ORmrVq3CunXrcPr0acyaNQs6nQ7Tp08HAEydOhUpKSmm9WfNmoWKigo888wzOHv2LLZv347XXnsNs2fPbr+9ICKLVqu/Nt9AbYMBt/fwxlOjuosdicjmmD0PwcSJE1FaWoqFCxeiuLgYUVFR2Llzp2mgYV5eHqTSP3pGcHAwdu3ahWeffRYDBw5EYGAgnnnmGbzwwgvttxdEZNEWfXcCZ9XV8HGV492HonjTIiIRmD0PgRg4DwGR9fomswDJXx6FVAKsfyyOpwqI2lmHzENARNSeckuq8eJv4waevqsHywCRiFgIiEgUdQ0GPLUxEzV6A4ZFeGHOnZxvgEhMLAREJIpXvj/123wDDljy1yjIOG6ASFQsBETU6bYfu4INB/MgkQDvTYyCryvnGyASGwsBEXWq/IoazPvtPgWzRkTg9h4+IiciIoCFgIg6kb7RiKe+yEJVfSOiQz2QfHdPsSMR0W9YCIio07y9OwdH8yuhdLTHB5N4nwKiroQ/jUTUKfbmlODjny8AAN58YCAC3R1FTkRE/42FgIg6nFpbh+e+PAoASIoPRWK/5m+GRkTiYSEgog5lMAp4dnM2KnR69PF3Q8rYPmJHIqJmsBAQUYf6aF8u9p8vh5ODDMsmD4LCXnbzjYio07EQEFGHOXKpAu/9cA4A8PK9/RDh4yJyIiJqCQsBEXUITU0DntmUDYNRwISoADwQHSR2JCK6ARYCImp3giDgha+PobCyFqFeTlh8/wBIJJyamKgrYyEgona34WAedp4shr1MgqWTBsFFbid2JCK6CRYCImpXOcVVeOX7UwCA5xN7Y2CQu7iBiKhVWAiIqN3U6g2Y80Um6huNGNHTBzNu6yZ2JCJqJRYCImo3i7efwll1Nbxd5HjnoUhIeUtjIovBQkBE7WLniWu3NAaA9yZGwttFLnIiIjIHCwER3bLCylo8v+XaLY2f4C2NiSwSCwER3ZJGgxFzN2VBW9eIyGB3PDeatzQmskQsBER0Sz74MReHL12Fi9wOS/86CPa8pTGRReJPLhG12YEL5Vj247WpiV+9vz9CvJxETkREbcVCQERtclWnx7Obs2EUgAeig3BfVKDYkYjoFrAQEJHZfp+a+IqmDuHeznj53n5iRyKiW8RCQERmW3/gMnafUsNeJsEHkwbBmVMTE1k8FgIiMsvpK1q8sv00AGDemD7oH6gUORERtQcWAiJqtRp9I+Z8kQV9oxF39vbFo8PDxI5ERO2EhYCIWu2V708ht6Qavq5yvPXAQN7SmMiKsBAQUatsP3YFXxzKh0QCvDcxCl6cmpjIqrAQENFN5VfUYN4316YmnjUiAsO7e4uciIjaGwsBEd1Qg8GIpzdloaquEYNC3PHs3ZyamMgasRAQ0Q29u+cssvIq4aqwwwecmpjIavEnm4ha9H/nSrHip/MAgNf/PBDBnpyamMhasRAQUbNKq+rx7OajEARgclwIxg30FzsSEXUgFgIiuo7RKOC5r46irLoePVUuWHhPX7EjEVEHYyEgouus+r8L+PlsKRT2UiybPBgKe5nYkYiog7EQEFETmXlX8dauHADAwnv6oafKVeRERNQZWAiIyERT24Cnv8hCo1HAuIH+mBQbLHYkIuokLAREBODaLY3nfX0MBVdrEeLphNQ/D+DUxEQ2hIWAiAAA6w/m4T8nimEvk2DppEFwU9iLHYmIOhELARHhVJEWr3x/CgDwwp96IzLYXdxARNTpWAiIbFx1fSOe+iIT+kYj7urtixm3dRM7EhGJgIWAyIYJgoAXtx7HhVId/NwUeOvBSI4bILJRLARENuzLI/nYll0EmVSCpZMHwdPZQexIRCQSFgIiG5VTXIVF350EADw3uieGhHmKnIiIxMRCQGSDavSNmL0xE3UNRozo6YMn7ogQOxIRiaxNhWD58uUICwuDQqFAXFwcDh061KrtNm3aBIlEggkTJrTlZYmonSzYdhK5JdVQucnx7kORkEo5boDI1pldCDZv3ozk5GQsWrQImZmZiIyMRGJiIkpKSm643aVLl/D3v/8dt99+e5vDEtGt+/JIPr7OLIBUAnzw10HwcpGLHYmIugCzC8G7776LmTNnYvr06ejbty9WrFgBJycnfPrppy1uYzAYMGXKFLz88ssIDw+/pcBE1Hanr2ixYNsJAMBzo3shLtxL5ERE1FWYVQj0ej0yMjKQkJDwxxNIpUhISEB6enqL2/3rX/+Cr68vZsyY0arXqa+vh1arbfIgoltTVdeAJzdkor7RiJG9fDBrBMcNENEfzCoEZWVlMBgMUKlUTZarVCoUFxc3u80vv/yCTz75BKtWrWr166SmpkKpVJoewcG8wQrRrRAEASnfHMfFMh0ClAq891AUxw0QURMdepVBVVUVHnnkEaxatQre3t6t3i4lJQUajcb0yM/P78CURNZv/YHL+P7YFdhJJVg6eTA8ON8AEf0PO3NW9vb2hkwmg1qtbrJcrVbDz8/vuvXPnz+PS5cuYfz48aZlRqPx2gvb2SEnJwcREdcftpTL5ZDLOdCJqD0cK6jEK9+fBgDMG9Mb0aEeIicioq7IrCMEDg4OiI6ORlpammmZ0WhEWloa4uPjr1u/d+/eOH78OLKzs02Pe++9F6NGjUJ2djZPBRB1sKs6PWatz4TeYMTovirep4CIWmTWEQIASE5ORlJSEmJiYhAbG4slS5ZAp9Nh+vTpAICpU6ciMDAQqampUCgU6N+/f5Pt3d3dAeC65UTUvoxGAc9+mY3CylqEejnxPgVEdENmF4KJEyeitLQUCxcuRHFxMaKiorBz507TQMO8vDxIpZwAkUhsy/bmYl9OKeR2Unw0JRpKR3uxIxFRFyYRBEEQO8TNaLVaKJVKaDQauLm5iR2HqMv7+WwpktYcgiAAbz0wEA/G8PQcka1q7Xso/5QnsjJFlbV4ZlMWBAGYFBvMMkBErcJCQGRF6hoMmLU+A1drGtA/0A2LxvcTOxIRWQgWAiIr8vK/T+JogQZKR3t8NCUaCnuZ2JGIyEKwEBBZiU2H8vDFoXxIJMAHkwYh2NNJ7EhEZEFYCIiswNH8Siz89iQA4Lm7e2JETx+RExGRpWEhILJw5dX1mLU+A3qDEXf3VeHJkd3FjkREFoiFgMiCNRqMmPNFFoo0dQj3dsY7D0XypkVE1CYsBEQW7LUdZ7D/fDmcHGRY8Ug03BScfIiI2oaFgMhCfZ1RgE9/vQgAePehSPRUuYqciIgsGQsBkQU6ml+JlK3HAQBP39kdf+rvL3IiIrJ0LAREFqa0qh6Pf54BfaMRCX18MTehp9iRiMgKsBAQWRB9oxFPbshAsbYOET7OeG9iFAcRElG7YCEgshCCIODFbcdx+NJVuMrtsGpqDFw5iJCI2gkLAZGF+PTXS/jySAGkEmDp5EEI93EROxIRWREWAiILsC+nBK9uPwUA+Oe4vhjZy1fkRERkbVgIiLq43JJqzNmYBaMATIwJxqPDw8SORERWiIWAqAurrNHjsXWHUVXfiNgwT7wyoT8kEg4iJKL2x0JA1EXpG414/PMMXCqvQaC7Iz56eDAc7PgjS0Qdg79diLogQRCQ8s1xHLxYARe5HT6dNgReLnKxYxGRFWMhIOqCPtx3Hl9nFkAmlWD5lMHo5cdpiYmoY7EQEHUx3x8rwlu7cgAAL93bDyN6+oiciIhsAQsBUReSmXcVz315FADw6PBueGRoqMiJiMhWsBAQdRGXynR4bN0R1P92j4J/jusjdiQisiEsBERdQHl1PZLWHEKFTo8BgUq8/9dBkPEeBUTUiVgIiERWqzdgxrojuFxegyAPR3wyLQbOcjuxYxGRjWEhIBKRwSjg6U1ZyM6vhLuTPdY9GgtfV4XYsYjIBrEQEIlEEAS89N1J7DmlhoOdFKunxiCCNywiIpGwEBCJZOmPufj8wGVIJMCSiVGICfMUOxIR2TAWAiIRrD9wGe/uOQsAeGl8P4wd4C9yIiKydSwERJ1sx/ErWPDtCQDA03f1QNKwMHEDERGBhYCoU+3PLcPcTdkQBGBKXAieTeghdiQiIgAsBESd5mh+Jf72eQb0BiPGDvDDv+7jrYyJqOtgISDqBGeKtZj66SFU1zdiWIQX3psYxYmHiKhLYSEg6mAXy3R4ePUhaGobMCjEHaumxkBuJxM7FhFREywERB2osLIWD68+iLLqevTxd8PaabGchZCIuiQWAqIOUlJVh4dXH0RhZS3CfZzx+YxYKJ3sxY5FRNQsFgKiDlBWXY/Jqw7iYpkOge6OWD8jDt4ucrFjERG1iIWAqJ2VV9dj8qoDyC2php+bAhtnxiHA3VHsWEREN8RCQNSOKnR6TFl9EGfV1fB1leOLvw1FqJez2LGIiG6KhYConVTW6PHw6oM4U1wFn9/KQDdvlgEisgwsBETtoEKnx+RVB3HqihbeLg74YmYc71xIRBaF1z8R3aLSqnpMWX0AZ9XV8HZxwMaZQ9Hd11XsWEREZmEhILoFxZo6TF59ABdKdfB1lf9WBnhkgIgsDwsBURsVVtZi8qoDuFxegwClAhtnDkUYxwwQkYViISBqg2vTEV+bdCjY0xEbHxuKYE8nsWMREbUZCwGRmU4WaZD06SGUVesR7u2MDTPj4K/kPANEZNlYCIjMcPhSBR5dexhVdY3o6++Gz2bEcgZCIrIKbbrscPny5QgLC4NCoUBcXBwOHTrU4rqrVq3C7bffDg8PD3h4eCAhIeGG6xN1VXvPlOCRTw6iqq4RsWGe2PT4UJYBIrIaZheCzZs3Izk5GYsWLUJmZiYiIyORmJiIkpKSZtfft28fJk2ahL179yI9PR3BwcEYPXo0CgsLbzk8UWf5JrMAMz87groGI0b18sG6R2PhpuCNiojIekgEQRDM2SAuLg5DhgzBsmXLAABGoxHBwcGYM2cO5s2bd9PtDQYDPDw8sGzZMkydOrVVr6nVaqFUKqHRaODm5mZOXKJbIggCPtx3Hm/tygEA3BcVgLcfjIS9jHN6EZFlaO17qFljCPR6PTIyMpCSkmJaJpVKkZCQgPT09FY9R01NDRoaGuDp6dniOvX19aivrzd9rNVqzYlJ1C4aDUYs+u4kNhzMAwA8fkc4XvhTb0ilEpGTERG1P7P+zCkrK4PBYIBKpWqyXKVSobi4uFXP8cILLyAgIAAJCQktrpOamgqlUml6BAcHmxOT6JbV6g14Yn0mNhzMg0QCvDS+L1LG9mEZICKr1anHPV9//XVs2rQJW7duhUKhaHG9lJQUaDQa0yM/P78TU5KtK9HWYeLH6fjhtBoOdlJ8OHkwpg3vJnYsIqIOZdYpA29vb8hkMqjV6ibL1Wo1/Pz8brjt22+/jddffx0//PADBg4ceMN15XI55HKO3qbOd6JQg5mfHcEVTR08nOzx8dQYDAlr+fQWEZG1MOsIgYODA6Kjo5GWlmZaZjQakZaWhvj4+Ba3e/PNN/HKK69g586diImJaXtaog60+2QxHlyRjiuaOkT4OGPb7OEsA0RkM8yemCg5ORlJSUmIiYlBbGwslixZAp1Oh+nTpwMApk6disDAQKSmpgIA3njjDSxcuBAbN25EWFiYaayBi4sLXFx4ExgSnyAIWPnzBbyx8wwEAbi9hzeWTR4MpSMvKyQi22F2IZg4cSJKS0uxcOFCFBcXIyoqCjt37jQNNMzLy4NU+seBh48++gh6vR4PPPBAk+dZtGgRXnrppVtLT3SLavSNeH7LMXx/7AoA4OGhIVg0vh8vKyQim2P2PARi4DwE1BHyK2ow87MjOFNcBTupBIvG98XDQ0MhkfBKAiKyHh0yDwGRtfjlXBme+iITlTUN8HZxwIdTohHbjeMFiMh2sRCQTTEaBSzfm4v3fjgLowBEBimx4pFo3q2QiGweCwHZjAqdHnM3Z+Pns6UAgIdigvCv+/pDYS8TORkRkfhYCMgmZFyuwFMbs3BFUweFvRT/uq8/HorhDJhERL9jISCrZjReu6Twnd05aDQKCPd2xocPD0ZvPw5OJSL6bywEZLWKNXVI/jIb+8+XAwDuGeiP1/8yEC5yftsTEf0v/mYkq7TrZDFe+PoYKmsa4Ggvw8v39sODMUG8pJCIqAUsBGRVqusb8er2U/ji0LUbYvUPdMP7fx2ECB/OiklEdCMsBGQ10s+X4x9bjqLgai0A4G93hOPvo3vBwY6zDhIR3QwLAVm8Wr0Bb+46gzW/XgIABHk44q0HIhEf4SVuMCIiC8JCQBYt/Xw55m89jotlOgDApNgQ/HNcHw4cJCIyE39rkkXS1DYgdcdpbDp8bayAyk2ON/4yECN7+YqcjIjIMrEQkEURBAE7TxRj4XcnUVpVDwCYEheCF8b0hpuCtysmImorFgKyGJfLdVj03Unsy7k29XC4tzNe/8tA3pSIiKgdsBBQl1fXYMCH+85jxU/noW80wl4mweN3ROCpO7vzPgRERO2EhYC6LEEQsPuUGq9uP428ihoAwO09vPHyvf0QznkFiIjaFQsBdUknizR45ftTOHChAgDg56bAwvF9Maa/H2cbJCLqACwE1KWUVNXh3d1nsflIPgQBkNtJMfP2cMwaGQFnXkpIRNRh+BuWugRtXQM+/ukCPvnlImobDACA8ZEBeOFPvRDk4SRyOiIi68dCQKKqazDg8/TLWL4vF5U1DQCAQSHueHFcH0SH8uoBIqLOwkJAoqhrMODLI/n4cO95FGvrAADdfV3wj8ReGN1XxXECRESdjIWAOlV9owFfHs7H8v8qAgFKBebe3RN/GRwEmZRFgIhIDCwE1Cl09Y3YdDgfq36+YCoCfm4KzB4VgYeGBENux/kEiIjExEJAHapCp8e6/ZewLv2SaYwAiwARUdfDQkAd4kJpNdb8eglbMgpMVw2EeTnh8RERuH9QIGcYJCLqYlgIqN0IgoBfc8vx6a8X8eOZEtPyAYFKzBoZgcR+fhwjQETURbEQ0C3T1jXgm4wCbDiYh3Ml1QAAiQS4q7cvHh3eDfERXrxqgIioi2MhoDY7UajBhoOXsS2ryHRawMlBhgejgzBteDd083YWOSEREbUWCwGZ5apOj2+zC/HlkQKcuqI1Le/h64JH4kMxYVAg3BT2IiYkIqK2YCGgm2owGPHz2VJ8k1WIPSfV0BuMAAAHmRSJ/f3wcFwIYrt58rQAEZEFYyGgZgmCgMy8SnybXYh/Hy3C1d8uGQSAvv5umDgkGPdFBcDdyUHElERE1F5YCMhEEAQcLdBgx/Er2H7sCgora02f83aRY3ykP/4yOAj9A5UipiQioo7AQmDjDEYBGZevYvfJYvznRHGTEuDkIENiPz9MGBSI4RFesJNJRUxKREQdiYXABunqG/Frbhn2nFIj7UwJKnR60+ecHGS4q48K4wb4YWQvX04gRERkI1gIbIAgCLhQpsO+nFLsyynBwQsVpoGBAKB0tMddvX0xup8KI3r6wtGBJYCIyNawEFipCp0ev+aW4ZdzZfglt6zJqQAACPZ0xF29VRjdT4UhYZ6w5+kAIiKbxkJgJSpr9Dh0sQLpF8px4EIFzhRrIQh/fN5eJkFcNy+M7OWDUb19Ee7tzMsEiYjIhIXAQhVV1uLwpQocuXQVhy9VIEdd1aQAAEAvlStu6+GN23p4I66bJ5wc+OUmIqLm8R3CAtTqDThRpEF2XiWy8q8iO68SRZq669aL8HHG0HAvDA33Qly4J3xdFSKkJSIiS8RC0MXUNRhw+ooWJwo1OF6owbECDc6VVMNgbPrnv0wqQb8AN8SEeiImzAMxoR7wdWMBICKitmEhEIkgCFBr63GmWIszxVU4VaTFqStaXCitxv+89wMAfFzlGBTsjkEhHogKdsfAICWc5fzyERFR++A7SgcTBAHF2jrkllSbHmfVVcgproK2rrHZbbycHdA/UImBQUr0D1RiQKAS/koFBwESEVGHYSFoB4IgoLKmAZcranC5XIcLpTpcLPvjUV3f/Bu/TCpBN29n9PJzRV9/N/QNcENffzf4usr55k9ERJ2KhaCVavUGFFbWouBqDfKvXvtvQUUtLlfocLm8BlUt/LUPXHvjD/VyQncfF3T3dUFPlSt6+bki3McZcjtOAkREROJjIcC1N/uSqjoUa+pQrK3DFc21f1/R1KKwshZFlXVNpvdticpNjlBPZ4T7OKOb97VHuI8zQjyd4WDHiX+IiKjrsslCcFZdhZf/fRJqbT1KtHUtnsv/Xy5yOwR5OCLIwwlBHo4I9nRCsIcjQr2cEeLpxCl/iYjIYtlkIQCAX3PLm3zsaC+Dyk0Of6Uj/JUK+CkV8FcqEODuaHooHe1FSktERNSx2lQIli9fjrfeegvFxcWIjIzE0qVLERsb2+L6X331FRYsWIBLly6hR48eeOONNzB27Ng2h75VQR6OeG9iJFSuCvi6KaByk8NFbseBfEREZLPMPrG9efNmJCcnY9GiRcjMzERkZCQSExNRUlLS7Pr79+/HpEmTMGPGDGRlZWHChAmYMGECTpw4ccvh28rJwQ73DwrCsO7e6O7rAleFPcsAERHZNIkg/O8M+DcWFxeHIUOGYNmyZQAAo9GI4OBgzJkzB/Pmzbtu/YkTJ0Kn0+H77783LRs6dCiioqKwYsWKVr2mVquFUqmERqOBm5ubOXGJiIhsWmvfQ806QqDX65GRkYGEhIQ/nkAqRUJCAtLT05vdJj09vcn6AJCYmNji+kRERNT5zBpDUFZWBoPBAJVK1WS5SqXCmTNnmt2muLi42fWLi4tbfJ36+nrU19ebPtZqtebEJCIiIjN1yYvjU1NToVQqTY/g4GCxIxEREVk1swqBt7c3ZDIZ1Gp1k+VqtRp+fn7NbuPn52fW+gCQkpICjUZjeuTn55sTk4iIiMxkViFwcHBAdHQ00tLSTMuMRiPS0tIQHx/f7Dbx8fFN1geAPXv2tLg+AMjlcri5uTV5EBERUccxex6C5ORkJCUlISYmBrGxsViyZAl0Oh2mT58OAJg6dSoCAwORmpoKAHjmmWcwYsQIvPPOOxg3bhw2bdqEI0eO4OOPP27fPSEiIqI2M7sQTJw4EaWlpVi4cCGKi4sRFRWFnTt3mgYO5uXlQSr948DDsGHDsHHjRrz44ouYP38+evTogW3btqF///7ttxdERER0S8yeh0AMnIeAiIiobTpkHgIiIiKyThZxc6PfD2JwPgIiIiLz/P7eebMTAhZRCKqqqgCA8xEQERG1UVVVFZRKZYuft4gxBEajEUVFRXB1dW23mxBptVoEBwcjPz/fasYlcJ+6PmvbH4D7ZCm4T5ahI/ZJEARUVVUhICCgyaD//2URRwikUimCgoI65LmtcZ4D7lPXZ237A3CfLAX3yTK09z7d6MjA7ziokIiIiFgIiIiIyIYLgVwux6JFiyCXy8WO0m64T12fte0PwH2yFNwnyyDmPlnEoEIiIiLqWDZ7hICIiIj+wEJARERELARERETEQkBERERgIWiivr4eUVFRkEgkyM7OFjvOLbn33nsREhIChUIBf39/PPLIIygqKhI7VptdunQJM2bMQLdu3eDo6IiIiAgsWrQIer1e7Gi35NVXX8WwYcPg5OQEd3d3seO0yfLlyxEWFgaFQoG4uDgcOnRI7Eht9vPPP2P8+PEICAiARCLBtm3bxI50y1JTUzFkyBC4urrC19cXEyZMQE5Ojtix2uyjjz7CwIEDTRP3xMfH4z//+Y/YsdrV66+/DolEgrlz53bq67IQ/Jfnn38eAQEBYsdoF6NGjcKXX36JnJwcfP311zh//jweeOABsWO12ZkzZ2A0GrFy5UqcPHkS7733HlasWIH58+eLHe2W6PV6PPjgg5g1a5bYUdpk8+bNSE5OxqJFi5CZmYnIyEgkJiaipKRE7GhtotPpEBkZieXLl4sdpd389NNPmD17Ng4cOIA9e/agoaEBo0ePhk6nEztamwQFBeH1119HRkYGjhw5gjvvvBP33XcfTp48KXa0dnH48GGsXLkSAwcO7PwXF0gQBEHYsWOH0Lt3b+HkyZMCACErK0vsSO3q22+/FSQSiaDX68WO0m7efPNNoVu3bmLHaBdr1qwRlEql2DHMFhsbK8yePdv0scFgEAICAoTU1FQRU7UPAMLWrVvFjtHuSkpKBADCTz/9JHaUduPh4SGsXr1a7Bi3rKqqSujRo4ewZ88eYcSIEcIzzzzTqa/PIwQA1Go1Zs6cic8//xxOTk5ix2l3FRUV2LBhA4YNGwZ7e3ux47QbjUYDT09PsWPYLL1ej4yMDCQkJJiWSaVSJCQkID09XcRkdCMajQYArOJnx2AwYNOmTdDpdIiPjxc7zi2bPXs2xo0b1+RnqjPZfCEQBAHTpk3DE088gZiYGLHjtKsXXngBzs7O8PLyQl5eHr799luxI7Wb3NxcLF26FI8//rjYUWxWWVkZDAYDVCpVk+UqlQrFxcUipaIbMRqNmDt3LoYPH47+/fuLHafNjh8/DhcXF8jlcjzxxBPYunUr+vbtK3asW7Jp0yZkZmYiNTVVtAxWWwjmzZsHiURyw8eZM2ewdOlSVFVVISUlRezIN9XaffrdP/7xD2RlZWH37t2QyWSYOnUqhC42MaW5+wQAhYWF+NOf/oQHH3wQM2fOFCl5y9qyT0SdYfbs2Thx4gQ2bdokdpRb0qtXL2RnZ+PgwYOYNWsWkpKScOrUKbFjtVl+fj6eeeYZbNiwAQqFQrQcVjt1cWlpKcrLy2+4Tnh4OB566CH8+9//hkQiMS03GAyQyWSYMmUK1q1b19FRW621++Tg4HDd8oKCAgQHB2P//v1d6tCauftUVFSEkSNHYujQoVi7du0N7+0tlrZ8ndauXYu5c+eisrKyg9O1H71eDycnJ2zZsgUTJkwwLU9KSkJlZaXFH5GSSCTYunVrk32zZE899RS+/fZb/Pzzz+jWrZvYcdpVQkICIiIisHLlSrGjtMm2bdtw//33QyaTmZYZDAZIJBJIpVLU19c3+VxHsevwVxCJj48PfHx8brreBx98gMWLF5s+LioqQmJiIjZv3oy4uLiOjGi21u5Tc4xGI4Brl1Z2JebsU2FhIUaNGoXo6GisWbOmS5YB4Na+TpbEwcEB0dHRSEtLM71pGo1GpKWl4amnnhI3HJkIgoA5c+Zg69at2Ldvn9WVAeDa911X+91mjrvuugvHjx9vsmz69Ono3bs3XnjhhU4pA4AVF4LWCgkJafKxi4sLACAiIgJBQUFiRLplBw8exOHDh3HbbbfBw8MD58+fx4IFCxAREdGljg6Yo7CwECNHjkRoaCjefvttlJaWmj7n5+cnYrJbk5eXh4qKCuTl5cFgMJjmv+jevbvpe7ErS05ORlJSEmJiYhAbG4slS5ZAp9Nh+vTpYkdrk+rqauTm5po+vnjxIrKzs+Hp6Xnd7wpLMXv2bGzcuBHffvstXF1dTeM7lEolHB0dRU5nvpSUFIwZMwYhISGoqqrCxo0bsW/fPuzatUvsaG3m6up63ZiO38d/depYj069psECXLx40eIvOzx27JgwatQowdPTU5DL5UJYWJjwxBNPCAUFBWJHa7M1a9YIAJp9WLKkpKRm92nv3r1iR2u1pUuXCiEhIYKDg4MQGxsrHDhwQOxIbbZ3795mvx5JSUliR2uzln5u1qxZI3a0Nnn00UeF0NBQwcHBQfDx8RHuuusuYffu3WLHandiXHZotWMIiIiIqPW65klYIiIi6lQsBERERMRCQERERCwEREREBBYCIiIiAgsBERERgYWAiIiIwEJAREREYCEgIiIisBAQERERWAiIiIgILAREREQE4P8B0PYGsaV970IAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_function(torch.sigmoid, title='Sigmoid', min=-4, max=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "As you can see, it takes any input value, positive or negative, and smooshes it onto an output value between 0 and 1. It's also a smooth curve that only goes up, which makes it easier for SGD to find meaningful gradients. \n",
    "\n",
    "Let's update `mnist_loss` to first apply `sigmoid` to the inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_loss(predictions, targets):\n",
    "    predictions = predictions.sigmoid()\n",
    "    return torch.where(targets==1, 1-predictions, predictions).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now we can be confident our loss function will work, even if the predictions are not between 0 and 1. All that is required is that a higher prediction corresponds to higher confidence an image is a 3.\n",
    "\n",
    "Having defined a loss function, now is a good moment to recapitulate why we did this. After all, we already had a metric, which was overall accuracy. So why did we define a loss?\n",
    "\n",
    "The key difference is that the metric is to drive human understanding and the loss is to drive automated learning. To drive automated learning, the loss must be a function that has a meaningful derivative. It can't have big flat sections and large jumps, but instead must be reasonably smooth. This is why we designed a loss function that would respond to small changes in confidence level. This requirement means that sometimes it does not really reflect exactly what we are trying to achieve, but is rather a compromise between our real goal and a function that can be optimized using its gradient. The loss function is calculated for each item in our dataset, and then at the end of an epoch the loss values are all averaged and the overall mean is reported for the epoch.\n",
    "\n",
    "Metrics, on the other hand, are the numbers that we really care about. These are the values that are printed at the end of each epoch that tell us how our model is really doing. It is important that we learn to focus on these metrics, rather than the loss, when judging the performance of a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### SGD and Mini-Batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a loss function that is suitable for driving SGD, we can consider some of the details involved in the next phase of the learning process, which is to change or update the weights based on the gradients. This is called an *optimization step*.\n",
    "\n",
    "In order to take an optimization step we need to calculate the loss over one or more data items. How many should we use? We could calculate it for the whole dataset, and take the average, or we could calculate it for a single data item. But neither of these is ideal. Calculating it for the whole dataset would take a very long time. Calculating it for a single item would not use much information, so it would result in a very imprecise and unstable gradient. That is, you'd be going to the trouble of updating the weights, but taking into account only how that would improve the model's performance on that single item.\n",
    "\n",
    "So instead we take a compromise between the two: we calculate the average loss for a few data items at a time. This is called a *mini-batch*. The number of data items in the mini-batch is called the *batch size*. A larger batch size means that you will get a more accurate and stable estimate of your dataset's gradients from the loss function, but it will take longer, and you will process fewer mini-batches per epoch. Choosing a good batch size is one of the decisions you need to make as a deep learning practitioner to train your model quickly and accurately. \n",
    "\n",
    "Another good reason for using mini-batches rather than calculating the gradient on individual data items is that, in practice, we nearly always do our training on an accelerator such as a GPU. These accelerators only perform well if they have lots of work to do at a time, so it's helpful if we can give them lots of data items to work on. Using mini-batches is one of the best ways to do this. However, if you give them too much data to work on at once, they run out of memory.\n",
    "\n",
    "We get better generalization if we can vary things during training. One simple and effective thing we can vary is what data items we put in each mini-batch. Rather than simply enumerating our dataset in order for every epoch, instead what we normally do is randomly shuffle it on every epoch, before we create mini-batches. PyTorch and fastai provide a class that will do the shuffling and mini-batch collation for you, called `DataLoader`.\n",
    "\n",
    "A `DataLoader` can take any Python collection and turn it into an iterator over mini-batches, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([ 8,  0, 12, 14,  5]),\n",
       " tensor([ 2, 11, 13,  6,  9]),\n",
       " tensor([ 7,  3,  1,  4, 10])]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coll = range(15)\n",
    "dl = DataLoader(coll, batch_size=5, shuffle=True)\n",
    "list(dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For training a model, we don't just want any Python collection, but a collection containing independent and dependent variables (that is, the inputs and targets of the model). A collection that contains tuples of independent and dependent variables is known in PyTorch as a `Dataset`. Here's an example of an extremely simple `Dataset`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#26) [(0, 'a'),(1, 'b'),(2, 'c'),(3, 'd'),(4, 'e'),(5, 'f'),(6, 'g'),(7, 'h'),(8, 'i'),(9, 'j')...]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = L(enumerate(string.ascii_lowercase))\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we pass a `Dataset` to a `DataLoader` we will get back mini-batches which are themselves tuples of tensors representing batches of independent and dependent variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([18, 20,  7,  0, 25, 21]), ('s', 'u', 'h', 'a', 'z', 'v')),\n",
       " (tensor([ 2, 13, 10, 22,  4,  8]), ('c', 'n', 'k', 'w', 'e', 'i')),\n",
       " (tensor([15, 12,  6, 24,  9, 11]), ('p', 'm', 'g', 'y', 'j', 'l')),\n",
       " (tensor([17,  3,  1, 16,  5, 23]), ('r', 'd', 'b', 'q', 'f', 'x')),\n",
       " (tensor([19, 14]), ('t', 'o'))]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = DataLoader(ds, batch_size=6, shuffle=True)\n",
    "list(dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Putting It All Together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's re-initialize our parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = init_params((28*28,1))\n",
    "bias = init_params(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `DataLoader` can be created from a `Dataset`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([256, 784]), torch.Size([256, 1]))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = DataLoader(dset, batch_size=256)\n",
    "xb,yb = first(dl)\n",
    "xb.shape,yb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll do the same for the validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dl = DataLoader(valid_dset, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's create a mini-batch of size 4 for testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 784])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = train_x[:4]\n",
    "batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.4054],\n",
       "        [-8.8730],\n",
       "        [ 2.4265],\n",
       "        [-4.9154]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = linear1(batch)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7604, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = mnist_loss(preds, train_y[:4])\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now we can calculate the gradients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784, 1]), tensor(-0.0041), tensor([-0.0283]))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.backward()\n",
    "weights.grad.shape,weights.grad.mean(),bias.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put that all in a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_grad(xb, yb, model):\n",
    "    preds = model(xb)\n",
    "    loss = mnist_loss(preds, yb)\n",
    "    loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and test it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.0082), tensor([-0.0565]))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_grad(batch, train_y[:4], linear1)\n",
    "weights.grad.mean(),bias.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "But look what happens if we call it twice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.0123), tensor([-0.0848]))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_grad(batch, train_y[:4], linear1)\n",
    "weights.grad.mean(),bias.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradients have changed! The reason for this is that `loss.backward` actually *adds* the gradients of `loss` to any gradients that are currently stored. So, we have to set the current gradients to 0 first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights.grad.zero_()\n",
    "bias.grad.zero_();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> note: Inplace Operations: Methods in PyTorch whose names end in an underscore modify their objects _in place_. For instance, `bias.zero_()` sets all elements of the tensor `bias` to 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Our only remaining step is to update the weights and biases based on the gradient and learning rate. When we do so, we have to tell PyTorch not to take the gradient of this step too—otherwise things will get very confusing when we try to compute the derivative at the next batch! If we assign to the `data` attribute of a tensor then PyTorch will not take the gradient of that step. Here's our basic training loop for an epoch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, lr, params):\n",
    "    for xb,yb in dl:\n",
    "        calc_grad(xb, yb, model)\n",
    "        for p in params:\n",
    "            p.data -= p.grad*lr\n",
    "            p.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We also want to check how we're doing, by looking at the accuracy of the validation set. To decide if an output represents a 3 or a 7, we can just check whether it's greater than 0. So our accuracy for each item can be calculated (using broadcasting, so no loops!) with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [False]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(preds>0.0).float() == train_y[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "That gives us this function to calculate our validation accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_accuracy(xb, yb):\n",
    "    preds = xb.sigmoid()\n",
    "    correct = (preds>0.5) == yb\n",
    "    return correct.float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2500)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_accuracy(linear1(batch), train_y[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "and then put the batches together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_epoch(model):\n",
    "    accs = [batch_accuracy(model(xb), yb) for xb,yb in valid_dl]\n",
    "    return round(torch.stack(accs).mean().item(), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2813"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_epoch(linear1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "That's our starting point. Let's train for one epoch, and see if the accuracy improves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5687"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 1.\n",
    "params = weights,bias\n",
    "train_epoch(linear1, lr, params)\n",
    "validate_epoch(linear1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then do a few more:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6654 0.8749 0.9306 0.9472 0.9511 0.9535 0.9564 0.9584 0.9593 0.9618 0.9637 0.9652 0.9657 0.9667 0.9681 0.9691 0.9691 0.9701 0.9701 0.9701 "
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    train_epoch(linear1, lr, params)\n",
    "    print(validate_epoch(linear1), end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking good! We're already about at the same accuracy as our \"pixel similarity\" approach, and we've created a general-purpose foundation we can build on. Our next step will be to create an object that will handle the SGD step for us. In PyTorch, it's called an *optimizer*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Creating an Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because this is such a general foundation, PyTorch provides some useful classes to make it easier to implement. The first thing we can do is replace our `linear1` function with PyTorch's `nn.Linear` module. A *module* is an object of a class that inherits from the PyTorch `nn.Module` class. Objects of this class behave identically to standard Python functions, in that you can call them using parentheses and they will return the activations of a model.\n",
    "\n",
    "`nn.Linear` does the same thing as our `init_params` and `linear` together. It contains both the *weights* and *biases* in a single class. Here's how we replicate our model from the previous section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = nn.Linear(28*28,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Every PyTorch module knows what parameters it has that can be trained; they are available through the `parameters` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 784]), torch.Size([1]))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w,b = linear_model.parameters()\n",
    "w.shape,b.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this information to create an optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicOptim:\n",
    "    def __init__(self,params,lr): self.params,self.lr = list(params),lr\n",
    "\n",
    "    def step(self, *args, **kwargs):\n",
    "        for p in self.params: p.data -= p.grad.data * self.lr\n",
    "\n",
    "    def zero_grad(self, *args, **kwargs):\n",
    "        for p in self.params: p.grad = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can create our optimizer by passing in the model's parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = BasicOptim(linear_model.parameters(), lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our training loop can now be simplified to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model):\n",
    "    for xb,yb in dl:\n",
    "        calc_grad(xb, yb, model)\n",
    "        opt.step()\n",
    "        opt.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Our validation function doesn't need to change at all:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6245"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_epoch(linear_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put our little training loop in a function, to make things simpler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, epochs):\n",
    "    for i in range(epochs):\n",
    "        train_epoch(model)\n",
    "        print(validate_epoch(model), end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The results are the same as in the previous section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4932 0.8291 0.8457 0.9145 0.9336 0.9492 0.955 0.9619 0.9653 0.9672 0.9692 0.9721 0.9731 0.9746 0.9761 0.9765 0.977 0.978 0.978 0.9785 "
     ]
    }
   ],
   "source": [
    "train_model(linear_model, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fastai provides the `SGD` class which, by default, does the same thing as our `BasicOptim`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4932 0.7637 0.8589 0.9194 0.9365 0.9507 0.958 0.9633 0.9658 0.9682 0.9697 0.9717 0.9746 0.9746 0.9761 0.977 0.9775 0.978 0.9785 0.979 "
     ]
    }
   ],
   "source": [
    "linear_model = nn.Linear(28*28,1)\n",
    "opt = SGD(linear_model.parameters(), lr)\n",
    "train_model(linear_model, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "fastai also provides `Learner.fit`, which we can use instead of `train_model`. To create a `Learner` we first need to create a `DataLoaders`, by passing in our training and validation `DataLoader`s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataLoaders(dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a `Learner` without using an application (such as `vision_learner`) we need to pass in all the elements that we've created in this chapter: the `DataLoaders`, the model, the optimization function (which will be passed the parameters), the loss function, and optionally any metrics to print:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, nn.Linear(28*28,1), opt_func=SGD,\n",
    "                loss_func=mnist_loss, metrics=batch_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now we can call `fit`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/biagio/miniconda3/envs/iadb-dl/lib/python3.11/site-packages/fastai/torch_core.py:263: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
      "  return getattr(torch, 'has_mps', False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>batch_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.636005</td>\n",
       "      <td>0.503384</td>\n",
       "      <td>0.495584</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.485063</td>\n",
       "      <td>0.216726</td>\n",
       "      <td>0.806183</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.179541</td>\n",
       "      <td>0.173672</td>\n",
       "      <td>0.842983</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.079457</td>\n",
       "      <td>0.104799</td>\n",
       "      <td>0.914622</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.042569</td>\n",
       "      <td>0.077016</td>\n",
       "      <td>0.934249</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.028129</td>\n",
       "      <td>0.061891</td>\n",
       "      <td>0.948479</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.022162</td>\n",
       "      <td>0.052440</td>\n",
       "      <td>0.955839</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.019489</td>\n",
       "      <td>0.046144</td>\n",
       "      <td>0.962709</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.018120</td>\n",
       "      <td>0.041711</td>\n",
       "      <td>0.965653</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.017292</td>\n",
       "      <td>0.038434</td>\n",
       "      <td>0.967125</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(10, lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now replace our linear model with a neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Adding a Nonlinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have a general procedure for optimizing the parameters of a function, and we have tried it out on a simple linear classifier. A linear classifier is very constrained in terms of what it can do. To make it a bit more complex (and able to handle more tasks), we need to add something nonlinear between two linear classifiers—this is what gives us a neural network.\n",
    "\n",
    "Here is the entire definition of a basic neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_net(xb): \n",
    "    res = xb@w1 + b1\n",
    "    res = res.max(tensor(0.0))\n",
    "    res = res@w2 + b2\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "That's it! All we have in `simple_net` is two linear classifiers with a `max` function between them.\n",
    "\n",
    "Here, `w1` and `w2` are weight tensors, and `b1` and `b2` are bias tensors; that is, parameters that are initially randomly initialized, just like we did in the previous section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = init_params((28*28,30))\n",
    "b1 = init_params(30)\n",
    "w2 = init_params((30,1))\n",
    "b2 = init_params(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The key point about this is that `w1` has 30 output activations (which means that `w2` must have 30 input activations, so they match). That means that the first layer can construct 30 different features, each representing some different mix of pixels. You can change that `30` to anything you like, to make the model more or less complex.\n",
    "\n",
    "That little function `res.max(tensor(0.0))` is called a *rectified linear unit*, also known as *ReLU*. We think we can all agree that *rectified linear unit* sounds pretty fancy and complicated... But actually, there's nothing more to it than `res.max(tensor(0.0))`—in other words, replace every negative number with a zero. This tiny function is also available in PyTorch as `F.relu`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_function(F.relu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The basic idea is that by using more linear layers, we can have our model do more computation, and therefore model more complex functions. But there's no point just putting one linear layer directly after another one, because when we multiply things together and then add them up multiple times, that could be replaced by multiplying different things together and adding them up just once! \n",
    "> Mathematically, we say the composition of two linear functions is another linear function. So, we can stack as many linear classifiers as we want on top of each other, and without nonlinear functions between them, it will just be the same as one linear classifier.\n",
    "\n",
    "But if we put a nonlinear function between them, such as `max`, then this is no longer true. Now each linear layer is actually somewhat decoupled from the other ones, and can do its own useful work. The `max` function is particularly interesting, because it operates as a simple `if` statement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "As we saw, it can be mathematically proven that this little function can solve any computable problem to an arbitrarily high level of accuracy, if you can find the right parameters for `w1` and `w2` and if you make these matrices big enough. For any arbitrarily wiggly function, we can approximate it as a bunch of lines joined together; to make it closer to the wiggly function, we just have to use shorter lines. This is known as the *universal approximation theorem*. The three lines of code that we have here are known as *layers*. The first and third are known as *linear layers*, and the second line of code is known variously as a *nonlinearity*, or *activation function*.\n",
    "\n",
    "Just like in the previous section, we can replace this code with something a bit simpler, by taking advantage of PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_net = nn.Sequential(\n",
    "    nn.Linear(28*28,30),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(30,1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "`nn.Sequential` creates a module that will call each of the listed layers or functions in turn.\n",
    "\n",
    "`nn.ReLU` is a PyTorch module that does exactly the same thing as the `F.relu` function. Most functions that can appear in a model also have identical forms that are modules. Generally, it's just a case of replacing `F` with `nn` and changing the capitalization. When using `nn.Sequential`, PyTorch requires us to use the module version. Since modules are classes, we have to instantiate them, which is why you see `nn.ReLU()` in this example. \n",
    "\n",
    "Because `nn.Sequential` is a module, we can get its parameters, which will return a list of all the parameters of all the modules it contains. Let's try it out! As this is a deeper model, we'll use a lower learning rate and a few more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, simple_net, opt_func=SGD,\n",
    "                loss_func=mnist_loss, metrics=batch_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>batch_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.323018</td>\n",
       "      <td>0.402363</td>\n",
       "      <td>0.506869</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.149650</td>\n",
       "      <td>0.235003</td>\n",
       "      <td>0.797350</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.082624</td>\n",
       "      <td>0.117938</td>\n",
       "      <td>0.914132</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.054026</td>\n",
       "      <td>0.079289</td>\n",
       "      <td>0.940137</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.040783</td>\n",
       "      <td>0.061769</td>\n",
       "      <td>0.955348</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.034043</td>\n",
       "      <td>0.051922</td>\n",
       "      <td>0.963690</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.030185</td>\n",
       "      <td>0.045720</td>\n",
       "      <td>0.965162</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.027686</td>\n",
       "      <td>0.041484</td>\n",
       "      <td>0.967125</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.025887</td>\n",
       "      <td>0.038399</td>\n",
       "      <td>0.968106</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.024494</td>\n",
       "      <td>0.036041</td>\n",
       "      <td>0.969578</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.023363</td>\n",
       "      <td>0.034167</td>\n",
       "      <td>0.972031</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.022420</td>\n",
       "      <td>0.032629</td>\n",
       "      <td>0.973994</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.021616</td>\n",
       "      <td>0.031338</td>\n",
       "      <td>0.974975</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.020923</td>\n",
       "      <td>0.030233</td>\n",
       "      <td>0.975466</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.020316</td>\n",
       "      <td>0.029270</td>\n",
       "      <td>0.975466</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.019780</td>\n",
       "      <td>0.028423</td>\n",
       "      <td>0.976448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.019301</td>\n",
       "      <td>0.027669</td>\n",
       "      <td>0.976448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.018870</td>\n",
       "      <td>0.026991</td>\n",
       "      <td>0.977920</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.018478</td>\n",
       "      <td>0.026380</td>\n",
       "      <td>0.977920</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.018121</td>\n",
       "      <td>0.025825</td>\n",
       "      <td>0.977920</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.017793</td>\n",
       "      <td>0.025320</td>\n",
       "      <td>0.978410</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.017489</td>\n",
       "      <td>0.024857</td>\n",
       "      <td>0.979392</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.017207</td>\n",
       "      <td>0.024431</td>\n",
       "      <td>0.979392</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.016944</td>\n",
       "      <td>0.024039</td>\n",
       "      <td>0.979392</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.016698</td>\n",
       "      <td>0.023676</td>\n",
       "      <td>0.979882</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.016466</td>\n",
       "      <td>0.023340</td>\n",
       "      <td>0.980373</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.016247</td>\n",
       "      <td>0.023028</td>\n",
       "      <td>0.980373</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.016041</td>\n",
       "      <td>0.022738</td>\n",
       "      <td>0.981354</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.015845</td>\n",
       "      <td>0.022468</td>\n",
       "      <td>0.981845</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.015659</td>\n",
       "      <td>0.022217</td>\n",
       "      <td>0.982336</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.015482</td>\n",
       "      <td>0.021982</td>\n",
       "      <td>0.982826</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.015313</td>\n",
       "      <td>0.021763</td>\n",
       "      <td>0.983317</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.015151</td>\n",
       "      <td>0.021558</td>\n",
       "      <td>0.983317</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.014997</td>\n",
       "      <td>0.021366</td>\n",
       "      <td>0.983317</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.014849</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>0.982826</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.021017</td>\n",
       "      <td>0.982826</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.014570</td>\n",
       "      <td>0.020858</td>\n",
       "      <td>0.983317</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.014438</td>\n",
       "      <td>0.020708</td>\n",
       "      <td>0.983317</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.014312</td>\n",
       "      <td>0.020566</td>\n",
       "      <td>0.983317</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.014189</td>\n",
       "      <td>0.020431</td>\n",
       "      <td>0.983317</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide_output\n",
    "learn.fit(40, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The training process is recorded in `learn.recorder`, with the table of output stored in the `values` attribute, so we can plot the accuracy over training as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(L(learn.recorder.values).itemgot(2));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can view the final accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.983316957950592"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.recorder.values[-1][2]"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "rise": {
   "enable_chalkboard": true,
   "scroll": true,
   "theme": "simple"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
